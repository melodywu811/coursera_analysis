,course_href,course_name,partner_title,stars,recent_views,num_ratings,num_reviews,description,length,100%_online,shareable_certificate,flexible_deadlines,english,intermediate_level,beginner_level,spanish,chinese_(traditional),arabic,portuguese_(brazilian),russian,advanced_level,chinese_(simplified),french,japanese,specialization,outcome_career_benefit,outcome_pay_increase,outcome_new_career,he_partner,enrollment
0,/learn/exploratory-data-analysis,Exploratory Data Analysis,Johns Hopkins University,4.7,108049,5836,845,This course covers the essential exploratory techniques for summarizing data. These techniques are typically applied before formal modeling commences and can help inform the development of more complex statistical models. Exploratory techniques are also important for eliminating or sharpening potential hypotheses about the world that can be addressed by the data. We will cover in detail the plotting systems in R as well as some of the basic principles of constructing data graphics. We will also cover some of the common multivariate statistical techniques used to visualize high-dimensional data.,55,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,38.0,15.0,38.0,1,157581
1,/learn/clinical-natural-language-processing,Clinical Natural Language Processing,University of Colorado System,3.5,3786,17,9,"This course teaches you the fundamentals of clinical natural language processing (NLP). In this course you will learn the basic linguistic principals underlying NLP, as well as how to write regular expressions and handle text data in R. You will also learn practical techniques for text processing to be able to extract information from clinical notes.  Finally, you will have a chance to put your skills to the test with a real-world practical application where you develop text processing algorithms to identify diabetic complications from clinical notes. You will complete this work using a free, online computational environment for data science hosted by our Industry Partner Google Cloud.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,3341
2,/learn/machine-learning-with-python,Machine Learning with Python,IBM,4.7,510028,10738,1813,"This course dives into the basics of machine learning using an approachable, and well-known programming language, Python. In this course, we will be reviewing two main components:
First, you will be learning about the purpose of Machine Learning and where it applies to the real world. 
Second, you will get a general overview of Machine Learning topics such as supervised vs unsupervised learning,  model evaluation, and Machine Learning algorithms. 

In this course, you practice with real-life examples of Machine learning and see how it affects society in ways you may not have guessed!

By just putting in a few hours a week for the next few weeks, this is what you’ll get.
1) New skills to add to your resume, such as regression, classification, clustering, sci-kit learn and SciPy 
2) New projects that you can add to your portfolio, including cancer detection, predicting economic trends, predicting customer churn, recommendation engines, and many more.
3) And a certificate in machine learning to prove your competency, and share it anywhere you like online or offline, such as LinkedIn profiles and social media.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge upon successful completion of the course.",22,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,21.0,17.0,13.0,0,199048
3,/learn/material-informatics,Materials Data Sciences and Informatics,Georgia Institute of Technology,4.4,9147,256,72,"This course aims to provide a succinct overview of the emerging discipline of Materials Informatics at the intersection of materials science, computational science, and information science. Attention is drawn to specific opportunities afforded by this new field in accelerating materials development and deployment efforts. A particular emphasis is placed on materials exhibiting hierarchical internal structures spanning multiple length/structure scales and the impediments involved in establishing invertible process-structure-property (PSP) linkages for these materials. More specifically, it is argued that modern data sciences (including advanced statistics, dimensionality reduction, and formulation of metamodels) and innovative cyberinfrastructure tools (including integration platforms, databases, and customized tools for enhancement of collaborations among cross-disciplinary team members) are likely to play a critical and pivotal role in addressing the above challenges.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,11573
4,/learn/complete-reinforcement-learning-system,A Complete Reinforcement Learning System (Capstone),University of Alberta,4.7,24627,464,95,"In this final course, you will put together your knowledge from Courses 1, 2 and 3 to implement a complete RL solution to a problem. This capstone will let you see how each component---problem formulation, algorithm selection, parameter selection and representation design---fits together into a complete solution, and how to make appropriate choices when deploying RL in the real world. This project will require you to implement both the environment to stimulate your problem, and a control agent with Neural Network function approximation. In addition, you will conduct a scientific study of your learning system to develop your ability to assess the robustness of RL agents. To use RL in the real world, it is critical to (a) appropriately formalize the problem as an MDP, (b) select appropriate algorithms, (c ) identify what choices in your implementation will have large impacts on performance and (d) validate the expected behaviour of your algorithms. This capstone is valuable for anyone who is planning on using RL to solve real problems.To be successful in this course, you will need to have completed Courses 1, 2, and 3 of this Specialization or the equivalent.

By the end of this course, you will be able to: 

Complete an RL solution to a problem, starting from problem formulation, appropriate algorithm selection and implementation and empirical study into the effectiveness of the solution.",23,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,1,11701
5,/learn/intro-to-deep-learning,Introduction to Deep Learning,HSE University,4.6,197219,1743,405,"The goal of this course is to give learners basic understanding of modern neural networks and their applications in computer vision and natural language understanding. The course starts with a recap of linear models and discussion of stochastic optimization methods that are crucial for training deep neural networks. Learners will study all popular building blocks of neural networks including fully connected layers, convolutional and recurrent layers. Learners will use these building blocks to define complex modern architectures in TensorFlow and Keras frameworks. In the course project learner will implement deep neural network for the task of image captioning which solves the problem of giving a text description for an input image.

The prerequisites for this course are: 
1) Basic knowledge of Python.
2) Basic linear algebra and probability.

Please note that this is an advanced course and we assume basic knowledge of machine learning. You should understand:
1) Linear regression: mean squared error, analytical solution.
2) Logistic regression: model, cross-entropy loss, class probability estimation.
3) Gradient descent for linear models. Derivatives of MSE and cross-entropy loss functions.
4) The problem of overfitting.
5) Regularization for linear models.

Do you have technical problems? Write to us: coursera@hse.ru",34,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,34.0,20.0,29.0,1,157741
6,/learn/response-surfaces-mixtures-model-building,"Response Surfaces, Mixtures, and Model Building",Arizona State University,4.6,7269,38,11,"Factorial experiments are often used in factor screening.; that is, identify the subset of factors in a process or system that are of primary important to the response. Once the set of important factors are identified interest then usually turns to optimization; that is, what levels of the important factors produce the best values of the response.  This course provides design and optimization tools to answer that questions using the response surface framework.  Other related topics include design and analysis of computer experiments, experiments with mixtures, and experimental strategies to reduce the effect of uncontrollable factors on unwanted variability in the response.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,1812
7,/learn/clinical-data-management,Data Management for Clinical Research,Vanderbilt University,4.7,94363,997,317,"This course presents critical concepts and practical methods to support planning, collection, storage, and dissemination of data in clinical research.Understanding and implementing solid data management principles is critical for any scientific domain. Regardless of your current (or anticipated) role in the research enterprise, a strong working knowledge and skill set in data management principles and practice will increase your productivity and improve your science. Our goal is to use these modules to help you learn and practice this skill set. 

This course assumes very little current knowledge of technology other than how to operate a web browser. We will focus on practical lessons, short quizzes, and hands-on exercises as we explore together best practices for data management.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,28.0,17.0,32.0,1,61693
8,/learn/experimentation,Experimentation for Improvement,McMaster University,4.8,17688,783,207,"We are always using experiments to improve our lives, our community, and our work. Are you doing it efficiently? Or are you (incorrectly) changing one thing at a time and hoping for the best? In this course, you will learn how to plan efficient experiments - testing with many variables. Our goal is to find the best results using only a few experiments. A key part of the course is how to optimize a system.

We use simple tools: starting with fast calculations by hand, then we show how to use FREE software. 

The course comes with slides, transcripts of all lectures, subtitles (English, Spanish and Portuguese; some Chinese and French), videos, audio files, source code, and a free textbook. You get to keep all of it, all freely downloadable.

This course is for anyone working in a company, or wanting to make changes to their life, their community, their neighbourhood. You don't need to be a statistician or scientist! There's something for everyone in here. 
⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯
Over 1500 people have completed this online course. What have prior students said about this course?

""This definitely is one of the most fruitful courses I have participated at Coursera, considering the takeaways and implementations! And so far I finished 12 [courses].""

""Excelente curso, flexible y con suficiente material didáctico fácilmente digerible y cómodo. No importa si se tiene pocas bases matemáticas o estadísticas, el curso proporciona casi toda explicación necesaria para un entendimiento alto.""

""I wish I had enrolled in your course years ago -- it would have saved us a lot of time in optimizing experimental conditions."" Jason Eriksen, 3 Jan 2017

""Interesting and developing both analytical and creative thinking. The lecturer took care to bring lots of real live examples which are fun to analyze."" 20 February 2016.

""... love your style of presentation, and the examples you took from everyday life to explain things. It is very difficult to make such a mathematical course accessible and comprehensible to this wide a variety of people!""
⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,14.0,,11.0,1,30541
9,/learn/computer-simulations,Computer Simulations,"University of California, Davis",4.7,9628,38,10,"Big data and artificial intelligence get most of the press about computational social science, but maybe the most complex aspect of it refers to using computational tools to explore and develop social science theory. This course shows how computer simulations are being used to explore the realm of what is theoretically possible. Computer simulations allow us to study why societies are the way they are, and to dream about the world we would like to live in. This can be as intuitive as playing a video game. Much like the well-known video game SimCity is used to build and manage an artificial city, we use agent-based models to grow and study artificial societies. Without hurting anyone in the real world, computer simulations allow us explore how to make the world a better place. We play hands-on with several practical computer simulation models and explore how we can combine hypothetical models with real world data. Finally, you will program a simple artificial society yourself, bottom-up. This will allow you to feel the complexity that arises when designing social systems, while at the same time experiencing the ease with which our new computational tools allow us to pursue such daunting endeavors.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,3881
10,/learn/sas-programming-basics,Getting Started with SAS Programming,SAS,4.8,191893,1811,403,"This course is for users who want to learn how to write SAS programs to access, explore, prepare, and analyze data. It is the entry point to learning SAS programming for data science, machine learning, and artificial intelligence. It is a prerequisite to many other SAS courses.By the end of this course, you will know how to use SAS Studio to write and submit SAS programs that access SAS, Microsoft Excel, and text data. You will know how to explore and validate data, prepare data by subsetting rows and computing new columns, analyze and report on data, export data and results to other formats, use SQL in SAS to query and join tables.

Prerequisites:
Learners should have experience using computer software. Specifically, you should be able to understand file structures and system commands on your operating systems and access data files on your operating systems. No prior SAS experience is needed.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,14.0,18.0,0,55783
11,/learn/excel-data-analysis-fundamentals,Excel Fundamentals for Data Analysis,Macquarie University,4.7,268211,941,243,"As data becomes the modern currency, so the ability to analyse the data quickly and accurately has become of paramount importance. Excel with its extraordinarily broad range of features and capabilities is one of the most widely used programs for doing this. In the first course of our Excel Skills for Data Analysis and Visualization Specialization, you will learn the fundamentals of Excel for data analysis. When you have completed the course, you will be able to use a range of Excel tools and functions to clean and prepare data for analysis; automate data analysis with the help of Named Ranges and Tables; and use logical and lookup functions to transform, link and categorise data.This course will enable you to build a strong foundation in the fundamentals, helping you to be more efficient in your day-to-day and developing the necessary skills to work with the more advanced techniques used in later courses. To make the content easy to relate to and to personalize the learning experience, we are going to follow Zara's journey through the course. Who is Zara? Well, she is no-one and everyone. You will find that Zara's trials and tribulations sound familiar, and together with Zara, you will develop your Excel skills along the way — and, importantly, have some fun doing it.

The Excel Skills for Data Analytics and Visualization courses are the sequel to one of most successful specializations on Coursera, Excel Skills for Business, which has attracted hundreds of thousands of learners and top ratings. Transform your skills, your confidence, and your opportunities by adding this new set of skills to your repertoire.",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,42228
12,/learn/managing-describing-analyzing-data,"Managing, Describing, and Analyzing Data",University of Colorado Boulder,4.2,15533,9,4,"In this course, you will learn the basics of understanding the data you have and why correctly classifying data is the first step to making correct decisions. You will describe data both graphically and numerically using descriptive statistics and R software. You will learn four probability distributions commonly used in the analysis of data. You will analyze data sets using the appropriate probability distribution. Finally, you will learn the basics of sampling error, sampling distributions, and errors in decision-making.This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",12,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,,,,1,1616
13,/learn/demand-analytics,Demand Analytics,Rutgers the State University of New Jersey,4.4,19622,120,25,"Welcome to Demand Analytics - one of the most sought-after skills in supply chain management and marketing!Through the real-life story and data of a leading cookware manufacturer in North America, you will learn the data analytics skills for demand planning and forecasting. Upon the completion of this course, you will be able to  

1. Improve the forecasting accuracy by building and validating demand prediction models. 
2. Better stimulate and influence demand by identifying the drivers (e.g., time, seasonality, price, and other environmental factors) for demand and quantifying their impact.

AK is a leading cookware manufacturer in North America. Its newly launched top-line product was gaining momentum in the marketplace. However, a price adjustment at the peak season stimulated a significant demand surge which took AK completely by surprise and resulted in huge backorders. AK faced the risk of losing the market momentum due to the upset customers and the high cost associated with over-time production and expedited shipping. Accurate demand forecast is essential for increasing revenue and reducing cost. Identifying the drivers for demand and assessing their impact on demand can help companies better influence and stimulate demand.

I hope you enjoy the course!",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,8812
14,/learn/python-representation,Python Data Representations,Rice University,4.7,17590,990,165,"This course will continue the introduction to Python programming that started with Python Programming Essentials.  We'll learn about different data representations, including strings, lists, and tuples, that form the core of all Python programs.  We will also teach you how to access files, which will allow you to store and retrieve data within your programs. These concepts and skills will help you to manipulate data and write more complex Python programs.By the end of the course, you will be able to write Python programs that can manipulate data stored in files.  This will extend your Python programming expertise, enabling you to write a wide range of scripts using Python

This course uses Python 3.  While most Python programs continue to use Python 2, Python 3 is the future of the Python programming language. This course introduces basic desktop Python development environments, allowing you to run Python programs directly on your computer. This choice enables a smooth transition from online development environments.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,29.0,,20.0,1,19260
15,/learn/python-data-analysis,Introduction to Data Science in Python,University of Michigan,4.5,696169,23651,5311,"This course will introduce the learner to the basics of the python programming environment, including fundamental python programming techniques such as lambdas, reading and manipulating csv files, and the numpy library. The course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the Series and DataFrame as the central data structures for data analysis, along with tutorials on how to use functions such as groupby, merge, and pivot tables effectively. By the end of this course, students will be able to take tabular data, clean it, manipulate it, and run basic inferential statistical analyses. This course should be taken before any of the other Applied Data Science with Python courses: Applied Plotting, Charting & Data Representation in Python, Applied Machine Learning in Python, Applied Text Mining in Python, Applied Social Network Analysis in Python.",30,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,31.0,13.0,27.0,1,587430
16,/learn/descriptive-statistics-statistical-distributions-business-application,"Basic Data Descriptors, Statistical Distributions, and Application to Business Decisions",Rice University,4.7,68685,1959,329,"The ability to understand and apply Business Statistics is becoming increasingly important in the industry. A good understanding of Business Statistics is a requirement to make correct and relevant interpretations of data. Lack of knowledge could lead to erroneous decisions which could potentially have negative consequences for a firm. This course is designed to introduce you to Business Statistics. We begin with the notion of descriptive statistics, which is summarizing data using a few numbers. Different categories of descriptive measures are introduced and discussed along with the Excel functions to calculate them. The notion of probability or uncertainty is introduced along with the concept of a sample and population data using relevant business examples. This leads us to various statistical distributions along with their Excel functions which are then used to model or approximate business processes. You get to apply these descriptive measures of data and various statistical distributions using easy-to-follow Excel based examples which are demonstrated throughout the course.To successfully complete course assignments, students must have access to Microsoft Excel. 
________________________________________
WEEK 1
Module 1: Basic Data Descriptors
In this module you will get to understand, calculate and interpret various descriptive or summary measures of data. These descriptive measures summarize and present data using a few numbers. Appropriate Excel functions to do these calculations are introduced and demonstrated.

Topics covered include:
•	Categories of descriptive data
•	Measures of central tendency, the mean, median, mode, and their interpretations and calculations
•	Measures of spread-in-data, the range, interquartile-range, standard deviation and variance
•	Box plots
•	Interpreting the standard deviation measure using the rule-of-thumb and Chebyshev’s theorem
________________________________________
WEEK 2
Module 2: Descriptive Measures of Association, Probability, and Statistical Distributions
This module presents the covariance and correlation measures and their respective Excel functions. You get to understand the notion of causation versus correlation. The module then introduces the notion of probability and random variables and starts introducing statistical distributions.

Topics covered include:
•	Measures of association, the covariance and correlation measures; causation versus correlation
•	Probability and random variables; discrete versus continuous data
•	Introduction to statistical distributions
________________________________________
WEEK 3
Module 3: The Normal Distribution
This module introduces the Normal distribution and the Excel function to calculate probabilities and various outcomes from the distribution. 

Topics covered include:
•	Probability density function and area under the curve as a measure of probability
•	The Normal distribution (bell curve), NORM.DIST, NORM.INV functions in Excel
________________________________________
WEEK 4
Module 4: Working with Distributions, Normal, Binomial, Poisson
In this module, you'll see various applications of the Normal distribution. You will also get introduced to the Binomial and Poisson distributions. The Central Limit Theorem is introduced and explained in the context of understanding sample data versus population data and the link between the two.

Topics covered include:
•	Various applications of the Normal distribution
•	The Binomial and Poisson distributions
•	Sample versus population data; the Central Limit Theorem",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,39367
17,/learn/healthcare-data-quality-governance,Healthcare Data Quality and Governance,"University of California, Davis",4.5,8837,39,8,"Career prospects are bright for those qualified to work with healthcare data or as Health Information Management (HIM) professionals. Perhaps you work in data analytics but are considering a move into healthcare, or you work in healthcare but are considering a transition into a new role. In either case, Healthcare Data Quality and Governance will provide insight into how valuable data assets are protected to maintain data quality. This serves care providers, patients, doctors, clinicians, and those who carry out the business of improving health outcomes. ""Big Data"" makes headlines, but that data must be managed to maintain quality. High-quality data is one of the most valuable assets gathered and used by any business. This holds greater significance in healthcare where the maintenance and governance of data quality directly impact people’s lives. This course will explain how data quality is improved and maintained. You’ll learn why data quality matters, then see how healthcare professionals monitor, manage and improve data quality. You’ll see how human and computerized systems interact to sustain data quality through data governance. You’ll discover how to measure data quality with metadata, tracking data provenance, validating and verifying data, along with a communication framework commonly used in healthcare settings. 

This knowledge matters because high-quality data will be transformed into valuable insights that can save lives, reduce costs, to improve healthcare and make it more accessible and affordable. You will make yourself more of an asset in the healthcare field by what you gain from this course.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,4066
18,/learn/foundations-big-data-analysis-sql,Foundations for Big Data Analysis with SQL,Cloudera,4.8,62437,758,192,"In this course, you'll get a big-picture view of using SQL for big data, starting with an overview of data, database systems, and the common querying language (SQL). Then you'll learn the characteristics of big data and SQL tools for working on big data platforms. You'll also install an exercise environment (virtual machine) to be used through the specialization courses, and you'll have an opportunity to do some initial exploration of databases and tables in that environment.By the end of the course, you will be able to
• distinguish operational from analytic databases, and understand how these are applied in big data;
• understand how database and table design provides structures for working with data;
• appreciate how differences in volume and variety of data affects your choice of an appropriate database system;
• recognize the features and benefits of SQL dialects designed to work with big data systems for storage and analysis; and 
• explore databases and tables in a big data platform.

To use the hands-on environment for this course, you need to download and install a virtual machine and the software on which to run it. Before continuing, be sure that you have access to a computer that meets the following hardware and software requirements:
• Windows, macOS, or Linux operating system (iPads and Android tablets will not work)
• 64-bit operating system (32-bit operating systems will not work)
• 8 GB RAM or more
• 25GB free disk space or more
• Intel VT-x or AMD-V virtualization support enabled (on Mac computers with Intel processors, this is always enabled;
on Windows and Linux computers, you might need to enable it in the BIOS)
• For Windows XP computers only: You must have an unzip utility such as 7-Zip or WinZip installed (Windows XP’s built-in unzip utility will not work)",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,14.0,,0,33380
19,/learn/data-science-k-means-clustering-python,Foundations of Data Science: K-Means Clustering in Python,University of London,4.6,105028,296,98,"Organisations all around the world are using data to predict behaviours and extract valuable real-world insights to inform decisions. Managing and analysing big data has become an essential part of modern finance, retail, marketing, social science, development and research, medicine and government.This MOOC, designed by an academic team from Goldsmiths, University of London, will quickly introduce you to the core concepts of Data Science to prepare you for intermediate and advanced Data Science courses. It focuses on the basic mathematics, statistics and programming skills that are necessary for typical data analysis tasks. 

You will consider these fundamental concepts on an example data clustering task, and you will use this example to learn basic programming skills that are necessary for mastering Data Science techniques. During the course, you will be asked to do a series of mathematical and programming exercises and a small data clustering project for a given dataset.",29,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,,,,1,15242
20,/learn/machine-learning-asset-management-alternative-data,Python and Machine-Learning for Asset Management with Alternative Data Sets,EDHEC Business School,4.4,20973,182,44,"Over-utilization of market and accounting data over the last few decades has led to portfolio crowding, mediocre performance and systemic risks, incentivizing financial institutions which are looking for an edge to quickly adopt alternative data as a substitute to traditional data. This course introduces the core concepts around alternative data, the most recent research in this area, as well as practical portfolio examples and actual applications. The approach of this course is somewhat unique because while the theory covered is still a main component, practical lab sessions and examples of working with alternative datasets are also key. This course is fo you if you are aiming at carreers prospects as a data scientist in financial markets, are looking to enhance your analytics skillsets to the financial markets, or if you are interested in cutting-edge technology and research as  they apply to big data. The required background is: Python programming, Investment theory , and Statistics. This course will enable you to learn new data and research techniques applied to the financial markets while strengthening data science and python skills.",19,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,8997
21,/learn/sequence-models-in-nlp,Natural Language Processing with Sequence Models,DeepLearning.AI,4.5,117275,656,134,"In Course 3 of the Natural Language Processing Specialization, offered by deeplearning.ai, you will:a) Train a neural network with GLoVe word embeddings to perform sentiment analysis of tweets,
b) Generate synthetic Shakespeare text using a Gated Recurrent Unit (GRU) language model,
c) Train a recurrent neural network to perform named entity recognition (NER) using LSTMs with linear layers, and 
d) Use so-called ‘Siamese’ LSTM models to compare questions in a corpus and identify those that are worded differently but have the same meaning. 
 
Please make sure that you’ve completed Course 2 and are familiar with the basics of TensorFlow. If you’d like to prepare additionally, you can take Course 1: Neural Networks and Deep Learning of the Deep Learning Specialization.

By the end of this Specialization, you will have designed NLP applications that perform question-answering and sentiment analysis, created tools to translate languages and summarize text, and even built a chatbot!

This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. Łukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.",19,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,27846
22,/learn/intro-tensorflow,Introduction to TensorFlow,Google Cloud,4.4,38554,2547,310,"This course is focused on using the flexibility and “ease  of use” of TensorFlow 2.x and Keras to build, train, and deploy machine learning models.  You will learn about the TensorFlow 2.x API hierarchy and will get to know the main components of TensorFlow through hands-on exercises.  We will introduce you to working with datasets and feature columns. You will learn how to design and build a TensorFlow 2.x input data pipeline.  You will get hands-on practice loading csv data, numPy arrays, text data, and images using tf.Data.Dataset. You will also get hands-on practice creating numeric, categorical, bucketized, and hashed feature columns.We will introduce you to the Keras Sequential API and the Keras Functional API to show you how to create deep learning models.  We’ll talk about activation functions, loss, and optimization.  Our Jupyter Notebooks hands-on labs offer you the opportunity to build basic linear regression, basic logistic regression, and advanced logistic regression machine learning models.  You will learn how to train, deploy, and productionalize machine learning models at scale with Cloud AI Platform.",19,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,31.0,,25.0,0,35301
23,/learn/big-data-introduction-ar,مقدمة عن البيانات الضخمة,University of California San Diego,4.6,4202,73,27,"مقدمة عن البيانات الضخمةهل أنت مهتم بزيادة معرفتك بأبرز سمات البيانات الضخمة؟ هذه الدورة التدريبية مخصصة للمستجدين في علوم البيانات والمهتمين بفهم أسباب ظهور عصر البيانات الضخمة. فهي مخصصة لمن يريدون الإلمام بالمصطلحات والمفاهيم الأساسية الخاصة بمشكلات البيانات الضخمة وتطبيقاتها وأنظمتها. إنها لمن يريدون البدء في التفكير بشأن الطريقة التي يمكن أن تفيدهم البيانات الضخمة بها في عملهم أو مسيرتهم المهنية. حيث تتعرض مقدمة عن أحد أكثر أطر العمل الشائعة ألا وهو Hadoop، والذي زاد من سهولة تحليل البيانات الضخمة وإمكانية الوصول إليها، فقد زاد من احتمالية تطوير البيانات الضخمة لعالمنا!

وفي نهاية الدورة التدريبية، ستتمكن مما يلي:

*  وصف أبرز سمات البيانات الضخمة بما في ذلك الأمثلة على مشكلات البيانات الضخمة على أرض الواقع التي تتضمن ثلاثة مصادر أساسية للبيانات الضخمة وهي الأفراد والمؤسسات وأدوات الاستشعار.

* شرح خصائص البيانات الضخمة التي تبدأ بالحرف V مثل (volume (الحجم)، وvelocity (السرعة)، وvariety (التنوع)، وveracity (الصحة)، وvalence (التكافؤ)، وvalue (القيمة)) ولماذا تؤثر كل خاصية من تلك الخصائص في جمع البيانات ومتابعتها وتخزينها وتحليلها والإبلاغ عنها

* الاستفادة بقيمة البيانات الضخمة عن طريق استخدام عملية مكونة من 5 خطوات لهيكلة تحليلك. 

* تحديد المشكلات التي تندرج تحت البيانات الضخمة والتي لا تندرج تحتها، والقدرة على إعادة تشكيل مشكلات البيانات الضخمة مثل مسائل علوم البيانات.

* تقديم تفسير للمكونات الهندسية والنماذج البرمجية التي تستخدم في التحليل القابل للتوسيع للبيانات الضخمة.

* تلخيص ميزات المكونات الأساسية لمكدس Hadoop وقيمتها بما في ذلك مورد YARN ونظام إدارة الوظائف، ونظام ملفات HDFS، ونموذج برمجة MapReduce.

* تثبيت البرامج وتشغيلها باستخدام إطار عمل Hadoop!

هذه الدورة التدريبية موجهة للمستجدين في علوم البيانات.  لا يلزم توافر خبرة برمجية مسبقة، على الرغم من ضرورة توافر القدرة على تثبيت التطبيقات واستخدام الأجهزة الظاهرية لإنجاز الواجبات العملية.  

متطلبات الأجهزة:
(أ) معالج رباعي النواة (يوصى بمعالج يدعم ميزة VT-x أو AMD-V)، 64 بت؛ (ب) ذاكرة وصول عشوائي بحجم 8 جيجابايت؛ (ج) مساحة خالية بحجم 20 جيجابايت. 
طريقة العثور على معلومات الأجهزة: (نظام Windows): افتح النظام عن طريق الضغط على زر Start (بدء التشغيل)، وانقر بزر الفأرة الأيمن على أيقونة Computer (جهاز الكمبيوتر)، ثم انقر على Properties (خصائص)؛ (نظام Mac): افتح Overview (نظرة عامة) عن طريق الضغط على قائمة Apple والنقر على ""About This Mac."" سيتوفر الحد الأدنى من المتطلبات في معظم أجهزة الكمبيوتر ذات الذاكرة العشوائية سعة 8 جيجابايت والتي تم شراؤها في آخر 3 أعوام. وستحتاج إلى سرعة اتصال عالية بالإنترنت لأنك ستقوم بتنزيل ملفات يصل حجمها إلى 4 جيجابايت.

المتطلبات البرمجية: تعتمد هذه الدورة التدريبية على العديد من الأدوات البرمجية مفتوحة المصدر، ومنها Apache Hadoop. ويمكن تنزيل جميع البرامج المطلوبة وتثبيتها مجانًا.
تتضمن المتطلبات البرمجية ما يلي: Windows 7+ أو Mac OS X 10.10+ أو Ubuntu 14.04+ أو CentOS 6+ VirtualBox 5+.",17,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,,,,1,2155
24,/learn/econometria-basica-aplicada,Econometria Básica Aplicada,Universidade de São Paulo,4.4,15476,126,29,Buscaremos introduzir aos alunos métodos de estimação de modelos lineares que relacionam variáveis econômicas. Espera-se que o aluno seja capaz de entender modelos simples e testar hipóteses sobre os modelos de interesse.,8,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,17.0,20.0,,0,12208
25,/learn/advanced-manufacturing-process-analysis,Advanced Manufacturing Process Analysis,University at Buffalo,4.6,7710,1064,259,"Variability is a fact of life in manufacturing environments, impacting product quality and yield. Through this course, students will learn why performing advanced analysis of manufacturing processes is integral for diagnosing and correcting operational flaws in order to improve yields and reduce costs.   Gain insights into the best ways to collect, prepare and analyze data, as well as computational platforms that can be leveraged to collect and process data over sustained periods of time. Become better prepared to participate as a member of an advanced analysis team and share valuable inputs on effective implementation.    

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the fourth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal. To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,14.0,,14.0,1,17055
26,/learn/sql-data-science-capstone,SQL for Data Science Capstone Project,"University of California, Davis",3.8,16794,48,11,"Data science is a dynamic and growing career field that demands knowledge and skills-based in SQL to be successful. This course is designed to provide you with a solid foundation in applying SQL skills to analyze data and solve real business problems.Whether you have successfully completed the other courses in the Learn SQL Basics for Data Science Specialization or are taking just this course, this project is your chance to apply the knowledge and skills you have acquired to practice important SQL  querying and solve problems with data. You will participate in your own personal or professional journey to create a portfolio-worthy piece from start to finish. You will choose a dataset and develop a project proposal. You will explore your data and perform some initial statistics you have learned through this specialization. You will uncover analytics for qualitative data and consider new metrics that make sense from the patterns that surface in your analysis. You will put all of your work together in the form of a presentation where you will tell the story of your findings. Along the way, you will receive feedback through the peer-review process. This community of fellow learners will provide additional input to help you refine your approach to data analysis with SQL and present your findings to clients and management.",35,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,14600
27,/learn/advanced-manufacturing-enterprise,Advanced Manufacturing Enterprise,University at Buffalo,4.6,9670,564,128,"Enterprises that seek to become proficient in advanced manufacturing must incorporate manufacturing management tools and integrate data throughout the supply chain to be successful. This course will make students aware of what a digitally connected enterprise is, as they learn about the operational complexity of enterprises, business process optimization and the concept of an integrated product-process-value chain. Students will become acquainted with the available tools, technologies and techniques for aggregation and integration of data throughout the manufacturing supply chain and entire product life-cycle. They will receive foundational knowledge to assist in efforts to facilitate design, planning, and production scheduling of goods and services by applying product life cycle data.  

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the sixth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal. To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,75.0,,1,11854
28,/learn/feature-engineering-es,Feature Engineering en Español,Google Cloud,4.5,5171,24,8,"Le damos la bienvenida a los foros de discusión. Aquí podrá hacer preguntas, debatir ideas y buscar a otras personas con sus mismos objetivos. Explore las conversaciones populares que aparecen a continuación o consulte otros foros en la barra lateral.",14,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,,,,0,2300
29,/learn/executive-data-science-capstone,Executive Data Science Capstone,Johns Hopkins University,4.7,3426,1474,321,"The Executive Data Science Capstone, the specialization’s culminating project, is an opportunity for people who have completed all four EDS courses to apply what they've learned to a real-world scenario developed in collaboration with Zillow, a data-driven online real estate and rental marketplace, and DataCamp, a web-based platform for data science programming. Your task will be to lead a virtual data science team and make key decisions along the way to demonstrate that you have what it takes to shepherd a complex analysis project from start to finish.  For the final project, you will prepare and submit a presentation, which will be evaluated and graded by your fellow capstone participants.Course cover image by Luckey_sun. Creative Commons BY-SA https://flic.kr/p/bx1jvU",2,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,14.0,34.0,1,12788
30,/learn/roadmap-success-digital-manufacturing-design,Roadmap to Success in Digital Manufacturing & Design ,University at Buffalo,4.7,3134,232,42,"Learners will create a roadmap to achieve their own personal goals related to the digital manufacturing and design (DM&D) profession, which will help them leverage relevant opportunities. The culminating project provides a tangible element to include in their professional portfolios that showcases their knowledge of Industry 4.0.This project is part of the Digital Manufacturing and Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0. To learn more about the specialization and its courses, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,6321
31,/learn/ibm-ai-workflow-data-analysis-hypothesis-testing,AI Workflow: Data Analysis and Hypothesis Testing,IBM,4.2,7080,84,13,"This is the second course in the IBM AI Enterprise Workflow Certification specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  In this course you will begin your work for a hypothetical streaming media company by doing exploratory data analysis (EDA).  Best practices for data visualization, handling missing data, and hypothesis testing will be introduced to you as part of your work.  You will learn techniques of estimation with probability distributions and extending these estimates to apply null hypothesis significance tests. You will apply what you learn through two hands on case studies: data visualization and multiple testing using a simple pipeline.
 
By the end of this course you should be able to:
1.  List several best practices concerning EDA and data visualization
2.  Create a simple dashboard in Watson Studio
3.  Describe strategies for dealing with missing data
4.  Explain the difference between imputation and multiple imputation
5.  Employ common distributions to answer questions about event probabilities
6.  Explain the investigative role of hypothesis testing in EDA
7.  Apply several methods for dealing with multiple testing
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.

What skills should you have?
It is assumed that you have completed Course 1 of the IBM AI Enterprise Workflow specialization and have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,50.0,,,0,2357
32,/learn/excel-analysis,Problem Solving with Excel ,PwC,4.7,112168,4691,845,"This course explores Excel as a tool for solving business problems. In this course you will learn the basic functions of excel through guided demonstration. Each week you will build on your excel skills and be provided an opportunity to practice what you’ve learned. Finally, you will have a chance to put your knowledge to work in a final project.  Please note, the content in this course was developed using a Windows version of Excel 2013.  This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",20,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,24.0,15.0,27.0,0,109208
33,/learn/statistical-thinking-applied-statistics,"Statistical Thinking for Industrial Problem Solving, presented by JMP",SAS,4.8,37129,38,15,"Statistical Thinking for Industrial Problem Solving is an applied statistics course for scientists and engineers offered by JMP, a division of SAS. By completing this course, students will understand the importance of statistical thinking, and will be able to use data and basic statistical methods to solve many real-world problems. Students completing this course will be able to:•	Explain the importance of statistical thinking in solving problems
•	Describe the importance of data, and the steps needed to compile and prepare data for analysis
•	Compare core methods for summarizing, exploring and analyzing data, and describe when to apply these methods
•	Recognize the importance of statistically designed experiments in understanding cause and effect",44,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,,,,0,2601
34,/learn/computer-vision-basics,Computer Vision Basics,University at Buffalo,4.2,65807,1663,477,"By the end of this course, learners will understand what computer vision is, as well as its mission of making computers see and interpret the world as humans do, by learning core concepts of the field and receiving an introduction to human vision capabilities. They are equipped to identify some key application areas of computer vision and understand the digital imaging process. The course covers crucial elements that enable computer vision: digital signal processing, neuroscience and artificial intelligence. Topics include color, light and image formation; early, mid- and high-level vision; and mathematics essential for computer vision. Learners will be able to apply mathematical techniques to complete computer vision tasks. This course is ideal for anyone curious about or interested in exploring the concepts of computer vision. It is also useful for those who desire a refresher course in mathematical concepts of computer vision. Learners should have basic programming skills and experience (understanding of for loops, if/else statements), specifically in MATLAB (Mathworks provides the basics here: https://www.mathworks.com/learn/tutorials/matlab-onramp.html). Learners should also be familiar with the following: basic linear algebra (matrix vector operations and notation), 3D co-ordinate systems and transformations, basic calculus (derivatives and integration) and basic probability (random variables).  

Material includes online lectures, videos, demos, hands-on exercises, project work, readings and discussions. Learners gain experience writing computer vision programs through online labs using MATLAB* and supporting toolboxes.

 * A free license to install MATLAB for the duration of the course is available from MathWorks.",13,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,27.0,17.0,,1,63483
35,/learn/clinical-data-models-and-data-quality-assessments,Clinical Data Models and Data Quality Assessments,University of Colorado System,4.3,8084,51,15,"This course aims to teach the concepts of clinical data models and common data models. Upon completion of this course, learners will be able to interpret and evaluate data model designs using Entity-Relationship Diagrams (ERDs), differentiate between data models and articulate how each are used to support clinical care and data science, and create SQL statements in Google BigQuery to query the MIMIC3 clinical data model and the OMOP common data model.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,29.0,17.0,,1,4296
36,/learn/vvedeniye-dannyye,Введение в данные,Novosibirsk State University ,4.7,16628,142,26,"Этот курс - первый в специализации ""Анализ данных"". Курс будет особенно полезен тем, кто имеет небольшой опыт работы с данными, или хочет освежить знания по теории вероятностей, математической статистике и типах данных. Сначала мы вспомним основы теории вероятностей и поговорим о случайных величинах и их свойствах, об основных распределениях случайных величин. 
Затем перейдем к основным характеристикам распределений: мерам центра и мерам вариативности. Далее обсудим основные типы шкал измерения признаков, а также основные ограничения, которые тип шкалы накладывает на применимые методы анализа данных. 
Третья неделя курса посвящена графическому анализу данных и способам визуализации распределений, индивидуальных или совместных. Завершающий модуль курса посвящен выборкам и способам их формирования, а также принципам и инструментам работы с пропущенными и неопределенными значениями. 
Вы сможете применить полученные знания, выполнив небольшой проект на реальных данных, предоставленных компанией 2GIS. 
Присоединяйтесь!",16,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,,,,1,8701
37,/learn/supply-chain-analytics-essentials,Supply Chain Analytics Essentials,Rutgers the State University of New Jersey,4.5,77302,458,115,"Welcome to Supply Chain Analytics - an exciting area that is in high demand! In this introductory course to Supply Chain Analytics, I will take you on a journey to this fascinating area where supply chain management meets data analytics. You will learn real life examples on how analytics can be applied to various domains of a supply chain, from selling, to logistics, production and sourcing, to generate a significant social / economic impact. You will also learn job market trend, job requirement and preparation. Lastly, you will master a job intelligence tool to find preferred job(s) by region, industry and company. 

Upon completing this course, you will

1. Understand why analytics is critical to supply chain management and its financial / economic impact.
2. See the pain points of a supply chain and how analytics may relieve them.
3. Learn supply chain analytics job opportunities, and use a job intelligence tool to make data-driven career decisions.

I hope you enjoy the course!",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,25.0,25.0,,1,22303
38,/learn/datascimed,Data Science in Stratified Healthcare and Precision Medicine,The University of Edinburgh,4.6,19282,212,60,"An increasing volume of data is becoming available in biomedicine and healthcare, from genomic data, to electronic patient records and data collected by wearable devices. Recent advances in data science are transforming the life sciences, leading to precision medicine and stratified healthcare. In this course, you will learn about some of the different types of data and computational methods involved in stratified healthcare and precision medicine.  You will have a hands-on experience of working with such data.  And you will learn from leaders in the field about successful case studies. 

Topics include: (i) Sequence Processing, (ii) Image Analysis, (iii) Network Modelling, (iv) Probabilistic Modelling, (v) Machine Learning, (vi) Natural Language Processing, (vii) Process Modelling and (viii) Graph Data.

Watch the course promo video here: http://edin.ac/2pn350P",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,11.0,1,13707
39,/learn/improving-statistical-questions,Improving Your Statistical Questions,Eindhoven University of Technology,4.9,8900,84,18,"This course aims to help you to ask better statistical questions when performing empirical research. We will discuss how to design informative studies, both when your predictions are correct, as when your predictions are wrong. We will question norms, and reflect on how we can improve research practices to ask more interesting questions. In practical hands on assignments you will learn techniques and tools that can be immediately implemented in your own research, such as thinking about the smallest effect size you are interested in, justifying your sample size, evaluate findings in the literature while keeping publication bias into account, performing a meta-analysis, and making your analyses computationally reproducible.If you have the time, it is recommended that you complete my course 'Improving Your Statistical Inferences' before enrolling in this course, although this course is completely self-contained.",18,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,,,,1,4739
40,/learn/machine-learning-data-analysis,Machine Learning for Data Analysis,Wesleyan University,4.2,10823,301,65,"Are you interested in predicting future outcomes using your data? This course helps you do just that! Machine learning is the process of developing, testing, and applying predictive algorithms to achieve this goal. Make sure to familiarize yourself with course 3 of this specialization before diving into these machine learning concepts. Building on Course 3, which introduces students to integral supervised machine learning concepts, this course will provide an overview of many additional concepts, techniques, and algorithms in machine learning, from basic classification to decision trees and clustering. By completing this course, you will learn how to apply, test, and interpret machine learning algorithms as alternative methods for addressing your research questions.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,36.0,17.0,29.0,1,41079
41,/learn/r-programming-environment,The R Programming Environment,Johns Hopkins University,4.4,51341,1088,295,"This course provides a rigorous introduction to the R programming language, with a  particular focus on using R for software development in a data science setting. Whether you are part of a data science team or working individually within a community of developers, this course will give you the knowledge of R needed to make useful contributions in those settings. As the first course in the Specialization, the course provides the essential foundation of R needed for the following courses. We cover basic R concepts and language fundamentals, key concepts like tidy data and related ""tidyverse"" tools, processing and manipulation of complex and large datasets, handling textual data, and basic data science tasks. Upon completing this course, learners will have fluency at the R console and will be able to create tidy datasets from a wide range of possible data sources.",27,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,42.0,12.0,47.0,1,46017
42,/learn/ai-deep-learning-capstone,AI Capstone Project with Deep Learning ,IBM,4.5,21577,319,59,"In this capstone, learners will apply their deep learning knowledge and expertise to a real world challenge.  They will use a library of their choice to develop and test a deep learning model. They will load and pre-process data for a real problem, build the model and validate it. Learners  will then present a project report to demonstrate the validity of their model and their proficiency in the field of Deep Learning.Learning Outcomes:
•	determine what kind of deep learning method to use in which situation
•	know how to build a deep learning model to solve a real problem 
•	master the process of creating  a deep learning pipeline 
•	apply knowledge of deep learning to improve models using real data
•	demonstrate ability to present and communicate outcomes of deep learning projects",16,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,7534
43,/learn/statistics-for-data-science-python,Statistics for Data Science with Python,IBM,4.6,55613,82,22,"This Statistics for Data Science course is designed to introduce you to the basic principles of statistical methods and procedures used for data analysis. After completing this course you will have practical knowledge of crucial topics in statistics including  - data gathering, summarizing data using descriptive statistics, displaying and visualizing data, examining relationships between variables, probability distributions, expected values, hypothesis testing, introduction to ANOVA (analysis of variance), regression and correlation analysis. You will take a hands-on approach to statistical analysis using Python and Jupyter Notebooks – the tools of choice for Data Scientists and Data Analysts. At the end of the course, you will complete a project to apply various concepts in the course to a Data Science problem involving a real-life inspired scenario and demonstrate an understanding of the foundational statistical thinking and reasoning. The focus is on developing a clear understanding of the different 
approaches for different data types, developing an intuitive understanding, making appropriate assessments of the proposed methods, using Python to analyze our data, and interpreting the output accurately. 

This course is suitable for a variety of professionals and students intending to start their journey in data and statistics-driven roles such as Data Scientists, Data Analysts, Business Analysts, Statisticians, and Researchers. It does not require any computer science or statistics background.  We strongly recommend taking the Python for Data Science course before starting this course to get familiar with the Python programming language,  Jupyter notebooks, and libraries. An optional refresher on Python is also provided.

After completing this course, a learner will be able to:
✔Calculate and apply measures of central tendency and measures of dispersion to grouped and ungrouped data.
✔Summarize, present, and visualize data in a way that is clear, concise, and provides a practical insight for non-statisticians needing the results.
✔Identify appropriate hypothesis tests to use for common data sets.
✔Conduct hypothesis tests, correlation tests, and regression analysis.
✔Demonstrate proficiency in statistical analysis using Python and Jupyter Notebooks.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,4109
44,/learn/custom-models-layers-loss-functions-with-tensorflow,"Custom Models, Layers, and Loss Functions with TensorFlow",DeepLearning.AI,4.9,95241,342,83,"In this course, you will:• Compare Functional and Sequential APIs, discover new models you can build with the Functional API, and build a model that produces multiple outputs including a Siamese network.
• Build custom loss functions (including the contrastive loss function used in a Siamese network) in order to measure how well a model is doing and help your neural network learn from training data. 
• Build off of existing standard layers to create custom layers for your models, customize a network layer with a lambda layer, understand the differences between them, learn what makes up a custom layer, and explore activation functions. 
• Build off of existing models to add custom functionality, learn how to define your own custom class instead of using the Functional or Sequential APIs, build models that can be inherited from the TensorFlow Model class, and build a residual network (ResNet) through defining a custom model class. 


The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture and tools that help them create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",31,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,8759
45,/learn/building-ai-applications,Building AI Applications with Watson APIs,IBM,4.2,22632,541,124,"A learner will be able to write an application that leverages multiple Watson AI services (Discovery, Speech to Text, Assistant, and Text to Speech). By the end of the course, they’ll learn best practices of combining Watson services, and how they can build interactive information retrieval systems with Discovery + Assistant.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,9800
46,/learn/simple-regression-analysis-public-health,Simple Regression Analysis in Public Health ,Johns Hopkins University,4.7,19610,243,47,"Biostatistics is the application of statistical reasoning to the life sciences, and it's the key to unlocking the data gathered by researchers and the evidence presented in the scientific public health literature. In this course, we'll focus on the use of simple regression methods to determine the relationship between an outcome of interest and a single predictor via a linear equation. Along the way, you'll be introduced to a variety of methods, and you'll practice interpreting data and performing calculations on real data from published studies.  Topics include logistic regression, confidence intervals, p-values, Cox regression, confounding, adjustment, and effect modification.",14,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,1,7497
47,/learn/introduction-gis-mapping,Introduction to GIS Mapping,University of Toronto,4.9,83632,1343,446,"Get started learning about the fascinating and useful world of geographic information systems (GIS)! In this first course of the specialization GIS, Mapping, and Spatial Analysis, you'll learn about what a GIS is, how to get started with the software yourself, how things we find in the real world can be represented on a map, how we record locations using coordinates, and how we can make a two-dimensional map from a three-dimensional Earth. In the course project, you will create your own GIS data by tracing geographic features from a satellite image for a location and theme of your choice. This course will give you a strong foundation in mapping and GIS that will give you the understanding you need to start working with GIS, and to succeed in the other courses in this specialization.This course is for anyone who wants to learn about mapping and GIS. You don't have to have any previous experience - just your curiosity! The course includes both practical software training and explanations of the concepts you need to know to make informed decisions as you start your journey to becoming a GIS analyst.

You will need a Windows computer with ArcGIS Desktop installed. (software is not provided)",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,18.0,20.0,,1,36723
48,/learn/data-preparation,Prepare Data for Exploration,Google,4.8,850567,200,27,"This is the third course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. As you continue to build on your understanding of the topics from the first two courses, you’ll also be introduced to new topics that will help you gain practical data analytics skills. You’ll learn how to use tools like spreadsheets and SQL to extract and make use of the right data for your objectives and how to organize and protect your data. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Find out how analysts decide which data to collect for analysis.
 - Learn about structured and unstructured data, data types, and data formats.
 - Discover how to identify different types of bias in data to help ensure data credibility. 
 - Explore how analysts use spreadsheets and SQL with databases and data sets.
 - Examine open data and the relationship between and importance of data ethics and data privacy.
 - Gain an understanding of how to access databases and extract, filter, and sort the data they contain.
 - Learn the best practices for organizing data and keeping it secure.",23,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,0,7663
49,/learn/python-machine-learning,Applied Machine Learning in Python,University of Michigan,4.6,262756,7232,1315,"This course will introduce the learner to applied machine learning, focusing more on the techniques and methods than on the statistics behind these methods. The course will start with a discussion of how machine learning is different than descriptive statistics, and introduce the scikit learn toolkit through a tutorial. The issue of dimensionality of data will be discussed, and the task of clustering data, as well as evaluating those clusters, will be tackled. Supervised approaches for creating predictive models will be described, and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability (e.g. cross validation, overfitting). The course will end with a look at more advanced techniques, such as building ensembles, and practical limitations of predictive models. By the end of this course, students will be able to identify the difference between a supervised (classification) and unsupervised (clustering) technique, identify which technique they need to apply for a particular dataset and need, engineer features to meet that need, and write python code to carry out an analysis. This course should be taken after Introduction to Data Science in Python and Applied Plotting, Charting & Data Representation in Python and before Applied Text Mining in Python and Applied Social Analysis in Python.",34,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,30.0,11.0,30.0,1,229569
50,/learn/machine-learning,Machine Learning,Stanford University,4.9,7254807,157748,40394,"Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.",60,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,32.0,,33.0,1,4047733
51,/learn/data-collection-framework,Framework for Data Collection and Analysis,"University of Maryland, College Park",4.2,13167,561,134,"This course will provide you with an overview over existing data products and a good understanding of the data collection landscape. With the help of various examples you will learn how to identify which data sources likely matches your research question, how to turn your research question into measurable pieces, and how to think about an analysis plan. Furthermore this course will provide you with a general framework that allows you to not only understand each step required for a successful data collection and analysis, but also help you to identify errors associated with different data sources. You will learn some metrics to quantify each potential error, and thus you will have tools at hand to describe the quality of a data source. Finally we will introduce different large scale data collection efforts done by private industry and government agencies, and review the learned concepts through these examples. This course is suitable for beginners as well as those that know about one particular data source, but not others, and are looking for a general framework to evaluate data products.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,19.0,,20.0,1,21520
52,/learn/python-genomics,Python for Genomic Data Science,Johns Hopkins University,4.3,44233,1279,242,This class provides an introduction to the Python programming language and the iPython notebook. This is the third course in the Genomic Big Data Science Specialization from Johns Hopkins University.,9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,26.0,,31.0,1,39696
53,/learn/introduction-to-data-engineering,Introduction to Data Engineering,IBM,4.7,80199,37,9,"This course introduces you to the core concepts, processes, and tools you need to know in order to get a foundational knowledge of data engineering. You will gain an understanding of the modern data ecosystem and the role Data Engineers, Data Scientists, and Data Analysts play in this ecosystem. The Data Engineering Ecosystem includes several different components. It includes disparate data types, formats, and sources of data. Data Pipelines gather data from multiple sources, transform it into analytics-ready data, and make it available to data consumers for analytics and decision-making. Data repositories, such as relational and non-relational databases, data warehouses, data marts, data lakes, and big data stores process and store this data. Data Integration Platforms combine disparate data into a unified view for the data consumers. You will learn about each of these components in this course. You will also learn about Big Data and the use of some of the Big Data processing tools. 

A typical Data Engineering lifecycle includes architecting data platforms, designing data stores, and gathering, importing, wrangling, querying, and analyzing data. It also includes performance monitoring and finetuning to ensure systems are performing at optimal levels. In this course, you will learn about the data engineering lifecycle. You will also learn about security, governance, and compliance. 

Data Engineering is recognized as one of the fastest-growing fields today. The career opportunities available in the field and the different paths you can take to enter this field are discussed in the course. 

The course also includes hands-on labs that guide you to create your IBM Cloud Lite account, provision a database instance, load data into the database instance, and perform some basic querying operations that help you understand your dataset.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2700
54,/learn/neural-networks-deep-learning,Neural Networks and Deep Learning,DeepLearning.AI,4.9,1668898,104371,20866,"In the first course of the Deep Learning Specialization, you will study the foundational concept of neural networks and deep learning. By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",22,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,33.0,10.0,33.0,0,933282
55,/learn/digital-thread-components,Digital Thread: Components,University at Buffalo,4.6,7327,713,123,"This course will help you recognize how the ""digital thread"" is the backbone of the digital manufacturing and design (DM&D) transformation, turning manufacturing processes from paper-based to digital-based. You will have a working understanding of the digital thread – the stream that starts at product concept and continues to accumulate information and data throughout the product’s life cycle – and identify opportunities to leverage it. Gain an understanding of how ""the right information, in the right place, at the right time"" should flow. This is one of the keys to unlocking the potential of a digital design process. Acknowledging this will enable you to be more involved in a product’s development cycle, and to help a company become more flexible. 

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the second course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal. To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,10.0,33.0,1,9835
56,/learn/sql-for-data-science,SQL for Data Science,"University of California, Davis",4.6,696867,9229,2411,"As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. This is a data scientist, “part mathematician, part computer scientist, and part trend spotter” (SAS Institute, Inc.). According to Glassdoor, being a data scientist is the best job in America; with a median base salary of $110,000 and thousands of job openings at a time. The skills necessary to be a good data scientist include being able to retrieve and work with data, and to do that you need to be well versed in SQL, the standard language for communicating with database systems.This course is designed to give you a primer in the fundamentals of SQL and working with data so that you can begin analyzing it for data science purposes. You will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization. This course starts with the basics and assumes you do not have any knowledge or skills in SQL. It will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables.  You'll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results. 

You will create new tables and be able to move data into them. You will learn common operators and how to combine the data. You will use case statements and concepts like data governance and profiling. You will discuss topics on data, and practice using real-world programming assignments. You will interpret the structure, meaning, and relationships in source data and use SQL as a professional to shape your data for targeted analysis purposes. 

Although we do not have any specific prerequisites or software requirements to take this course, a simple text editor is recommended for the final project. So what are you waiting for? This is your first step in landing a job in the best occupation in the US and soon the world!",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,26.0,11.0,28.0,1,302468
57,/learn/data-driven-astronomy,Data-driven Astronomy,The University of Sydney,4.8,28890,999,300,"Science is undergoing a data explosion, and astronomy is leading the way. Modern telescopes produce terabytes of data per observation, and the simulations required to model our observable Universe push supercomputers to their limits. To analyse this data scientists need to be able to think computationally to solve problems. In this course you will investigate the challenges of working with large datasets: how to implement algorithms that work; how to use databases to manage your data; and how to learn from your data with machine learning tools. The focus is on practical skills - all the activities will be done in Python 3, a modern programming language used throughout astronomy.Regardless of whether you’re already a scientist, studying to become one, or just interested in how modern astronomy works ‘under the bonnet’, this course will help you explore astronomy: from planets, to pulsars to black holes.

Course outline:
Week 1: Thinking about data
- Principles of computational thinking
- Discovering pulsars in radio images

Week 2: Big data makes things slow
- How to work out the time complexity of algorithms
- Exploring the black holes at the centres of massive galaxies

Week 3: Querying data using SQL
- How to use databases to analyse your data
- Investigating exoplanets in other solar systems

Week 4: Managing your data
- How to set up databases to manage your data
- Exploring the lifecycle of stars in our Galaxy

Week 5: Learning from data: regression
- Using machine learning tools to investigate your data
- Calculating the redshifts of distant galaxies

Week 6: Learning from data: classification
- Using machine learning tools to classify your data
- Investigating different types of galaxies

Each week will also have an interview with a data-driven astronomy expert.

Note that some knowledge of Python is assumed, including variables, control structures, data structures, functions, and working with files.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17.0,,23.0,1,22441
58,/learn/gcp-creating-bigquery-datasets-visualizing-insights,Creating New BigQuery Datasets and Visualizing Insights,Google Cloud,4.6,36740,1201,120,"This is the second course in the Data to Insights specialization. Here we will cover how to ingest new external datasets into BigQuery and  visualize them with Google Data Studio. We will also cover intermediate SQL concepts like multi-table JOINs and UNIONs which will allow you to analyze data across multiple data sources.Note: Even if you have a background in SQL, there are BigQuery specifics (like handling query cache and table wildcards) that may be new to you.

>>> By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,43.0,14.0,40.0,0,14701
59,/learn/python-databases,Using Databases with Python,University of Michigan,4.8,346024,19380,2935,"This course will introduce students to the basics of the Structured Query Language (SQL) as well as basic database design for storing data as part of a multi-step data gathering, analysis, and processing effort.  The course will use SQLite3 as its database.  We will also build web crawlers and multi-step data gathering and visualization processes.  We will use the D3.js library to do basic data visualization.  This course will cover Chapters 14-15 of the book “Python for Everybody”. To succeed in this course, you should be familiar with the material covered in Chapters 1-13 of the textbook and the first three courses in this specialization. This course covers Python 3.",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,34.0,14.0,34.0,1,366077
60,/learn/spark-sql,Distributed Computing with Spark SQL,"University of California, Davis",4.5,38684,279,70,"This course is for students with SQL experience and now want to take the next step in gaining familiarity with distributed computing using Spark. Students will gain an understanding of when to use Spark and how Spark as an engine uniquely combines Data and AI technologies at scale. The four modules build on one another and by the end of the course the student will understand: Spark architecture, Spark DataFrame, optimizing reading/writing data, and how to build a machine learning model. The first module will introduce Spark, including how Spark works with distributed computing and what are Spark Dataframes. Module 2 covers the core concepts of Spark such as storage vs. computing, caching, partitions and Spark UI. The third module looks at Engineering Data Pipelines covering connecting to databases, schemas and type, file formats and writing good data. The final module looks at the application of Spark with Machine Learning through the business use case, a short introduction to what machine learning is, building and applying models and a final course conclusion. By understanding when to use Spark, either scaling out when the model or data is too large to process on a single machine, or having a need to simply speed up to get faster results, students will hone their SQL skills and become a more adept Data Scientist.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,18215
61,/learn/launching-machine-learning,Launching into Machine Learning,Google Cloud,4.6,41442,3999,459,"Starting from a history of machine learning, we discuss why neural networks today perform so well in a variety of data science problems. We then discuss how to set up a supervised learning problem and find a good solution using gradient descent. This involves creating datasets that permit generalization; we talk about methods of doing so in a repeatable way that supports experimentation.Course Objectives:
Identify why deep learning is currently popular
Optimize and evaluate models using loss functions and performance metrics
Mitigate common problems that arise in machine learning
Create repeatable and scalable training, evaluation, and test datasets",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,36.0,23.0,37.0,0,34704
62,/learn/smart-analytics-machine-learning-ai-gcp,"Smart Analytics, Machine Learning, and AI on GCP",Google Cloud,4.6,42983,922,117,"Incorporating machine learning into data pipelines increases the ability of businesses to extract insights from their data. This course covers several ways machine learning can be included in data pipelines on Google Cloud Platform depending on the level of customization required. For little to no customization, this course covers AutoML. For more tailored machine learning capabilities, this course introduces AI Platform Notebooks and BigQuery Machine Learning. Also, this course covers how to productionalize machine learning solutions using Kubeflow. Learners will get hands-on experience building machine learning models on Google Cloud Platform using QwikLabs.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,21174
63,/learn/linear-algebra-machine-learning,Mathematics for Machine Learning: Linear Algebra,Imperial College London,4.7,456645,9547,1926,"In this course on Linear Algebra we look at what linear algebra is and how it relates to vectors and matrices. Then we look through what vectors and matrices are and how to work with them, including the knotty problem of eigenvalues and eigenvectors, and how to use these to solve problems. Finally  we look at how to use these to do fun things with datasets - like how to rotate images of faces and how to extract eigenvectors to look at how the Pagerank algorithm works.Since we're aiming at data-driven applications, we'll be implementing some of these ideas in code, not just on pencil and paper. Towards the end of the course, you'll write code blocks and encounter Jupyter notebooks in Python, but don't worry, these will be quite short, focussed on the concepts, and will guide you through if you’ve not coded before.

At the end of this course you will have an intuitive understanding of vectors and matrices that will help you bridge the gap into linear algebra problems, and how to apply these concepts to machine learning.",19,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,28.0,,28.0,1,236723
64,/learn/excel-intermediate-2,Excel Skills for Business: Intermediate II,Macquarie University,4.8,616624,5884,1342,"Spreadsheet software remains one of the most ubiquitous pieces of software used in workplaces across the world. Learning to confidently operate this software means adding a highly valuable asset to your employability portfolio. In this third course of our Excel specialization Excel Skills for Business you will delve deeper into some of the most powerful features Excel has to offer. When you have successfully completed the course you will be able toCheck for and prevent errors in spreadsheets; 
Create powerful automation in spreadsheets; 
Apply advanced formulas and conditional logic to help make informed business decisions; and
Create spreadsheets that help forecast and model data. 

Once again, we have brought together a great teaching team that will be with you every step of the way. Nicky, Prashan and myself will guide you through each week. As we are exploring these more advanced topics, we are following Alex who is an Excel consultant called in by businesses that experience issues with their spreadsheets.",29,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,18.0,10.0,15.0,1,127122
65,/learn/python-data-visualization,"Capstone: Retrieving, Processing, and Visualizing Data with Python",University of Michigan,4.7,143118,11242,1457,"In the capstone, students will build a series of applications to retrieve, process and visualize data using Python.   The projects will involve all the elements of the specialization.  In the first part of the capstone, students will do some visualizations to become familiar with the technologies in use and then will pursue their own project to visualize some other data that they have or can find.  Chapters 15 and 16 from the book “Python for Everybody” will serve as the backbone for the capstone. This course covers Python 3.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,38.0,19.0,37.0,1,189302
66,/learn/developing-ai-applications-azure,Developing AI Applications on Azure,LearnQuest,4.4,20948,915,249,"This course introduces the concepts of Artificial Intelligence and Machine learning. We'll discuss machine learning types and tasks, and machine learning algorithms. You'll  explore Python as a popular programming language for machine learning solutions, including using some scientific ecosystem packages which will help you implement machine learning. Next, this course introduces the machine learning tools available in Microsoft Azure. We'll review standardized approaches to data analytics and you'll receive specific guidance on Microsoft's Team Data Science Approach. As you go through the course, we'll introduce you to Microsoft's pre-trained and managed machine learning offered as REST API's in their suite of cognitive services. We'll implement solutions using the computer vision API and the facial recognition API, and we'll do sentiment analysis by calling the natural language service.   

Using the Azure Machine Learning Service you'll create and use an Azure Machine Learning Worksace.Then you'll train your own model, and you'll deploy and test your model in the cloud. Throughout the course you will perform hands-on exercises to practice your new AI skills. By the end of this course, you will be able to create, implement and deploy machine learning models.",16,1,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,25.0,40.0,17.0,0,42146
67,/learn/machine-learning-applied,Introduction to Applied Machine Learning,Alberta Machine Intelligence Institute,4.7,11126,561,136,"This course is for professionals who have heard the buzz around machine learning and want to apply machine learning to data analysis and automation. Whether finance, medicine, engineering, business or other domains, this course will introduce you to problem definition and data preparation in a machine learning project.By the end of the course, you will be able to clearly define a machine learning problem using two approaches. You will learn to survey available data resources and identify potential ML applications. You will learn to take a business need and turn it into a machine learning application. You will prepare data for effective machine learning applications.

This is the first course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,17776
68,/learn/data-analytics-business,Introduction to Data Analytics for Business,University of Colorado Boulder,4.7,140503,2530,680,"This course will expose you to the data analytics practices executed in the business world. We will explore such key areas as the analytical process, how data is created, stored, accessed, and how the organization works with data and creates the environment in which analytics can flourish.What you learn in this course will give you a strong foundation in all the areas that support analytics and will help you to better position yourself for success within your organization. You’ll develop skills and a perspective that will make you more productive faster and allow you to become a valuable asset to your organization.

This course also provides a basis for going deeper into advanced investigative and computational methods, which you have an opportunity to explore in future courses of the Data Analytics for Business specialization.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,19.0,,33.0,1,140661
69,/learn/praktiki-sozdaniya-analiticheskikh-paneley-power-bi,Практики создания аналитических панелей в среде Microsoft Power BI,Saint Petersburg State University,4.6,10558,67,16,"Курс предназначен для опытных пользователей MS Excel, сталкивающихся с задачей создания системы показателей деятельности компании и представления их в наглядном и удобном для принятия управленческих решений. Данный курс - четвертый в рамках специализации ""Практики анализа экономических данных: от простого к сложному"".Для эффективного анализа деятельности компании необходимо выявить и создать систему показателей ее деятельности и представить их в наглядном и удобном для принятия управленческих решений виде. Четвертый курс специализации «Практики анализа данных от простого к сложному» посвящен обсуждению кейсов, связанных с таким анализом. На примере реальных задач рассматриваются возможности создания системы показателей деятельности компании, примеры эффективного представления отчетов и демонстрируется логика и технология создания аналитических панелей в среде Microsoft Power BI. Слушатель пройдет все этапы разработки информационно-аналитических панелей: от формирования требований до полной разработки дашбордов разного уровня сложности и инструментальной насыщенности. Изучение построено по принципу: от простого к сложному. Слушатель получит практические навыки разработки аналитической среды разного уровня сложности, навыки работы с данными как ресурсом для принятия решений.",10,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,,,,1,5300
70,/learn/social-media-data-analytics,Social Media Data Analytics,University of Washington,4.1,30834,256,67,"Learner Outcomes: After taking this course, you will be able to:- Utilize various Application Programming Interface (API) services to collect data from different social media sources such as YouTube, Twitter, and Flickr.
- Process the collected data - primarily structured - using methods involving correlation, regression, and classification to derive insights about the sources and people who generated that data.
- Analyze unstructured data - primarily textual comments - for sentiments expressed in them.
- Use different tools for collecting, analyzing, and exploring social media data for research and development purposes.

Sample Learner Story: Data analyst wanting to leverage social media data.
Isabella is a Data Analyst working as a consultant for a multinational corporation. She has experience working with Web analysis tools as well as marketing data. She wants to now expand into social media arena, trying to leverage the vast amounts of data available through various social media channels. Specifically, she wants to see how their clients, partners, and competitors view their products/services and talk about them. She hopes to build a new workflow of data analytics that incorporates traditional data processing using Web and marketing tools, as well as newer methods of using social media data.

Sample Job Roles requiring these skills: 
- Social Media Analyst
- Web Analyst
- Data Analyst
- Marketing and Public Relations 

Final Project Deliverable/ Artifact: The course will have a series of small assignments or mini-projects that involve data collection, analysis, and presentation involving various social media sources using the techniques learned in the class.

The course was developed by Dr. Chirag Shah while he was a faculty member at Rutgers University. He is currently a faculty member at University of Washington.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,40.0,50.0,25.0,1,32022
71,/learn/time-series-survival-analysis,Specialized Models: Time Series and Survival Analysis,IBM,4.3,30017,21,6,"This course introduces you to additional topics in Machine Learning that complement essential tasks, including forecasting and analyzing censored data. You will learn how to find analyze data with a time component and censored data that needs outcome inference. You will learn a few techniques for Time Series Analysis and Survival Analysis. The hands-on section of this course focuses on using best practices and verifying assumptions derived from Statistical Learning.By the end of this course you should be able to:
Identify common modeling challenges with time series data
Explain how to decompose Time Series data: trend, seasonality, and residuals
Explain how autoregressive, moving average, and ARIMA models work
Understand how to select and implement various Time Series models
Describe hazard and survival modeling approaches
Identify types of problems suitable for survival analysis

Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Time Series Analysis and Survival Analysis.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Supervised Machine Learning, Unsupervised Machine Learning, Probability, and Statistics.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2480
72,/learn/data-manipulation,Data Manipulation at Scale: Systems and Algorithms,University of Washington,4.3,10108,748,162,"Data analysis has replaced data acquisition as the bottleneck to evidence-based decision making --- we are drowning in it.  Extracting knowledge from large, heterogeneous, and noisy datasets requires not only powerful computing resources, but the programming abstractions to use them effectively.  The abstractions that emerged in the last decade blend ideas from parallel databases, distributed systems, and programming languages to create a new class of scalable data analytics platforms that form the foundation for data science at realistic scales.In this course, you will learn the landscape of relevant systems, the principles on which they rely, their tradeoffs, and how to evaluate their utility against your requirements. You will learn how practical systems were derived from the frontier of research in computer science and what systems are coming on the horizon.   Cloud computing, SQL and NoSQL databases, MapReduce and the ecosystem it spawned, Spark and its contemporaries, and specialized systems for graphs and arrays will be covered.

You will also learn the history and context of data science, the skills, challenges, and methodologies the term implies, and how to structure a data science project.  At the end of this course, you will be able to:

Learning Goals: 
1. Describe common patterns, challenges, and approaches associated with data science projects, and what makes them different from projects in related fields.
2. Identify and use the programming models associated with scalable data manipulation, including relational algebra, mapreduce, and other data flow models.
3. Use database technology adapted for large-scale analytics, including the concepts driving parallel databases, parallel query processing, and in-database analytics
4. Evaluate key-value stores and NoSQL systems, describe their tradeoffs with comparable systems, the details of important examples in the space, and future trends.
5. “Think” in MapReduce to effectively write algorithms for systems including Hadoop and Spark.  You will understand their limitations, design details, their relationship to databases, and their associated ecosystem of algorithms, extensions, and languages.
write programs in Spark
6. Describe the landscape of specialized Big Data systems for graphs, arrays, and streams",20,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,56985
73,/learn/mbse,MBSE: Model-Based Systems Engineering ,University at Buffalo,4.5,37773,477,127,"This Model-Based Systems Engineering (MBSE) course and the Digital Thread courses featured earlier in this specialization bring together the concepts from across digital manufacturing and design, forming a vision in which the geometry of a product is just one way of describing it. MBSE is where the model resulting from the evolution of system requirements, design, analysis, verification and validation activities is the focus of design and manufacturing. Students will gain an understanding of systems engineering, the model-based approach to design and manufacturing, the Digital Twin, and a roadmap toward a model-based enterprise.Students will be able to explain the value and expectations of systems engineering and model-based systems engineering, and the underlying motivations and opportunities represented by a model-based enterprise. They will develop the knowledge necessary to perform a baseline assessment of an organization’s potential to leverage MBSE. 

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the eighth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal. To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,20.0,25.0,33.0,1,13639
74,/learn/znakomstvo-r-bazovaya-statistika,Знакомство с R и базовая статистика,Saint Petersburg State University,4.7,17767,62,17,"Статистическая обработка данных и визуализация результатов анализа - это неизбежный этап работы с данными, полученными в различных областях естественных наук, в социологии, психологии или экономике. В этом курсе мы подробно разберем основы статистики и познакомимся с основами языка статистического программирования R. Мы научим вас гибко использовать средства визуализации (диаграммы, графики и т.п.), чтобы сделать результаты анализа максимально доступными и понятными.  Вы научитесь рассчитывать основные описательные статистики: медиану и квантили, среднее и стандартное отклонение.  Вы познакомитесь с принципами использования теоретических распределений статистик для построения доверительных интервалов и тестирования гипотез (на примере t-критерия). Наконец, мы обсудим сложности, возникающие при множественном тестировании гипотез и научим вас преодолевать их.Этот курс для людей, начинающих знакомство со статистикой, а также для тех, кто хочет не только освоить базовые возможности языка R, но и научиться строить сложные графики.",20,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,,,,1,5661
75,/learn/bayesian,Bayesian Statistics,Duke University,3.8,34813,745,241,"This course describes Bayesian statistics, in which one's inferences about parameters or hypotheses are updated as evidence accumulates. You will learn to use Bayes’ rule to transform prior probabilities into posterior probabilities, and be introduced to the underlying theory and perspective of the Bayesian paradigm. The course will apply Bayesian methods to several practical problems, to show end-to-end Bayesian analyses that move from framing the question to building models to eliciting prior probabilities to implementing in R (free statistical software) the final posterior distribution. Additionally, the course will introduce credible regions, Bayesian comparisons of means and proportions, Bayesian regression and inference using multiple models, and discussion of Bayesian prediction.We assume learners in this course have background knowledge equivalent to what is covered in the earlier three courses in this specialization: ""Introduction to Probability and Data,"" ""Inferential Statistics,"" and ""Linear Regression and Modeling.""",35,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,17.0,,22.0,1,66298
76,/learn/linear-models-2,Advanced Linear Models for Data Science 2: Statistical Linear Models,Johns Hopkins University,4.6,8554,68,12,"Welcome to the Advanced Linear Models for Data Science Class 2: Statistical Linear Models. This class is an introduction to least squares from a linear algebraic and mathematical perspective. Before beginning the class make sure that you have the following:- A basic understanding of linear algebra and multivariate calculus.
- A basic understanding of statistics and regression models.
- At least a little familiarity with proof based mathematics.
- Basic knowledge of the R programming language.

After taking this course, students will have a firm foundation in a linear algebraic treatment of regression modeling. This will greatly augment applied data scientists' general understanding of regression models.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,19179
77,/learn/accounting-analytics,Accounting Analytics,University of Pennsylvania,4.5,40133,2706,501,"Accounting Analytics explores how financial statement data and non-financial metrics can be linked to financial performance.  In this course, taught by Wharton’s acclaimed accounting professors, you’ll learn how data is used to assess what drives financial performance and to forecast future financial scenarios. While many accounting and financial organizations deliver data, accounting analytics deploys that data to deliver insight, and this course will explore the many areas in which accounting data provides insight into other business areas including consumer behavior predictions, corporate strategy, risk management, optimization, and more. By the end of this course, you’ll understand how financial data and non-financial data interact to forecast events, optimize operations, and determine strategy. This course has been designed to help you make better business decisions about the emerging roles of accounting analytics, so that you can apply what you’ve learned to make your own business decisions and create strategy using financial data. ",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,23.0,11.0,18.0,1,89283
78,/learn/mathematics-sport,Math behind Moneyball,University of Houston,4.5,19032,86,26,"Learn how probability, math, and statistics can be used to help baseball, football and basketball teams improve, player and lineup selection as well as in game strategy.",65,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,,33.0,1,13505
79,/learn/wharton-business-financial-modeling-capstone,Wharton Business and Financial Modeling Capstone,University of Pennsylvania,4.6,27425,415,69,"In this Capstone you will recommend a business strategy based on a data model you’ve constructed. Using a data set designed by Wharton Research Data Services (WRDS), you will implement quantitative models in spreadsheets to identify the best opportunities for success and minimizing risk. Using your newly acquired decision-making skills, you will structure a decision and present this course of action in a professional quality PowerPoint presentation which includes both data and data analysis from your quantitative models.Wharton Research Data Services (WRDS) is the leading data research platform and business intelligence tool for over 30,000 corporate, academic, government and nonprofit clients in 33 countries. WRDS provides the user with one location to access over 200 terabytes of data across multiple disciplines including Accounting, Banking, Economics, ESG, Finance, Insurance, Marketing, and Statistics.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,22.0,30.0,1,5592
80,/learn/big-data-graph-analytics,Graph Analytics for Big Data,University of California San Diego,4.3,52773,1157,221,"Want to understand your data network structure and how it changes under different conditions? Curious to know how to identify closely interacting clusters within a graph? Have you heard of the fast-growing area of graph analytics and want to learn more? This course gives you a broad overview of the field of graph analytics so you can learn new ways to model, store, retrieve and analyze graph-structured data.After completing this course, you will be able to model a problem into a graph database and perform analytical tasks over the graph in a scalable manner.  Better yet, you will be able to apply these techniques to understand the significance of your data sets for your own projects.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,28.0,,42.0,1,40032
81,/learn/data-analysis-applications,Прикладные задачи анализа данных,Moscow Institute of Physics and Technology,4.4,30385,717,109,"Методы машинного обучения — будь то алгоритмы классификации или регрессии, методы кластеризации или алгоритмы понижения размерности — применяются к подготовленным данным с вычисленными признаками для решения уже сформулированной задачи. Однако специалисты по анализу данных редко оказываются в такой идеальной ситуации. Обычно перед ними ставят задачи, которые нуждаются в уточнении формулировки, выборе метрики качества и протокола тестирования итоговой модели. Данные, с которыми нужно работать, часто представлены в непригодном виде: они зашумлены, содержат ошибки и выбросы, хранятся в неудобном формате и т. д.В этом курсе мы разберем прикладные задачи из различных областей анализа данных: анализ текста и информационный поиск, коллаборативная фильтрация и рекомендательные системы, бизнес-аналитика, прогнозирование временных рядов. На их примере вы узнаете, как извлекать признаки из разнородных данных, какие при этом возникают проблемы и как их решать. Вы научитесь сводить задачу заказчика к формальной постановке задачи машинного обучения и поймёте, как проверять качество построенной модели на исторических данных и в онлайн-эксперименте. На каждой задаче мы изучим плюсы и минусы пройденных алгоритмов машинного обучения.

Прослушав этот курс, вы познакомитесь с распространенными типами прикладных задач и будете понимать схемы их решения.

Видео курса разработаны на Python 2. Задания и ноутбуки к ним адаптированы к Python 3.",28,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,79.0,40.0,73.0,0,17162
82,/learn/analyze-data,Analyze Data to Answer Questions,Google,4.7,282215,98,16,"This is the fifth course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. In this course, you’ll explore the “analyze” phase of the data analysis process. You’ll take what you’ve learned to this point and apply it to your analysis to make sense of the data you’ve collected. You’ll learn how to organize and format your data using spreadsheets and SQL to help you look at and think about your data in different ways. You’ll also find out how to perform complex calculations on your data to complete business objectives. You’ll learn how to use formulas, functions, and SQL queries as you conduct your analysis. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Learn how to organize data for analysis.
 - Discover the processes for formatting and adjusting data. 
 - Gain an understanding of how to aggregate data in spreadsheets and by using SQL.
 - Use formulas and functions in spreadsheets for data calculations.
 - Learn how to complete calculations using SQL queries.",23,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,0,3941
83,/learn/data-warehouse-bi-building,Design and Build a Data Warehouse for Business Intelligence Implementation,University of Colorado System,4.6,12458,244,34,"The capstone course, Design and Build a Data Warehouse for Business Intelligence Implementation, features a real-world case study that integrates your learning across all courses in the specialization. In response to business requirements presented in a case study, you’ll design and build a small data warehouse, create data integration workflows to refresh the warehouse, write SQL statements to support analytical and summary query requirements, and use the MicroStrategy business intelligence platform to create dashboards and visualizations.In the first part of the capstone course, you’ll be introduced to a medium-sized firm, learning about their data warehouse and business intelligence requirements and existing data sources. You’ll first architect a warehouse schema and dimensional model for a small data warehouse. You’ll then create data integration workflows using Pentaho Data Integration to refresh your data warehouse. Next, you’ll write SQL statements for analytical query requirements and create materialized views to support summary data management. For data integration workflows and analytical queries, you can use either Oracle or PostgreSQL. Finally, you will use MicroStrategy OLAP capabilities to gain insights into your data warehouse. In the completed project, you’ll have built a small data warehouse containing a schema design, data integration workflows, analytical queries, materialized views, dashboards and visualizations that you’ll be proud to show to your current and prospective employers.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,6995
84,/learn/mcmc-bayesian-statistics,Bayesian Statistics: Techniques and Models,"University of California, Santa Cruz",4.8,45250,395,130,"This is the second of a two-course sequence introducing the fundamentals of Bayesian statistics. It builds on the course Bayesian Statistics: From Concept to Data Analysis, which introduces Bayesian methods through use of simple conjugate models. Real-world data often require more sophisticated models to reach realistic conclusions. This course aims to expand our “Bayesian toolbox” with more general models, and computational techniques to fit them. In particular, we will introduce Markov chain Monte Carlo (MCMC) methods, which allow sampling from posterior distributions that have no analytical solution. We will use the open-source, freely available software R (some experience is assumed, e.g., completing the previous course in R) and JAGS (no experience required). We will learn how to construct, fit, assess, and compare Bayesian statistical models to answer scientific questions involving continuous, binary, and count data. This course combines lecture videos, computer demonstrations, readings, exercises, and discussion boards to create an active learning experience. The lectures provide some of the basic mathematical development, explanations of the statistical modeling process, and a few basic modeling techniques commonly used by statisticians. Computer demonstrations provide concrete, practical walkthroughs. Completion of this course will give you access to a wide range of Bayesian analytical tools, customizable to your data.",30,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,27.0,,29.0,1,42389
85,/learn/introduction-portfolio-construction-python,Introduction to Portfolio Construction and Analysis with Python,EDHEC Business School,4.8,117510,947,267,"The practice of investment management has been transformed in recent years by computational methods. This course provides an introduction to the underlying science, with the aim of giving you a thorough understanding of that scientific basis. However, instead of merely explaining the science, we help you build on that foundation in a practical manner, with an emphasis on the hands-on implementation of those ideas in the Python programming language. This course is the first in a four course specialization in Data Science and Machine Learning in Asset Management but can be taken independently. In this course, we cover the basics of Investment Science, and we'll build practical implementations of each of the concepts along the way. We'll start with the very basics of risk and return and quickly progress to cover a range of topics including several Nobel Prize winning concepts. We'll cover some of the most popular practical techniques in modern, state of the art investment management and portfolio construction. 

As we cover the theory and math in lecture videos, we'll also implement the concepts in Python, and you'll be able to code along with us so that you have a deep and practical understanding of how those methods work. By the time you are done, not only will you have a foundational understanding of modern computational methods in investment management, you'll have practical mastery in the implementation of those methods.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,33459
86,/learn/python-visualization,Python Data Visualization,Rice University,4.7,11621,481,75,"This if the final course in the specialization which builds upon the knowledge learned in Python Programming Essentials, Python Data Representations, and Python Data Analysis.  We will learn how to install external packages for use within Python, acquire data from sources on the Web, and then we will clean, process, analyze, and visualize that data. This course will combine the skills learned throughout the specialization to enable you to write interesting, practical, and useful programs.By the end of the course, you will be comfortable installing Python packages, analyzing existing data, and generating visualizations of that data.  This course will complete your education as a scripter, enabling you to locate, install, and use Python packages written by others. You will be able to effectively utilize tools and packages that are widely available to amplify your effectiveness and write useful programs.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,12.0,,12.0,1,31039
87,/learn/fundamentals-of-reinforcement-learning,Fundamentals of Reinforcement Learning,University of Alberta,4.8,148278,1898,475,"Reinforcement Learning is a subfield of Machine Learning, but is also a general purpose formalism for automated decision-making and AI. This course introduces you to statistical learning techniques where an agent explicitly takes actions and interacts with the world. Understanding the importance and challenges of learning agents that make decisions is of vital importance today, with more and more companies interested in interactive agents and intelligent decision-making. This course introduces you to the fundamentals of Reinforcement Learning. When you finish this course, you will:
- Formalize problems as Markov Decision Processes 
- Understand basic exploration methods and the exploration/exploitation tradeoff
- Understand value functions, as a general-purpose tool for optimal decision-making
- Know how to implement dynamic programming as an efficient solution approach to an industrial control problem

This course teaches you the key concepts of Reinforcement Learning, underlying classic and modern algorithms in RL. After completing this course, you will be able to start using RL for real problems, where you have or can specify the MDP. 

This is the first course of the Reinforcement Learning Specialization.",15,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,14.0,1,47582
88,/learn/ibm-ai-workflow-ai-production,AI Workflow: AI in Production,IBM,4.4,12780,33,7,"This is the sixth course in the IBM AI Enterprise Workflow Certification specialization.   You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.    This course focuses on models in production at a hypothetical streaming media company.  There is an introduction to IBM Watson Machine Learning.  You will build your own API in a Docker container and learn how to manage containers with Kubernetes.  The course also introduces  several other tools in the IBM ecosystem designed to help deploy or maintain models in production.  The AI workflow is not a linear process so there is some time dedicated to the most important feedback loops in order to promote efficient iteration on the overall workflow.
 
By the end of this course you will be able to:
1.  Use Docker to deploy a flask application
2.  Deploy a simple UI to integrate the ML model, Watson NLU, and Watson Visual Recognition
3.  Discuss basic Kubernetes terminology
4.  Deploy a scalable web application on Kubernetes 
5.  Discuss the different feedback loops in AI workflow
6.  Discuss the use of unit testing in the context of model production
7.  Use IBM Watson OpenScale to assess bias and performance of production machine learning models.

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 5 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2001
89,/learn/understanding-visualization-data,Understanding and Visualizing Data with Python,University of Michigan,4.7,189708,1881,375,"In this course, learners will be introduced to the field of statistics, including where data come from, study design, data management, and exploring and visualizing data. Learners will identify different types of data, and learn how to visualize, analyze, and interpret summaries for both univariate and multivariate data. Learners will also be introduced to the differences between probability and non-probability sampling from larger populations, the idea of how sample estimates vary, and how inferences can be made about larger populations based on probability sampling.At the end of each week, learners will apply the statistical concepts they’ve learned using Python within the course environment. During these lab-based sessions, learners will discover the different uses of Python as a tool, including the Numpy, Pandas, Statsmodels, Matplotlib, and Seaborn libraries. Tutorial videos are provided to walk learners through the creation of visualizations and data management, all within Python. This course utilizes the Jupyter Notebook environment within Coursera.",20,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,24.0,27.0,,1,80747
90,/learn/ml-classification,Machine Learning: Classification,University of Washington,4.7,61293,3534,587,"Case Studies: Analyzing Sentiment & Loan Default PredictionIn our case study on analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).  In our second case study for this course, loan default prediction, you will tackle financial data, and predict when a loan is likely to be risky or safe for the bank. These tasks are an examples of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification. 

In this course, you will create classifiers that provide state-of-the-art performance on a variety of tasks.  You will become familiar with  the most successful techniques, which are most widely used in practice, including logistic regression, decision trees and boosting.  In addition, you will be able to design and implement the underlying algorithms that can learn these models at scale, using stochastic gradient ascent.  You will implement these technique on real-world, large-scale machine learning tasks.  You will also address significant tasks you will face in real-world applications of ML, including handling missing data and measuring precision and recall to evaluate a classifier.  This course is hands-on, action-packed, and full of visualizations and illustrations of how these techniques will behave on real data.  We've also included optional content in every module, covering advanced topics for those who want to go even deeper! 

Learning Objectives: By the end of this course, you will be able to:
   -Describe the input and output of a classification model.
   -Tackle both binary and multiclass classification problems.
   -Implement a logistic regression model for large-scale classification.  
   -Create a non-linear model using decision trees.
   -Improve the performance of any model using boosting.
   -Scale your methods with stochastic gradient ascent.
   -Describe the underlying decision boundaries.  
   -Build a classification model to predict sentiment in a product review dataset.  
   -Analyze financial data to predict loan defaults.
   -Use techniques for handling missing data.
   -Evaluate your models using precision-recall metrics.
   -Implement these techniques in Python (or in the language of your choice, though Python is highly recommended).",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,44.0,21.0,41.0,1,107939
91,/learn/genomic-data-science-project,Genomic Data Science Capstone,Johns Hopkins University,4.5,7228,57,20,"In this culminating project, you will deploy the tools and techniques that you've mastered over the course of the specialization. You'll work with a real data set to perform analyses and prepare a report of your findings.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,2679
92,/learn/database-management,Database Management Essentials,University of Colorado System,4.6,182343,2630,648,"Database Management Essentials provides the foundation you need for a career in database development, data warehousing, or business intelligence, as well as for the entire Data Warehousing for Business Intelligence specialization. In this course, you will create relational databases, write SQL statements to extract information to satisfy business reporting requests, create entity relationship diagrams (ERDs) to design databases, and analyze table designs for excessive redundancy. As you develop these skills, you will use either Oracle, MySQL, or PostgreSQL to execute SQL statements and a database diagramming tool such as the ER Assistant or Visual Paradigm to create ERDs. We’ve designed this course to ensure a common foundation for specialization learners. Everyone taking the course can jump right in with writing SQL statements in Oracle, MySQL, or PostgreSQL.",36,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,35.0,20.0,32.0,1,146095
93,/learn/practical-time-series-analysis,Practical Time Series Analysis,The State University of New York,4.6,79822,1262,353,"Welcome to Practical Time Series Analysis!Many of us are ""accidental"" data analysts. We trained in the sciences, business, or engineering and then found ourselves confronted with data for which we have no formal analytic training.  This course is designed for people with some technical competencies who would like more than a ""cookbook"" approach, but who still need to concentrate on the routine sorts of presentation and analysis that deepen the understanding of our professional topics. 

In practical Time Series Analysis we look at data sets that represent sequential information, such as stock prices, annual rainfall, sunspot activity, the price of agricultural products, and more.  We look at several mathematical models that might be used to describe the processes which generate these types of data. We also look at graphical representations that provide insights into our data. Finally, we also learn how to make forecasts that say intelligent things about what we might expect in the future.

Please take a few minutes to explore the course site. You will find video lectures with supporting written materials as well as quizzes to help emphasize important points. The language for the course is R, a free implementation of the S language. It is a professional environment and fairly easy to learn.

You can discuss material from the course with your fellow learners. Please take a moment to introduce yourself!

Time Series Analysis can take effort to learn- we have tried to present those ideas that are ""mission critical"" in a way where you understand enough of the math to fell satisfied while also being immediately productive. We hope you enjoy the class!",26,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,20.0,,29.0,1,53273
94,/learn/machinetranslation,Machine Translation,Karlsruhe Institute of Technology,4.5,22697,34,8,"Welcome to the CLICS-Machine Translation MOOCThis MOOC explains the basic principles of machine translation. Machine translation is the task of translating from one natural language to another natural language. Therefore, these algorithms can help people communicate in different languages. Such algorithms are used in common applications, from Google Translate to apps on your mobile device.

After taking this course you will be able to understand the main difficulties of translating natural languages and the principles of different machine translation approaches. A main focus of the course will be the current state-of-the-art neural machine translation technology which uses deep learning methods to model the translation process. You will be able to decide which concepts fit your machine translation application best.

This course is taught by Prof. Dr. Alexander Waibel (http://isl.anthropomatik.kit.edu/english/21_74.php) and Assistant Professor Dr. Jan Niehus (https://www.maastrichtuniversity.nl/jan.niehues).",27,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,3028
95,/learn/machine-learning-sas,Machine Learning Using SAS Viya,SAS,4.7,39058,74,16,"This course covers the theoretical foundation for different techniques associated with supervised machine learning models. In addition, a business case study is defined to guide participants through all steps of the analytical life cycle, from problem understanding to model deployment, through data preparation, feature selection, model training and validation, and model assessment. A series of demonstrations and exercises is used to reinforce the concepts and the analytical approach to solving business problems. This course uses Model Studio, the pipeline flow interface in SAS Viya that enables you to prepare, develop, compare, and deploy advanced analytics models. You learn to train supervised machine learning models to make better decisions on big data. The SAS applications used in this course make machine learning possible without programming or coding.",48,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,67.0,67.0,,0,5727
96,/learn/statistical-inferences,Improving your statistical inferences,Eindhoven University of Technology,4.9,50472,664,213,"This course aims to help you to draw better statistical inferences from empirical research. First, we will discuss how to correctly interpret p-values, effect sizes, confidence intervals, Bayes Factors, and likelihood ratios, and how these statistics answer different questions you might be interested in. Then, you will learn how to design experiments where the false positive rate is controlled, and how to decide upon the sample size for your study, for example in order to achieve high statistical power. Subsequently, you will learn how to interpret evidence in the scientific literature given widespread publication bias, for example by learning about p-curve analysis. Finally, we will talk about how to do philosophy of science, theory construction, and cumulative science, including how to perform replication studies, why and how to pre-register your experiment, and how to share your results following Open Science principles. In practical, hands on assignments, you will learn how to simulate t-tests to learn which p-values you can expect, calculate likelihood ratio's and get an introduction the binomial Bayesian statistics, and learn about the positive predictive value which expresses the probability published research findings are true. We will experience the problems with optional stopping and learn how to prevent these problems by using sequential analyses. You will calculate effect sizes, see how confidence intervals work through simulations, and practice doing a-priori power analyses. Finally, you will learn how to examine whether the null hypothesis is true using equivalence testing and Bayesian statistics, and how to pre-register a study, and share your data on the Open Science Framework.

All videos now have Chinese subtitles. More than 30.000 learners have enrolled so far! 

If you enjoyed this course, I can recommend following it up with me new course ""Improving Your Statistical Questions""",28,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,14.0,,,1,52661
97,/learn/ai-for-medical-treatment,AI For Medical Treatment,DeepLearning.AI,4.7,28772,412,88,"AI is transforming the practice of medicine. It’s helping doctors diagnose patients more accurately, make predictions about patients’ future health, and recommend better treatments. This Specialization will give you practical experience in applying machine learning to concrete problems in medicine.Medical treatment may impact patients differently based on their existing health conditions. In this third course, you’ll recommend treatments more suited to individual patients using data from randomized control trials. In the second week, you’ll apply machine learning interpretation methods to explain the decision-making of complex machine learning models. Finally, you’ll use natural language entity extraction and question-answering methods to automate the task of labeling medical datasets.

These courses go beyond the foundations of deep learning to teach you the nuances in applying AI to medical use cases. If you are new to deep learning or want to get a deeper foundation of how neural networks work, we recommend that you take the Deep Learning Specialization.",22,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,14325
98,/learn/intelligent-machining,Intelligent Machining,University at Buffalo,4.6,12200,1236,263,"Manufacturers are increasingly utilizing machine tools that are self-aware – they perceive their own states and the state of the surrounding environment – and are able to make decisions related to machine activity processes. This is called intelligent machining, and through this course students will receive a primer on its background, tools and related terminology. Learn how the integration of smart sensors and controls are helping to improve productivity. You’ll be exposed to various sensors and sensing techniques, process control strategies, and open architecture systems that can be leveraged to enable intelligent machining. This course will prepare you to contribute to the implementation of intelligent machining projects. 

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the fifth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal. To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,20912
99,/learn/applied-data-science-capstone,Applied Data Science Capstone,IBM,4.7,266870,5246,669,"This capstone project course will give you a taste of what data scientists go through in real life when working with data. You will learn about location data and different location data providers, such as Foursquare. You will learn how to make RESTful API calls to the Foursquare API to retrieve data about venues in different neighborhoods around the world. You will also learn how to be creative in situations where data are not readily available by scraping web data and parsing HTML code. You will utilize Python and its pandas library to manipulate data, which will help you refine your skills for exploring and analyzing data. 

Finally, you will be required to use the Folium library to great maps of geospatial data and to communicate your results and findings.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge upon successful completion of the course.  

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.",47,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,36.0,10.0,39.0,0,73089
100,/learn/network-path-text-analyses-sas-va,"Performing Network, Path, and Text Analyses in SAS Visual Analytics",SAS,4.8,5077,154,17,"In this course, you learn about the data structure needed for network, path, and text analytics and how to create network analysis, path analysis, and text analytics in SAS Visual Analytics.",4,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,6431
101,/learn/open-source-tools-for-data-science,Tools for Data Science,IBM,4.5,820435,21021,3237,"What are some of the most popular data science tools, how do you use them, and what are their features? In this course, you'll learn about Jupyter Notebooks, JupyterLab, RStudio IDE, Git, GitHub, and Watson Studio. You will learn about what each tool is used for, what programming languages they can execute, their features and limitations. With the tools hosted in the cloud on Skills Network Labs, you will be able to test each tool and follow instructions to run simple code in Python, R or Scala. To end the course, you will create a final project with a Jupyter Notebook on IBM Watson Studio and demonstrate your proficiency preparing a notebook, writing Markdown, and sharing your work with your peers.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,30.0,17.0,26.0,0,194390
102,/learn/supply-chain-analytics,Supply Chain Analytics,Rutgers the State University of New Jersey,4.7,14189,576,124,"Welcome to Supply Chain Analytics - the art and science of applying data analytics to assess and improve supply chain performance!A supply chain is a complex system with conflicting objectives of cost efficiency and customer satisfaction. Supply chain management is becoming increasingly data driven. Through the real-life story and data of a major US telecommunication company, you will learn the analytics tools / skills to diagnose and optimize a supply chain. Upon completion of this course, you will be able to

1. Use data analytics to assess the impact of various strategies on all aspects of a supply chain, from inventory, shipping, to warehouse order fulfillment, store operations and customer satisfaction. 
2. Customize the supply chain strategy by product to improve the overall cost efficiency without sacrificing customer service. 
3. Obtain hands-on experience on the application and financial impact of analytics in integrated supply chain and logistics planning.

VASTA (name disguised) is a major wireless carrier in the US selling cell phones through a national network of retail stores. Recently, it wrote off a huge amount of obsolete inventory each year and was suffering a significant cost inefficiency in an increasingly stagnant market. VASTA must assess the competitive environment, and renovate its supply chain to stay competitive. At the end of this course, you will help VASTA save $billions on supply chain cost and retain its leadership in a stagnant and saturated market.

I hope you enjoy the course!",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,15693
103,/learn/advanced-computer-vision-with-tensorflow,Advanced Computer Vision with TensorFlow,DeepLearning.AI,4.8,96403,122,26,"In this course, you will:a) Explore image classification, image segmentation, object localization, and object detection. Apply transfer learning to object localization and detection.
b) Apply object detection models such as regional-CNN and ResNet-50, customize existing models, and build your own models to detect, localize, and label your own rubber duck images.
c) Implement image segmentation using variations of the fully convolutional network (FCN) including U-Net and d) Mask-RCNN to identify and detect numbers, pets, zombies, and more.
d) Identify which parts of an image are being used by your model to make its predictions using class activation maps and saliency maps and apply these ML interpretation methods to inspect and improve the design of a famous network, AlexNet.


The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture and tools that help them create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",24,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,6265
104,/learn/ai-data-bias,Artificial Intelligence Data Fairness and Bias						,LearnQuest,4.9,5197,43,8,"In this course, we will explore fundamental issues of fairness and bias in machine learning. As predictive models begin making important decisions, from college admission to loan decisions, it becomes paramount to keep models from making unfair predictions. From human bias to dataset awareness, we will explore many aspects of building more ethical models.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2114
105,/learn/gis-1,Geographical Information Systems - Part 1,École Polytechnique Fédérale de Lausanne,3.7,10816,47,15,"This course is organized into two parts presenting the theoretical and practical foundations of geographic information systems (GIS).- Together theses courses constitute an introduction to GIS and require no prior knowledge.
- By following this introduction to GIS you will quickly acquire the basic knowledge required to create spatial databases and produce high-quality maps and cartographic representations.
- This is a practical course and is based on free, open-source software, including QGIS.
If you study or work in the fields of land management or the analysis of geographically distributed objects such as land use planning, biology, public health, ecology, or energy, then this course is for you!

In this first part of the course, we will focus on the digitization and the storage of geodata. In particular, you will learn:
- To characterize spatial objects and/or phenomena (territory modeling) with respect to their position in space (through coordinate systems, projections, and spatial relationships) and according to their intrinsic nature (object/vector mode vs. Image/raster mode); 
- About the different means used to acquire spatial data; including direct measurement, georeferencing images, digitization, existing data source, etc.);
- About the different ways in which geodata can be stored - notably, files and relational databases;
- How to use data modeling tools to describe and create a spatial database;
- To query and analyze data using SQL, a common data manipulation language.

The second part of this course will focus on methods of spatial analysis and geodata representation. In this section, you will learn:
- How to describe and quantify the spatial properties of discrete variables, for example through spatial autocorrelation;
- To work with continuous variables. In particular, we will look at sampling strategies, how to construct contour lines and isovalue curves, and we will explore different interpolation methods;
- To use digital elevation models and create their derivative products (i.e. slope, orientation);
- How to evaluate the interaction between different types of geodata through overlay and interaction techniques;
- How to create effective maps based around the rules of graphic semiology;
- Finally, we will also explore other, increasingly common, forms of spatial representation such as interactive web-mapping and 3D representations.

You can find an interactive forum for course participants on our Facebook page: https://www.facebook.com/moocsig",16,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,9216
106,/learn/sas-sql,Structured Query Language (SQL) using SAS ,SAS,4.9,32457,79,19,"Course DescriptionIn this course, you learn about Structured Query Language (SQL) and how it can be used in SAS programs to create reports and query your data.   

“By the end of this course, a learner will be able to…”
●	Query and subset data.
●	Summarize and present data.
●	Combine tables using joins and set operators.
●	Create and modify tables and views.
●	Create data-driven macro variables using a query.
●	Access DBMS data with SAS/ACCESS technology.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,4977
107,/learn/big-data-visualizacion-datos,Big Data: visualización de datos,Universitat Autònoma de Barcelona,4.6,7963,139,53,"“Visualización de datos” es el cuarto curso de la especialización “Biga Data- Uso práctico de datos masivos. Organizado en cuatro semanas, tiene por objetivo motivar e introducir los conceptos clave de la visualización de datos así como mostrar ejemplos en diferentes contextos. Además, se proporcionan criterios para formular el problema y elegir las herramientas más adecuadas para obtener una correcta visualización. Este debe ser un curso introductorio, motivador e inspirador para la narración de historias a través de la visualización de sus datos.Los cuatro módulos en los que se estructura el curso son los siguientes:
MÓDULO 1: Contexto para la visualización de datos hoy
MÓDULO 2: Herramientas de análisis y visualización de datos
MÓDULO 3: El proceso de creación de una visualización de datos
MÓDULO 4: Otros aspectos de la visualización de datos",9,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,,,,0,9383
108,/learn/gcp-big-data-ml-fundamentals,Google Cloud Platform Big Data and Machine Learning Fundamentals,Google Cloud,4.7,282690,13018,2309,"This course introduces participants to the big data capabilities of Google Cloud. Through a combination of presentations, demos, and hands-on labs, participants get an overview of Google Cloud and a detailed view of the data processing and machine learning capabilities. This course showcases the ease, flexibility, and power of big data solutions on Google Cloud.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,39.0,,41.0,0,195367
109,/learn/dataviz-dashboards,Creating Dashboards and Storytelling with Tableau,"University of California, Davis",4.6,64604,805,143,"Leveraging the visualizations you created in the previous course, Visual Analytics with Tableau, you will create dashboards that help you identify the story within your data, and you will discover how to use Storypoints to create a powerful story to leave a lasting impression with your audience.You will balance the goals of your stakeholders with the needs of your end-users, and be able to structure and organize your story for maximum impact. Throughout the course you will apply more advanced functions within Tableau, such as hierarchies, actions and parameters to guide user interactions.  For your final project, you will create a compelling narrative to be delivered in a meeting, as a static report, or in an interactive display online.",15,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,32.0,,33.0,1,32580
110,/learn/sequence-models-tensorflow-gcp,Sequence Models for Time Series and Natural Language Processing,Google Cloud,4.4,16584,446,63,"This course is an introduction to sequence models and their applications, including an overview of sequence model architectures and how to handle inputs of variable length.• Predict future values of a time-series
• Classify free form text
• Address time-series and text problems with recurrent neural networks
• Choose between RNNs/LSTMs and simpler models
• Train and reuse word embeddings in text problems

You will get hands-on practice building and optimizing your own text classification and sequence models on a variety of public datasets in the labs we’ll work on together.  

Prerequisites: Basic SQL, familiarity with Python and TensorFlow",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,67.0,,50.0,0,13250
111,/learn/ibm-exploratory-data-analysis-for-machine-learning,Exploratory Data Analysis for Machine Learning,IBM,4.6,107248,234,56,"This first course in the IBM Machine Learning Professional Certificate introduces you to Machine Learning and the content of the professional certificate. In this course you will realize the importance of good, quality data. You will learn common techniques to retrieve your data, clean it, apply feature engineering, and have it ready for preliminary analysis and hypothesis testing.By the end of this course you should be able to:
Retrieve data from multiple data sources: SQL, NoSQL databases, APIs, Cloud 
Describe and use common feature selection and feature engineering techniques
Handle categorical and ordinal features, as well as missing values
Use a variety of techniques for detecting and dealing with outliers
Articulate why feature scaling is important and use a variety of scaling techniques
 
Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience  with Machine Learning and Artificial Intelligence in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Calculus, Linear Algebra, Probability, and Statistics.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,11458
112,/learn/big-data-ai-ethics,"Big Data, Artificial Intelligence, and Ethics","University of California, Davis",4.6,20299,304,83,"This course gives you context and first-hand experience with the two major catalyzers of the computational science revolution: big data and artificial intelligence. With more than 99% of all mediated information in digital format and with 98% of the world population using digital technology, humanity produces an impressive digital footprint. In theory, this provides unprecedented opportunities to understand and shape society. In practice, the only way this information deluge can be processed is through using the same digital technologies that produced it. Data is the fuel, but machine learning it the motor to extract remarkable new knowledge from vasts amounts of data. Since an important part of this data is about ourselves, using algorithms in order to learn more about ourselves naturally leads to ethical questions. Therefore, we cannot finish this course without also talking about research ethics and about some of the old and new lines computational social scientists have to keep in mind. As hands-on labs, you will use IBM Watson’s artificial intelligence to extract the personality of people from their digital text traces, and you will experience the power and limitations of machine learning by teaching two teachable machines from Google yourself.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,16611
113,/learn/strategic-business-analytics,Foundations of strategic business analytics,ESSEC Business School,4.4,30889,586,138,"Who is this course for?  This course is designed for students, business analysts, and data scientists who want to apply statistical knowledge and techniques to business contexts. For example, it may be suited to experienced statisticians, analysts, engineers who want to move more into a business role. 

You will find this course exciting and rewarding if you already have a background in statistics, can use R or another programming language and are familiar with databases and data analysis techniques such as regression, classification, and clustering.
However, it contains a number of recitals and R Studio tutorials which will consolidate your competences, enable you to play more freely with data and explore new features and statistical functions in R.

With this course, you’ll have a first overview on Strategic Business Analytics topics. We’ll discuss a wide variety of applications of Business Analytics. From Marketing to Supply Chain or Credit Scoring and HR Analytics, etc. We’ll cover many different data analytics techniques, each time explaining how to be relevant for your business.

We’ll pay special attention to how you can produce convincing, actionable, and efficient insights. We'll also present you with different data analytics tools to be applied to different types of issues.
By doing so, we’ll help you develop four sets of skills needed to leverage value from data: Analytics, IT, Business and Communication. 

By the end of this MOOC, you should be able to approach a business issue using Analytics by (1) qualifying the issue at hand in quantitative terms, (2) conducting relevant data analyses, and (3) presenting your conclusions and recommendations in a business-oriented, actionable and efficient way.

Prerequisites : 1/ Be able to use R or to program 2/ To know the fundamentals of databases, data analysis (regression, classification, clustering)

We give credit to Pauline Glikman, Albane Gaubert, Elias Abou Khalil-Lanvin (Students at ESSEC BUSINESS SCHOOL) for their contribution to this course design.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,45.0,,75.0,0,53036
114,/learn/linear-regression-model,Linear Regression and Modeling ,Duke University,4.7,46167,1516,280,"This course introduces simple and multiple linear regression models. These models allow you to assess the relationship between variables in a data set and a continuous response variable. Is there a relationship between the physical attractiveness of a professor and their student evaluation scores? Can we predict the test score for a child based on certain characteristics of his or her mother? In this course, you will learn the fundamental theory behind linear regression and, through data examples, learn to fit, examine, and utilize regression models to examine relationships between multiple variables, using the free statistical software R and RStudio.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,38.0,10.0,27.0,1,75760
115,/learn/jiegou-fangcheng-moxing,Structural Equation Model and its Applications | 结构方程模型及其应用 (普通话),The Chinese University of Hong Kong,4.8,7930,71,32,在社会学、心理学、教育学、经济学、管理学、市场学等研究领域的数据分析中，结构方程建模是当前最前沿的统计方法中应用最广、研究最多的一个。它包含了方差分析、回归分析、路径分析和因子分析，弥补了传统回归分析和因子分析的不足，可以分析多因多果的联系、潜变量的关系，还可以处理多水平数据和纵向数据，是非常重要的多元数据分析工具。本课程系统地介绍结构方程模型和LISREL软件的应用，内容包括：结构方程分析（包括验证性因子分析）的基本概念、统计原理、在社会科学研究中的应用、常用模型及其LISREL程序、结果的解释和模型评价。学员应具备基本的统计知识（如：标准差、t-检验、相关系数），理解回归分析和因子分析的概念。 注：本课程配套教材为《结构方程模型及其应用》（以LISREL软件为例）。,13,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,,,,1,6653
116,/learn/feature-engineering,Feature Engineering,Google Cloud,4.5,24636,1620,178,Want to know how you can improve the accuracy of your ML models? What about how to find which data columns make the most useful features? Welcome to Feature Engineering where we will discuss good vs bad features and how you can preprocess and transform them for optimal use in your models.,18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,18.0,14.0,12.0,0,23284
117,/learn/sig-1,Systèmes d’Information Géographique - Partie 1,École Polytechnique Fédérale de Lausanne,4.5,35155,221,87,"Organisé en deux parties, ce cours présente les bases théoriques et pratiques des systèmes d’information géographique.- Il propose une introduction aux systèmes d’information géographique qui ne requiert pas de connaissances préalables en informatique
- Il donne la possibilité d’acquérir rapidement les notions de base qui vous permettent de créer des bases de données spatiales et de fabriquer des cartes géographiques
- Il s’agit d’un cours pratique qui repose sur l’utilisation de logiciels libres, notamment QGIS
En somme, si vos études ou votre profession comprennent des activités liées à la gestion de territoires, à l’analyse d’objets distribués dans l’espace géographique (aménagement du territoire, biologie, santé publique, écologie, énergie, etc.), ce cours est fait pour vous!

En suivant cette première partie du cours, vous explorerez les principes de base de la numérisation du territoire et du stockage des géodonnées. Vous apprendrez notamment à :
- Caractériser des objets et/ou phénomènes spatiaux (modélisation du territoire) du point de vue de leur positionnement dans l’espace (systèmes de coordonnées et projections, relations spatiales) et en fonction de leur nature intrinsèque (mode objet ou vecteur vs. mode image ou raster), 
- Utiliser les diverses méthodes d’acquisition de données (mesure directe, géoréférencement d’images, digitalisation, source de données existantes, etc.)
- Utiliser les divers modes de stockage des géodonnées – Fichiers simples et/ou bases de données relationnelles
- Utiliser des outils de modélisation des données pour décrire et implémenter une base de données 
- Créer des requêtes dans le langage d’interrogation et de manipulation des données

La seconde partie du cours portera sur les méthodes d'analyse spatiale et les techniques de représentation des géo-données. Vous apprendrez notamment à:
- Analyser les propriétés spatiales de variables discrètes, par exemple en quantifiant l’autocorrélation spatiale
- Travailler avec les variables continues (échantillonnage, construction de courbes d’isovaleurs, méthodes d’interpolation)
- Utiliser les modèles numériques d'altitude et leurs dérivées (pente, orientation, etc.)
- Utiliser les techniques de superposition de géodonnées et d'interaction entre elles
- Produire des documents cartographiques selon les règles de la sémiologie graphique
- Explorer d’autres formes de représentation spatiale (cartographie interactive sur internet, représentations 3D, etc.)

La page https://www.facebook.com/moocsig fournit un forum interactif pour les participants à ce cours.",16,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,20.0,,20.0,0,25340
118,/learn/advanced-machine-learning-signal-processing,Advanced Machine Learning and Signal Processing,IBM,4.5,39119,1112,197,">>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area <<<This course, Advanced Machine Learning and Signal Processing, is part of the IBM Advanced Data Science Specialization which IBM is currently creating and gives you easy access to the invaluable insights into Supervised and Unsupervised Machine Learning Models used by experts in many field relevant disciplines. We’ll learn about the fundamentals of Linear Algebra to understand how machine learning modes work. Then we introduce the most popular Machine Learning Frameworks for python Scikit-Learn and SparkML. SparkML is making up the greatest portion of this course since scalability is key to address performance bottlenecks. We learn how to tune the models in parallel by evaluating hundreds of different parameter-combinations in parallel. We’ll continuously use a real-life example from IoT (Internet of Things), for exemplifying the different algorithms. For passing the course you are even required to create your own vibration sensor data using the accelerometer sensors in your smartphone. So you are actually working on a self-created, real dataset throughout the course.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  To find out more about IBM digital badges follow the link ibm.biz/badging.",27,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,38.0,12.0,36.0,0,34995
119,/learn/machine-learning-business-professionals,Managing Machine Learning Projects with Google Cloud,Google Cloud,4.6,35775,3483,919,"Business professionals in non-technical roles have a unique opportunity to lead or influence machine learning projects. If you have questions about machine learning and want to understand how to use it, without the technical jargon, this course is for you. Learn how to translate business problems into machine learning use cases and vet them for feasibility and impact. Find out how you can discover unexpected use cases, recognize the phases of an ML project and considerations within each, and gain confidence to propose a custom ML use case to your team or leadership or translate the requirements to a technical team.",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,43.0,,50.0,0,107954
120,/learn/humanidades-digitales,Humanidades digitales,Universitat Autònoma de Barcelona,4.6,16258,624,260,"¿Te has planteado para qué sirven las humanidades en el siglo XXI? ¿Cómo el advenimiento de lo Digital ha cambiado nuestra forma de acercarnos a las Humanidades? ¿Y al revés? ¿De qué forma las Humanidades influencian sobre los diferentes aspectos de la Tecnología? Te ofrecemos el primer curso online que da respuesta a estas preguntas. Una visión de las Humanidades Digitales desde la filosofía, la historia, la arqueología, el arte,… y desde las ciencias computacionales y la visión por ordenador.  El curso ofrece una  aproximación interdisciplinar a las Humanidades y el Patrimonio Digital, y a los métodos y herramientas utilizados (Bases de datos, Open Data, Big Data, Realidad Virtual, Redes Sociales, image recognition,…). También nos aporta una reflexión sobre los aspectos legales y éticos de la tecnología y sus implicaciones en la transformación digital, la innovación social, la política y la cultura. 
¿Para qué sirve este curso? El curso pretende ser una introducción a las Humanidades y el Patrimonio Digital. Con él tendrás una visión amplia y transversal de los diferentes aspectos implicados en los diferentes ámbitos. Un curso que te ayudará en tu camino a la transformación digital y a la implementación de la tecnología digital en las Humanidades.
Si eres una persona con una formación humanista, ingeniería o informática, o simplemente te interesa la relación de la tecnología con las humanidades, este curso es para ti. Está pensado para poder ser completado por cualquier persona con interés, puesto que las presentaciones son amenas y alternativas, eso sí, sin perder nunca el rigor académico. 
Un curso impartido por especialistas de la Xarxa d’Humanitats Digitals (Red de Humanidades Digitales) de la Universidad Autònoma de Barcelona.",3,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,55.0,25.0,50.0,0,14662
121,/learn/power-sample-size,Power and Sample Size for Multilevel and Longitudinal Study Designs,University of Florida,4.5,8863,21,3,"Power and Sample Size for Longitudinal and Multilevel Study Designs, a five-week, fully online course covers innovative, research-based power and sample size methods, and software for multilevel and longitudinal studies.  The power and sample size methods and software taught in this course can be used for any health-related, or more generally, social science-related (e.g., educational research) application.  All examples in the course videos are from real-world studies on behavioral and social science employing multilevel and longitudinal designs. The course philosophy is to focus on the conceptual knowledge to conduct power and sample size methods. The goal of the course is to teach and disseminate methods for accurate sample size choice, and ultimately, the creation of a power/sample size analysis for a relevant research study in your professional context. Power and sample size selection is one of the most important ethical questions researchers face. Interventional studies that are too large expose human volunteer research participants to possible, and needless, harm from research. Interventional studies that are too small will fail to reach their scientific objective, again bringing possible harm to research participants, without the possibility of concomitant gain from the increase in knowledge. For observational studies in which there are no possible harms to the participants, such as observational studies, proper power ensures good stewardship of both time and money.

Most National Institutes of Health (NIH) study sections will only fund a grant if the grantee has written a compelling and accurate power and sample size analysis. The Institute of Education Sciences (IES), the statistics, research, and evaluation arm of the U.S. Department of Education, also offers competitive grants requiring a compelling and accurate power and sample size analysis (Goal 3: Efficacy and Replication and Goal 4: Effectiveness/Scale-Up). 

At the end of the online course, learners will be able to: 
•	Use a framework and strategy for study planning 
•	Write study aims as testable hypotheses
•	Describe a longitudinal and multilevel study design
•	Write a statistical analysis plan 
•	Plan a sampling design for subgroups, e.g. racial and ethnic
•	Demonstrate the feasibility of recruitment
•	Describe expected missing data and dropout
•	Write a power and sample size analysis that is aligned with the planned statistical analysis

This is a five-week intensive and interactive online course. We will use a mix of instructional videos, software demonstration videos, online discussion forums, online readings, quizzes, exercise assignments, and peer-review assignments. The final course project is a peer-reviewed research study you design for future power or sample size analysis.",24,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,,,,1,2865
122,/learn/enjoyable-econometrics,Enjoyable Econometrics,Erasmus University Rotterdam,4.0,13504,42,14,"The goal of this MOOC is to show that econometric methods are often needed to answer questions. A question comes first, then data are to be collected, and then finally the model or method comes in. Depending on the data, however, it can happen that methods need to be adapted. For example, where we first look at two variables, later we may need to look at three or more. Or, when data are missing, what then do we do? And, if the data are counts, like the number of newspaper articles citing someone, then matters may change too. But these modifications always come last, and are considered only when relevant. An important motivation for me to make this MOOC is to emphasize that econometric models and methods can also be applied to more unconventional settings, which are typically settings where the practitioner has to collect his or her own data first. Such collection can be done by carefully combining existing databases, but also by holding surveys or running experiments. A byproduct of having to collect your own data is that this helps to choose amongst the potential methods and techniques that are around.

If you are searching for a MOOC on econometrics that treats (mathematical and statistical) methods of econometrics and their applications, you may be interested in the Coursera course “Econometrics: Methods and Applications” that is also from Erasmus University Rotterdam.",2,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,9863
123,/learn/ai-with-ibm-watson,Getting Started with AI using IBM Watson,IBM,4.5,51457,2041,399,"In this course you will learn how to quickly and easily get started with Artificial Intelligence using IBM Watson. You will understand how Watson works, become familiar with its use cases and real life client examples, and be introduced to several of Watson AI services from IBM that enable anyone to easily apply AI and build smart apps. You will also work with several Watson services to demonstrate AI in action.This course does not require any programming or computer science expertise and is designed for anyone whether you have a technical background or not.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,27350
124,/learn/optimize-machine-learning-model-performance,Optimizing Machine Learning Performance,Alberta Machine Intelligence Institute,4.6,6285,36,8,"This course synthesizes everything your have learned in the applied machine learning specialization. You will now walk through a complete machine learning project to prepare a machine learning maintenance roadmap. You will understand and analyze how to deal with changing data. You will also be able to identify and interpret potential unintended effects in your project. You will understand and define procedures to operationalize and maintain your applied machine learning model. By the end of this course you will have all the tools and understanding you need to confidently roll out a machine learning project and prepare to optimize it in your business context. To be successful, you should have at least beginner-level background in Python programming (e.g., be able to read and code trace existing code, be comfortable with conditionals, loops, variables, lists, dictionaries and arrays). You should have a basic understanding of linear algebra (vector notation) and statistics (probability distributions and mean/median/mode).

This is the final course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute (Amii).",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,5008
125,/learn/global-statistics,Global Statistics - Composite Indices for International Comparisons,University of Geneva,4.6,5064,33,16,"The number of composite indices that are constructed and used internationally is growing very fast; but whilst the complexity of quantitative techniques has increased dramatically, the education and training in this area has been dragging and lagging behind. As a consequence, these simple numbers, expected to synthesize quite complex issues, are often presented to the public and used in the political debate without proper emphasis on their intrinsic limitations and correct interpretations. In this course on global statistics, offered by the University of Geneva jointly with the ETH Zürich KOF, you will learn the general approach of constructing composite indices and some of resulting problems. We will discuss the technical properties, the internal structure (like aggregation, weighting, stability of time series), the primary data used and the variable selection methods.  These concepts will be illustrated using a sample of the most popular composite indices. We will try to address not only statistical questions but also focus on the distinction between policy-, media- and paradigm-driven indicators.",16,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,2505
126,/learn/process-data,Process Data from Dirty to Clean,Google,4.8,447152,117,20,"This is the fourth course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. In this course, you’ll continue to build your understanding of data analytics and the concepts and tools that data analysts use in their work. You’ll learn how to check and clean your data using spreadsheets and SQL as well as how to verify and report your data cleaning results. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will be able to do the following:
 - Learn how to check for data integrity.
 - Discover data cleaning techniques using spreadsheets. 
 - Develop basic SQL queries for use on databases.
 - Apply basic SQL functions for cleaning and transforming data.
 - Gain an understanding of how to verify the results of cleaning data.
 - Explore the elements and importance of data cleaning reports.",23,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,0,5395
127,/learn/ibm-data-analyst-capstone-project,IBM Data Analyst Capstone Project,IBM,4.6,158788,108,10,"In this course you will apply various Data Analytics skills and techniques that you have learned as part of the previous courses in the IBM Data Analyst Professional Certificate. You will assume the role of an Associate Data Analyst who has recently joined the organization and be presented with a business challenge that requires data analysis to be performed on real-world datasets. You will undertake the tasks of collecting data from multiple sources, performing exploratory data analysis, data wrangling and preparation, statistical analysis and mining the data, creating charts and plots to visualize data, and building an interactive dashboard. The project will culminate with a presentation of your data analysis report, with an executive summary for the various stakeholders in the organization. You will be assessed on both your work for the various stages in the Data Analysis process, as well as the final deliverable. 

This project is a great opportunity to showcase your Data Analytics skills, and demonstrate your proficiency to potential employers.",13,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,4625
128,/learn/introduction-clinical-data-science,Introduction to Clinical Data Science,University of Colorado System,4.6,19900,278,83,"This course will prepare you to complete all parts of the Clinical Data Science Specialization. In this course you will learn how clinical data are generated, the format of these data, and the ethical and legal restrictions on these data. You will also learn enough SQL and R programming skills to be able to complete the entire Specialization - even if you are a beginner programmer. While you are taking this course you will have access to an actual clinical data set and a free, online computational environment for data science hosted by our Industry Partner Google Cloud. At the end of this course you will be prepared to embark on your clinical data science education journey, learning how to take data created by the healthcare system and improve the health of tomorrow's patients.",8,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,27.0,25.0,20.0,1,10338
129,/learn/powerpoint-presentations,Effective Business Presentations with Powerpoint,PwC,4.5,72121,921,164,"This course is all about presenting the story of the data, using PowerPoint. You'll learn how to structure a presentation, to include insights and supporting data. You'll also learn some design principles for effective visuals and slides. You'll gain skills for client-facing communication - including public speaking, executive presence and compelling storytelling. Finally, you'll be given a client profile, a business problem, and a set of basic Excel charts, which you'll need to turn into a presentation - which you'll deliver with iterative peer feedback.This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,43.0,,60.0,0,69832
130,/learn/r-packages,Building R Packages,Johns Hopkins University,4.1,8917,205,53,"Writing good code for data science is only part of the job. In order to maximizing the usefulness and reusability of data science software, code must be organized and distributed in a manner that adheres to community-based standards and provides a good user experience. This course covers the primary means by which R software is organized and distributed to others. We cover R package development, writing good documentation and vignettes, writing robust software, cross-platform development, continuous integration tools, and distributing packages via CRAN and GitHub. Learners will produce R packages that satisfy the criteria for submission to CRAN.",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,14.0,,25.0,1,9380
131,/learn/guided-tour-machine-learning-finance,Guided Tour of Machine Learning in Finance,New York University,3.8,40552,577,183,"This course aims at providing an introductory and broad overview of the field of ML with the focus on applications on Finance. Supervised Machine Learning methods are used in the capstone project to predict bank closures. Simultaneously, while this course can be taken as a separate course, it serves as a preview of topics that are covered in more details in subsequent modules of the specialization Machine Learning and Reinforcement Learning in Finance.The goal  of Guided Tour of Machine Learning in Finance is to get a sense of what Machine Learning is, what it is for and in how many different financial problems it can be applied to.

The course is designed for three categories of students:
Practitioners working at financial institutions such as banks, asset management firms or hedge funds
Individuals interested in applications of ML for personal day trading
Current full-time students pursuing a degree in Finance, Statistics, Computer Science, Mathematics, Physics, Engineering or other related disciplines who want to learn about practical applications of ML in Finance  

Experience with Python (including numpy, pandas, and IPython/Jupyter notebooks), linear algebra, basic probability theory and basic calculus is necessary to complete assignments in this course.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,47.0,,50.0,1,24801
132,/learn/hipython,用Python玩转数据 Data Processing Using Python,Nanjing University,4.7,12469,1403,389,"本课程 (Please click https://www.coursera.org/learn/python-data-processing for English version) 主要面向非计算机专业学生，从Python基本语法开始，到Python中如何从本地和网络上进行数据获取，如何解析和表示数据，再到如何利用Python开源生态系统SciPy对数据进行基础和高级的统计分析及可视化，包括数据探索和预处理的具体方法，到最后如何设计一个简单的GUI界面来表示和处理数据，层层推进。整个课程以财经数据为基础，通过构建一个个喜闻乐见的案例，让大家可以以更直观的方式领略Python的简洁、优雅和健壮，同时探讨Python除了在商业领域之外在文学、社会学和新闻等人文社科类领域以及在数学和生物等理工类领域同样拥有便捷高效的数据处理能力，并可以触类旁通将其灵活应用于各专业中。

近期（2019年11月6日已更新完毕）本课程进行了全面改版，新版主要在以下几个方面做了改变：
1. 丰富了Python基础的案例实际操作和讲解；
2. 增加和扩展了如NumPy包的矢量运算和广播思想及常见应用，数据探索与预处理的多个环节，基于pandas的数据分析及数据挖掘案例等。
有些是直接在原视频上修改，有些是以拓展视频的方式呈现，特别是新录制的视频因为想说的内容很多所以时长较长，很多都超过了20分钟😓，小伙伴们学习时可能会比较辛苦，加油加油！",27,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,50.0,46.0,33.0,1,72736
133,/learn/dwrelational,Relational Database Support for Data Warehouses,University of Colorado System,4.6,13284,572,72,"Relational Database Support for Data Warehouses is the third course in the Data Warehousing for Business Intelligence specialization. In this course, you'll use analytical elements of SQL for answering business intelligence questions. You'll learn features of relational database management systems for managing summary data commonly used in business intelligence reporting. Because of the importance and difficulty of managing implementations of data warehouses, we'll also delve into storage architectures, scalable parallel processing, data governance, and big data impacts. In the assignments in this course, you can use either Oracle or PostgreSQL.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,17.0,20.0,33.0,1,25538
134,/learn/supervised-learning,Обучение на размеченных данных,Moscow Institute of Physics and Technology,4.8,139581,2511,334,"Обучение на размеченных данных или обучение с учителем – это наиболее распространенный класс задач машинного обучения. К нему относятся те задачи, где нужно научиться предсказывать некоторую величину для любого объекта, имея конечное число примеров. Это может быть предсказание уровня пробок на участке дороги, определение возраста пользователя по его действиям в интернете, предсказание цены, по которой будет куплена подержанная машина.В этом курсе вы научитесь формулировать и, конечно, решать такие задачи. В центре нашего внимания будут успешно применяемые на практике алгоритмы классификации и регрессии: линейные модели, нейронные сети, решающие деревья и так далее. Особый акцент мы сделаем на такой мощной технике как построение композиций, которая позволяет существенно повысить качество отдельных алгоритмов и широко используется при решении прикладных задач. В частности, мы узнаем про случайные леса и про метод градиентного бустинга.

Построение предсказывающих алгоритмов — это лишь часть работы при решении задачи анализа данных. Мы разберемся и с другими этапами: оценивание обобщающей способности алгоритмов, подбор параметров модели, выбор и подсчет метрик качества.

Видео курса разработаны на Python 2. Задания и ноутбуки к ним адаптированы к Python 3.",59,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,42.0,33.0,30.0,0,32043
135,/learn/excel-essentials,Excel Skills for Business: Essentials,Macquarie University,4.9,2161745,34941,9522,"In this first course of the specialization Excel Skills for Business, you will learn the essentials of Microsoft Excel. Within six weeks, you will be able to expertly navigate the Excel user interface, perform basic calculations with formulas and functions, professionally format spreadsheets, and create visualizations of data through charts and graphs.Whether you are self-taught and want to fill in the gaps for better efficiency and productivity, or whether you have never used Excel before, this course will set you up with a solid foundation to become a confident user and develop more advanced skills in later courses. 

The best way to learn Excel is to use Excel. In this course, learners will solve a broad range of business problems as they apply the Excel skills and techniques they learn along the way. This course uses downloadable Excel workbooks and full data sets with applied examples and practical challenge exercises. This provides learners with countless opportunities to practice their Excel skills while discovering new and useful productivity features of Excel for a variety of business contexts.

Spreadsheet software is one of the most ubiquitous pieces of software used in workplaces across the world. Learning to confidently operate this software means adding a highly valuable asset to your employability portfolio. At a time when digital skills jobs are growing much faster than non-digital jobs, make sure to position yourself ahead of the rest by adding Excel skills to your employment portfolio.",26,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,22.0,11.0,21.0,1,554582
136,/learn/wharton-risk-models,Modeling Risk and Realities,University of Pennsylvania,4.6,20281,2028,294,"Useful quantitative models help you to make informed decisions both in situations in which the factors affecting your decision are clear, as well as in situations in which some important factors are not clear at all. In this course, you can learn how to create quantitative models to reflect complex realities, and how to include in your model elements of risk and uncertainty. You’ll also learn the methods for creating predictive models for identifying optimal choices; and how those choices change in response to changes in the model’s assumptions. You’ll also learn the basics of the measurement and management of risk. By the end of this course, you’ll be able to build your own models with your own data, so that you can begin making data-informed decisions. You’ll also be prepared for the next course in the Specialization.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,30.0,,42.0,1,41004
137,/learn/precalculus-relations-functions,Precalculus: Relations and Functions,Johns Hopkins University,4.5,18927,52,17,"This course helps to build the foundational material to use mathematics as a tool to model, understand, and interpret the world around us.  This is done through studying functions, their properties, and applications to data analysis.  Concepts of precalculus provide the set of tools for the beginning student to begin their scientific career, preparing them for future science and calculus courses. This course is designed for all students, not just those interested in further mathematics courses.  Students interested in the natural sciences, computer sciences, psychology, sociology, or similar will genuinely benefit from this introductory course, applying the skills learned to their discipline to analyze and interpret their subject material.  Students will be presented with not only new ideas, but also new applications of an old subject. Real-life data, exercise sets, and regular assessments help to motivate and reinforce the content in this course, leading to learning and mastery.",11,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,1,3420
138,/learn/intro-data-science-programacion-estadistica-r,Introducción a Data Science: Programación Estadística con R,Universidad Nacional Autónoma de México,4.7,111781,6671,2688,"Este curso te proporcionará las bases del lenguaje de programación estadística R, la lengua franca de la estadística, el cual te permitirá escribir programas que lean, manipulen y analicen datos cuantitativos. Te explicaremos la instalación del lenguaje; también verás una introducción a los sistemas base de gráficos y al paquete para graficar ggplot2, para visualizar estos datos. Además también abordarás la utilización de uno de los IDEs más populares entre la comunidad de usuarios de R, llamado RStudio.Objetivo

Al término del curso:

Utilizarás el lenguaje de programación R con el fin de manipular datos, generar análisis estadísticos y representación gráfica, a través del procesamiento de datos cuantitativos.

Forma de trabajo

Este curso busca introducirte en el lenguaje de programación estadística R, un lenguaje computacional diseñado para el análisis estadístico de datos. Este curso está dirigido a estudiantes y profesionales que tienen interés en poder utilizar esta herramienta, para leer, manipular, analizar y graficar datos. 

Utilizarás un IDE (Ambiente de Desarrollo Integrado) muy popular para trabajar con el lenguaje R, llamado RStudio, que se ha vuelto el IDE de facto para programar en R.

En cada módulo encontrarás videos que te guiarán en la instalación de las herramientas a utilizar, así como explicaciones de las operaciones básicas y los elementos específicos que ofrecen un manejo más profundo del lenguaje. También hallarás algunas referencias bibliográficas para ahondar en el tema que sea de tu interés.

Para complementar las lecciones, realizarás prácticas con el lenguaje, las cuales tendrán valor para la evaluación.",47,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,24.0,10.0,25.0,0,172843
139,/learn/ntumlone-algorithmicfoundations,機器學習基石下 (Machine Learning Foundations)---Algorithmic Foundations,National Taiwan University,4.9,7197,289,53,"Machine learning is the study that allows computers to adaptively improve their performance with experience accumulated from the data observed. Our two sister courses teach the most fundamental algorithmic, theoretical and practical tools that any user of machine learning needs to know. This second course of the two would focus more on algorithmic tools, and the other course would focus more on mathematical tools. [機器學習旨在讓電腦能由資料中累積的經驗來自我進步。我們的兩項姊妹課程將介紹各領域中的機器學習使用者都應該知道的基礎演算法、理論及實務工具。本課程將較為著重方法類的工具，而另一課程將較為著重數學類的工具。]",9,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,27.0,33.0,12.0,1,12412
140,/learn/data-collection-analytics-project,Combining and Analyzing Complex Data,"University of Maryland, College Park",4.2,4133,52,7,"In this course you will learn how to use survey weights to estimate descriptive statistics, like means and totals, and more complicated quantities like model parameters for linear and logistic regressions.  Software capabilities will be covered with R® receiving particular emphasis.  The course will also cover the basics of record linkage and statistical matching—both of which are becoming more important as ways of combining data from different sources.  Combining of datasets raises ethical issues which the course reviews.  Informed consent may have to be obtained from persons to allow their data to be linked. You will learn about differences in the legal requirements in different countries.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,17.0,,,1,6763
141,/learn/matlab-image-processing,"Introduction to Data, Signal, and Image Analysis with MATLAB",Vanderbilt University,4.8,39278,64,23,"Welcome to Introduction to Data, Signal, and Image Analysis with MATLAB!     MATLAB is an extremely versatile programming language for data, signal, and image analysis tasks. This course provides an introduction on how to use MATLAB for data, signal, and image analysis. After completing the course,  learners will understand how machine learning methods can be used in MATLAB for data classification and prediction; how to perform data visualization, including data visualization for high dimensional datasets; how to perform image processing and analysis methods, including image filtering and image segmentation; and how to perform common signal analysis tasks, including filter design and frequency analysis.",23,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,13053
142,/learn/functional-mri-2,Principles of fMRI 2,Johns Hopkins University,4.7,10877,189,30,"Functional Magnetic Resonance Imaging (fMRI) is the most widely used technique for investigating the living, functioning human brain as people perform tasks and experience mental states. It is a convergence point for multidisciplinary work from many disciplines. Psychologists, statisticians, physicists, computer scientists, neuroscientists, medical researchers, behavioral scientists, engineers, public health researchers, biologists, and others are coming together to advance our understanding of the human mind and brain.  This course covers the analysis of Functional Magnetic Resonance Imaging (fMRI) data.  It is a continuation of the course “Principles of fMRI, Part 1”.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,11895
143,/learn/data-analysis-with-python,Data Analysis with Python,IBM,4.7,715403,13147,1926,"Learn how to analyze data using Python. This course will take you from the basics of Python to exploring many different types of data. You will learn how to prepare data for analysis, perform simple statistical analysis, create meaningful data visualizations, predict future trends from data, and more!Topics covered:

1) Importing Datasets
2) Cleaning the Data
3) Data frame manipulation
4) Summarizing the Data
5) Building machine learning Regression models
6) Building data pipelines

 Data Analysis with Python will be delivered through lecture, lab, and assignments. It includes following parts:

Data Analysis libraries: will learn to use Pandas, Numpy and Scipy libraries to work with a sample dataset. We will introduce you to pandas, an open-source library, and we will use it to load, manipulate, analyze, and visualize cool datasets. Then we will introduce you to another open-source library, scikit-learn, and we will use some of its machine learning algorithms to build smart models and make cool predictions.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.",25,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,27.0,12.0,25.0,0,175731
144,/learn/wharton-quantitative-modeling,Fundamentals of Quantitative Modeling,University of Pennsylvania,4.6,103675,7066,1402,"How can you put data to work for you? Specifically, how can numbers in a spreadsheet tell us about present and past business activities, and how can we use them to forecast the future? The answer is in building quantitative models, and this course is designed to help you understand the fundamentals of this critical, foundational, business skill. Through a series of short lectures, demonstrations, and assignments, you’ll learn the key ideas and process of quantitative modeling so that you can begin to create your own models for your own business or enterprise. By the end of this course, you will have seen a variety of practical commonly used quantitative models as well as the building blocks that will allow you to start structuring your own models. These building blocks will be put to use in the other courses in this Specialization.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,29.0,,28.0,1,138324
145,/learn/machine-learning-trading-finance,Using Machine Learning in Trading and Finance,New York Institute of Finance,3.9,29656,250,63,"This course provides the foundation for developing advanced trading strategies using machine learning techniques. In this course, you’ll review the key components that are common to every trading strategy, no matter how complex. You’ll be introduced to multiple trading strategies including quantitative trading, pairs trading, and momentum trading. By the end of the course, you will be able to design basic quantitative trading strategies, build machine learning models using Keras and TensorFlow, build a pair trading strategy prediction model and back test it, and build a momentum-based trading model and back test it.To be successful in this course, you should have advanced competency in Python programming and familiarity with pertinent libraries for machine learning, such as Scikit-Learn, StatsModels, and Pandas. Experience with SQL is recommended. You should have a background in statistics (expected values and standard deviation, Gaussian distributions, higher moments, probability, linear regressions) and foundational knowledge of financial markets (equities, bonds, derivatives, market structure, hedging).",19,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,50.0,25.0,33.0,0,11782
146,/learn/google-machine-learning,How Google does Machine Learning,Google Cloud,4.6,75472,6513,1026,"What is machine learning, and what kinds of problems can it solve? Google thinks about machine learning slightly differently -- of being about logic, rather than just data. We talk about why such a framing is useful for data scientists when thinking about building a pipeline of machine learning models. Then, we discuss the five phases of converting a candidate use case to be driven by machine learning, and consider why it is important the phases not be skipped. We end with a recognition of the biases that machine learning can amplify and how to recognize this.

>>> By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,30.0,,34.0,0,96472
147,/learn/mri-fundamentals,MRI Fundamentals,Korea Advanced Institute of Science and Technology(KAIST),4.6,16692,236,78,"Welcome! In this course learners will develop expertise in basic magnetic resonance imaging (MRI) physics and principles and gain knowledge of many different data acquisition strategies in MRI. In particular, learners will get to know what is magnetic resonance phenomenon, how magnetic resonance signals are generated, how an image can be formulated using MRI, how soft tissue contrast can change with imaging parameters. Also introduced will be MR imaging sequences of spin echo, gradient echo, fast spin echo, echo planar imaging, inversion recovery, etc.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,50.0,,50.0,0,10831
148,/learn/rpa-deployment-maintenance,RPA Lifecycle: Deployment and Maintenance,Automation Anywhere,4.6,3434,63,13,"Robotic Process Automation (or RPA) implementation is conducted over multiple critical phases. In the Discovery phase, you identify the business processes beneficial for automation. In the Design phase, you create an RPA plan for automating them. In the Development and Testing phase, you execute the RPA plan and develop bots, testing them thoroughly during development.Next, you need to deploy the bots and set them up for routine monitoring. These activities are performed next in the implementation lifecycle: in the Deployment and Maintenance phases.
You can deploy bots in various devices and also monitor their performance live via the Web Control Room. This is a web-based application, with comprehensive workload management, granular security controls, and an intuitive analytics dashboard. It is the one central interface from where you can create and manage users and roles, monitor connected and disconnected devices and schedule bot execution. 
As you begin this course, you will be introduced to the user interface of the Web Control Room. You will explore various panels and components in its Features Panel. You will also study some of the best practices and troubleshooting procedures that you can apply while using the Web Control Room during RPA Deployment and Maintenance. The learning will be reinforced through concept description, hands-on tasks, and guided practice.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,3067
149,/learn/big-data-procesamiento-analisis,Big Data: procesamiento y análisis,Universitat Autònoma de Barcelona,4.2,17125,210,82,"El presente curso tiene como objetivo presentar los métodos y técnicas básicos para el procesamiento y análisis de datos en el contexto de Big Data. No prentende ser un curso exhaustivo sobre Machine Learning ni sobre métodos Estadísticos, simplemente se pretenden mostrar las características principales de estas técnicas para que el alumno pueda tener una visión general de las opciones que ofrece el análisis de datos para poder explorar, confirmar indicios y en definitiva, extraer conclusiones.El curso está dirigido a estudiantes y profesionales que deseen aproximarse al procesamiento y análisis de datos en Big Data. Aunque no es un requisito indispensable tener experiencia en análisis de datos o en entornos Big Data, el curso puede resultar especialmente interesante  a estudiantes con ciertos conocimientos de análisis de datos que deseen introducirse en el entorno Big Data, por otro lado, también resultará interesante a aquellos estudiantes con cierta experiencia en entornos Big Data que deseen adquirir una mayor visión analítica. 

En este sentido el curso pretende ofrecer recursos realistas en el contexto Big Data y por este motivo se trabajará des de una máquina virtual con la aplicación Jupyter como enlace para desarrollar los modelos y técnicas con PySpark.

El curso está dividido en 4 módulos más o menos independientes aunque se recomienda realizarlos de forma secuencial. 

En el Módulo 1 se presentan los diferentes problemas y técnicas más habitules para analizar datos desde una perspectiva general. También se introduce el caso de estudio y las herramientas de trabajo que se emplearán. El resto de módulo está dedicado a la tarea de Exploración y Pre-Proceso de los datos, incluyendo consultas, tareas de gestión, resúmenes numéricos y gráficos. Los siguientes módulos se focalizan en las técnicas de análisis.

El Módulo 2 se centra en técnicas de modelización básicas, en particular regresión y regresión logística. Además de repasar las etapas de calibración del modelo, también se incluyen las etapas de validación y simplificación.

El módulo 3 está plenamente dedicado a la técnica de Árboles de Regresión y Clasificación. También se incluyen los bosques aleatorios.  

El módulo final contiene la técnica de Redes Neuronales para clasificación y también una introducción a las técnicas No Supervisadas, en particular, reducción de dimensión a través del análisis de componentes principales y la clasificación automática a través del análisis de clústers.",13,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,,,,0,11427
150,/learn/cyber-security-manufacturing,Cyber Security in Manufacturing  ,University at Buffalo,4.7,7571,472,101,"The nature of digital manufacturing and design (DM&D), and its heavy reliance on creating a digital thread of product and process data and information, makes it a prime target for hackers and counterfeiters. This course will introduce students to why creating a strong and secure infrastructure should be of paramount concern for anyone operating in the DM&D domain, and measures that can be employed to protect operational technologies, systems and resources. Acquire knowledge about security needs and the application of information security systems. Build the foundational skills needed in performing a risk assessment of operational and information technology assets. Gain valuable insights of implementing controls to mitigate identified risks.

Main concepts of this course will be delivered through lectures, readings, discussions and various videos. 

This is the seventh course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing’s “Fourth Revolution,”  aka Industry 4.0, and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal. To learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/wETK1O9c-CA",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,11956
151,/learn/intro-practical-deep-learning,An Introduction to Practical Deep Learning,Intel,4.2,7632,129,27,"This course provides an introduction to Deep Learning, a field that aims to harness the enormous amounts of data that we are surrounded by with artificial neural networks, allowing for the development of self-driving cars, speech interfaces, genomic sequence analysis and algorithmic trading. You will explore important concepts in Deep Learning, train deep networks using Intel Nervana Neon, apply Deep Learning to various applications and explore new and emerging Deep Learning topics.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,,25.0,0,21397
152,/learn/python-machine-learning-for-investment-management,Python and Machine Learning for Asset Management ,EDHEC Business School,3.0,26830,237,101,"This course will enable you mastering machine-learning approaches in the area of investment management. It has been designed by two thought leaders in their field, Lionel Martellini from EDHEC-Risk Institute and John Mulvey from Princeton University. Starting from the basics, they will help you build practical skills to understand data science so you can make the best portfolio decisions.The course will start with an introduction to the fundamentals of machine learning, followed by an in-depth discussion of the application of these techniques to portfolio management decisions, including the design of more robust factor models, the construction of portfolios with improved diversification benefits, and the implementation of more efficient risk management models. 

We have designed a 3-step learning process: first, we will introduce a meaningful investment problem and see how this problem can be addressed using statistical techniques. Then, we will see how this new insight from Machine learning can complete and improve the relevance of the analysis.

You will have the opportunity to capitalize on videos and recommended readings to level up your financial expertise, and to use the quizzes and Jupiter notebooks to ensure grasp of concept.

At the end of this course, you will master the various machine learning techniques in investment management.",16,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,10562
153,/learn/getting-started-with-tensor-flow2,Getting started with TensorFlow 2,Imperial College London,4.9,102530,282,104,"Welcome to this course on Getting started with TensorFlow 2!In this course you will learn a complete end-to-end workflow for developing deep learning models with Tensorflow, from building, training, evaluating and predicting with models using the Sequential API, validating your models and including regularisation, implementing callbacks, and saving and loading models. 

You will put concepts that you learn about into practice straight away in practical, hands-on coding tutorials, which you will be guided through by a graduate teaching assistant. In addition there is a series of automatically graded programming assignments for you to consolidate your skills.

At the end of the course, you will bring many of the concepts together in a Capstone Project, where you will develop an image classifier deep learning model from scratch.

Tensorflow is an open source machine library, and is one of the most widely used frameworks for deep learning. The release of Tensorflow 2 marks a step change in the product development, with a central focus on ease of use for all users, from beginner to advanced level. This course is intended for both users who are completely new to Tensorflow, as well as users with experience in Tensorflow 1.x.

The prerequisite knowledge required in order to be successful in this course is proficiency in the python programming language, (this course uses python 3), knowledge of general machine learning concepts (such as overfitting/underfitting, supervised learning tasks, validation, regularisation and model selection), and a working knowledge of the field of deep learning, including typical model architectures (MLP/feedforward and convolutional neural networks), activation functions, output layers, and optimisation.",26,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,17800
154,/learn/ai,Applied AI with DeepLearning,IBM,4.4,31111,992,169,">>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area <<<This course, Applied Artificial Intelligence with DeepLearning, is part of the IBM Advanced Data Science Certificate which IBM is currently creating and gives you easy access to the invaluable insights into Deep Learning models used by experts in Natural Language Processing, Computer Vision, Time Series Analysis, and many other disciplines. We’ll learn about the fundamentals of Linear Algebra and Neural Networks. Then we introduce the most popular DeepLearning Frameworks like Keras, TensorFlow, PyTorch, DeepLearning4J and Apache SystemML. Keras and TensorFlow are making up the greatest portion of this course. We learn about Anomaly Detection, Time Series Forecasting, Image Recognition and Natural Language Processing by building up models using Keras on real-life examples from IoT (Internet of Things), Financial Marked Data, Literature or Image Databases. Finally, we learn how to scale those artificial brains using Kubernetes, Apache Spark and GPUs.

IMPORTANT: THIS COURSE ALONE IS NOT SUFFICIENT TO OBTAIN THE ""IBM Watson IoT Certified Data Scientist certificate"". You need to take three other courses where two of them are currently built. The Specialization will be ready late spring, early summer 2018

Using these approaches, no matter what your skill levels in topics you would like to master, you can change your thinking and change your life. If you’re already an expert, this peep under the mental hood will give your ideas for turbocharging successful creation and deployment of DeepLearning models. If you’re struggling, you’ll see a structured treasure trove of practical techniques that walk you through what you need to do to get on track. If you’ve ever wanted to become better at anything, this course will help serve as your guide.

Prerequisites: Some coding skills are necessary. Preferably python, but any other programming language will do fine. Also some basic understanding of math (linear algebra) is a plus, but we will cover that part in the first week as well.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  To find out more about IBM digital badges follow the link ibm.biz/badging.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,45.0,20.0,0,45228
155,/learn/sas-programming-certification-review,Practical SAS Programming and Certification Review,SAS,4.9,11364,345,62,In this course you have the opportunity to use the skills you acquired in the two SAS programming courses to solve realistic problems. This course is also designed to give you a thorough review of SAS programming concepts so you are prepared to take the SAS Certified Specialist: Base Programming Using SAS 9.4 Exam.,21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,12903
156,/learn/analytical-solutions-common-healthcare-problems,Analytical Solutions to Common Healthcare Problems,"University of California, Davis",4.3,4858,15,5,"In this course, we’re going to go over analytical solutions to common healthcare problems. I will review these business problems and you’ll build out various data structures to organize your data. We’ll then explore ways to group data and categorize medical codes into analytical categories. You will then be able to extract, transform, and load data into data structures required for solving medical problems and be able to also harmonize data from multiple sources. Finally, you will create a data dictionary to communicate the source and value of data. Creating these artifacts of data processes is a key skill when working with healthcare data.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,2604
157,/learn/formal-concept-analysis,Introduction to Formal Concept Analysis,HSE University,4.8,5419,36,14,"This course is an introduction into formal concept analysis (FCA), a mathematical theory oriented at applications in knowledge representation, knowledge acquisition, data analysis and visualization. It provides tools for understanding the data by representing it as a hierarchy of concepts or, more exactly, a concept lattice. FCA can help in processing a wide class of data types providing a framework in which various data analysis and knowledge acquisition techniques can be formulated. In this course, we focus on some of these techniques, as well as cover the theoretical foundations and algorithmic issues of FCA.Upon completion of the course, the students will be able to use the mathematical techniques and computational tools of formal concept analysis in their own research projects involving data processing. Among other things, the students will learn about FCA-based approaches to clustering and dependency mining.
The course is self-contained, although basic knowledge of elementary set theory, propositional logic, and probability theory would help.
End-of-the-week quizzes include easy questions aimed at checking basic understanding of the topic, as well as more advanced problems that may require some effort to be solved.

Do you have technical problems? Write to us: coursera@hse.ru",26,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,,,1,7112
158,/learn/intermediate-programming-capstone,Capstone: Analyzing (Social) Network Data,University of California San Diego,4.7,2672,95,22,"In this capstone project we’ll combine  all of the skills from all four specialization courses to do something really fun: analyze social networks!  The opportunities for learning are practically endless in a social network.  Who are the “influential” members of the network?  What are the sub-communities in the network?   Who is connected to whom, and by how many links?   These are just some of the questions you can explore in this project.

We will provide you with a real-world data set and some infrastructure for getting started, as well as some warm up tasks and basic project requirements, but then it’ll be up to you where you want to take the project.  If you’re running short on ideas, we’ll have several suggested directions that can help get your creativity and imagination going.  Finally, to integrate the skills you acquired in course 4 (and to show off your project!) you will be asked to create a video showcase of your final product.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,60.0,25.0,44.0,1,5374
159,/learn/css-capstone,Computational Social Science Capstone Project,"University of California, Davis",4.7,4440,18,5,"CONGRATULATIONS! Not only did you accomplish to finish our intellectual tour de force, but, by now, you also already have all required skills to execute a comprehensive multi-method workflow of computational social science. We will put these skills to work in this final integrative lab, where we are bringing it all together. We scrape data from a social media site (drawing on the skills obtained in the 1st course of this specialization). We then analyze the collected data by visualizing the resulting networks (building on the skills obtained in the 3rd course). We analyze some key aspects of it in depth, using machine learning powered natural language processing (putting to work the insights obtained during the 2nd course). Finally, we use a computer simulation model to explore possible generative mechanism and scrutinize aspects that we did not find in our empirical reality, but that help us to improve this aspect of society (drawing on the skills obtained during the 4th course of this specialization). The result is the first glimpse at a new way of doing social science in a digital age: computational social science. Congratulations! Having done all of this yourself, you can consider yourself a fledgling computational social scientist!",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,1754
160,/learn/advanced-methods-reinforcement-learning-finance,Overview of Advanced Methods of Reinforcement Learning in Finance,New York University,3.8,8750,67,11,"In the last course of our specialization, Overview of Advanced Methods of Reinforcement Learning in Finance, we will take a deeper look into topics discussed in our third course, Reinforcement Learning in Finance.In particular, we will talk about links between Reinforcement Learning, option pricing and physics, implications of Inverse Reinforcement Learning for modeling market impact and price dynamics, and perception-action cycles in Reinforcement Learning. Finally, we will overview trending and potential applications of Reinforcement Learning for high-frequency trading, cryptocurrencies, peer-to-peer lending, and more.

After taking this course, students will be able to 
- explain fundamental concepts of finance such as market equilibrium, no arbitrage, predictability,
- discuss market modeling,
- Apply the methods of Reinforcement Learning to high-frequency trading, credit risk peer-to-peer lending, and cryptocurrencies trading.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,7835
161,/learn/python-data-processing,Data Processing Using Python,Nanjing University,4.2,24259,206,68,"This course (The English copy of ""用Python玩转数据"" <https://www.coursera.org/learn/hipython/home/welcome>)  is mainly for non-computer majors. It starts with the basic syntax of Python, to how to acquire data in Python locally and from network, to how to present data, then to how to conduct basic and advanced statistic analysis and visualization of data, and finally to how to design a simple GUI to present and process data, advancing level by level. This course, as a whole, based on Finance data and through the establishment of popular cases one after another, enables learners to more vividly feel the simplicity, elegance, and robustness of Python. Also, it discusses the fast, convenient and efficient data processing capacity of Python in humanities and social sciences fields like literature, sociology and journalism and science and engineering fields like mathematics and biology, in addition to business fields. Similarly, it may also be flexibly applied into other fields.

The course has been updated. Updates in the new version are : 

1) the whole course has moved from Python 2.x to Python 3.x 
2) Added manual webpage fetching and parsing. Web API is also added. 
3) Improve the content order and enrich details of some content especially for some practice projects.

Note: videos are in Chinese (Simplified) with English subtitles. All other materials are in English.",29,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,25.0,25.0,1,40571
162,/learn/ai-for-medical-diagnosis,AI for Medical Diagnosis,DeepLearning.AI,4.7,109410,1449,318,"AI is transforming the practice of medicine. It’s helping doctors diagnose patients more accurately, make predictions about patients’ future health, and recommend better treatments. As an AI practitioner, you have the opportunity to join in this transformation of modern medicine. If you're already familiar with some of the math and coding behind AI algorithms, and are eager to develop your skills further to tackle challenges in the healthcare industry, then this specialization is for you. No prior medical expertise is required! This program will give you practical experience in applying cutting-edge machine learning techniques to concrete problems in modern medicine:

- In Course 1, you will create convolutional neural network image classification and segmentation models to make diagnoses of lung and brain disorders. 
- In Course 2, you will build risk models and survival estimators for heart disease using statistical methods and a random forest predictor to determine patient prognosis. 
- In Course 3, you will build a treatment effect predictor, apply model interpretation techniques and use natural language processing to extract information from radiology reports.

These courses go beyond the foundations of deep learning to give you insight into the nuances of applying AI to medical use cases. As a learner, you will be set up for success in this program if you are already comfortable with some of the math and coding behind AI algorithms. You don't need to be an AI expert, but a working knowledge of deep neural networks, particularly convolutional networks, and proficiency in Python programming at an intermediate level will be essential. If you are relatively new to machine learning or neural networks, we recommend that you first take the Deep Learning Specialization, offered by deeplearning.ai and taught by Andrew Ng.

The demand for AI practitioners with the skills and knowledge to tackle the biggest issues in modern medicine is growing exponentially. Join us in this specialization and begin your journey toward building the future of healthcare.",19,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,40682
163,/learn/praktiki-operativnoy-analitiki-excel,Практики оперативной аналитики в MS Excel,Saint Petersburg State University,4.8,19164,260,52,"Курс предназначен для пользователей, которым необходимо проводить анализ экономических данных. Данный курс является первым в серии курсов ""Практики анализа экономических данных. От простого к сложному"". Первый курс посвящен правилам правильной организации данных, профессиональным приемам организации расчетов и визуализации данных. Слушатель сможет применить знания базовых инструментов MS Excel для решения бизнес-кейса. Все инструменты показываются через призму типовых примеров, в которых каждый слушатель узнает свои профессиональные проблемы. Используется подход к обучению анализу данных в среде Microsoft Excel через решение типовых задач, проецируемых на любую предметную область. Данный подход апробирован авторами на большом количестве групп повышения квалификации экономистов и менеджеров. В конце курса слушателям предлагается выполнить большой практический проект. По окончании курса Вы будетеЗнать:
- категории задач, решаемые в среде электронных таблиц;
- базовые правила организации расчетов при решении экономических задач;
- правила агрегирования данных;
- методы выборки данных в соответствии с потребностями аналитика;
- базовые концепции и инструменты визуализации данных.

Уметь:
- выбирать адекватные инструменты для решения задач;
- рассчитывать операционные, агрегированные показатели деятельности компании;
- представлять диаграммы, адекватно отражающие и интерпретирующие данные таблиц;
- применять инструменты фильтрации в соответствии с поставленной задачей.

Владеть:
- навыками решения аналитических задач в среде MS Excel;
- навыками выбора адекватных инструментов графического анализа данных;
- типовыми инструментами фильтрации данных;
- технологиями формирования агрегированных показателей.",12,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,20.0,33.0,,1,12148
164,/learn/sig-2,Systèmes d’Information Géographique - Partie 2,École Polytechnique Fédérale de Lausanne,4.3,5247,34,14,"Ce cours constitue la seconde partie d'un enseignement consacré aux bases théoriques et pratiques des systèmes d’information géographique.- Il propose une introduction aux systèmes d’information géographique qui ne requiert pas de connaissances préalables en informatique.
- Il donne la possibilité d’acquérir rapidement les notions de base qui vous permettent de créer des bases de données spatiales et de fabriquer des cartes géographiques.
- Il s’agit d’un cours pratique qui repose sur l’utilisation de logiciels libres, notamment QGIS.

Lors de la première partie du cours, vous avez exploré les principes de base de la numérisation du territoire et du stockage des géodonnées. Vous avez notamment appris à :
- Caractériser des objets et des phénomènes spatiaux (modélisation du territoire) du point de vue de leur positionnement dans l’espace (systèmes de coordonnées et projections, relations spatiales) et en fonction de leur nature intrinsèque (mode objet ou vecteur vs. mode image ou raster);
- Utiliser diverses méthodes d’acquisition de données (mesure directe, géoréférencement d’images, digitalisation, source de données existantes, etc.);
- Utiliser divers modes de stockage des géodonnées (fichiers simples et bases de données relationnelles);
- Utiliser des outils de modélisation des données pour décrire et implémenter une base de données; 
- Créer des requêtes dans un langage d’interrogation et de manipulation des données.

La seconde partie du cours porte sur les méthodes d'analyse spatiale et les techniques de représentation de l'information géoréférencée. Vous apprendrez notamment à:
- Analyser les propriétés spatiales de variables discrètes, par exemple en quantifiant l’autocorrélation spatiale;
- Travailler avec des variables continues (échantillonnage, interpolation et construction de courbes d’isovaleurs)
- Utiliser les modèles numériques d'altitude et leurs dérivées (pente, orientation, etc.);
- Utiliser des techniques de superposition des géodonnées;
- Produire des documents cartographiques selon les règles de la sémiologie graphique;
- Explorer d’autres formes de représentation spatiale (cartographie interactive sur internet, représentations 3D, et réalité augmentée).

La page https://www.facebook.com/moocsig fournit un forum interactif pour les participants à ce cours.",13,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,,,,0,6718
165,/learn/introduction-clinical-data,Introduction to Clinical Data,Stanford University,4.6,39917,95,19,This course introduces you to a framework for successful and ethical medical data mining. We will explore the variety of clinical data collected during the delivery of healthcare. You will learn to construct analysis-ready datasets and apply computational procedures to answer clinical questions. We will also explore issues of fairness and bias that may arise when we leverage healthcare data to make decisions about patient care.The Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.  Visit the FAQs below for important information regarding 1) Date of original release and Termination or expiration date; 2) Accreditation and Credit Designation statements; 3) Disclosure of financial relationships for every person in control of activity content.,12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,4839
166,/learn/data-results,Communicating Data Science Results,University of Washington,3.6,2586,134,37,"Important note: The second assignment in this course covers the topic of Graph Analysis in the Cloud, in which you will use Elastic MapReduce and the Pig language to perform graph analysis over a moderately large dataset, about 600GB. In order to complete this assignment, you will need to make use of Amazon Web Services (AWS). Amazon has generously offered to provide up to $50 in free AWS credit to each learner in this course to allow you to complete the assignment. Further details regarding the process of receiving this credit are available in the welcome message for the course, as well as in the assignment itself. Please note that Amazon, University of Washington, and Coursera cannot reimburse you for any charges if you exhaust your credit.While we believe that this assignment contributes an excellent learning experience in this course, we understand that some learners may be unable or unwilling to use AWS. We are unable to issue Course Certificates for learners who do not complete the assignment that requires use of AWS. As such, you should not pay for a Course Certificate in Communicating Data Results if you are unable or unwilling to use AWS, as you will not be able to successfully complete the course without doing so.

Making predictions is not enough!  Effective data scientists know how to explain and interpret their results, and communicate findings accurately to stakeholders to inform business decisions.  Visualization is the field of research in computer science that studies effective communication of quantitative results by linking perception, cognition, and algorithms to exploit the enormous bandwidth of the human visual cortex.  In this course you will learn to recognize, design, and use effective visualizations.

Just because you can make a prediction and convince others to act on it doesn’t mean you should.  In this course you will explore the ethical considerations around big data and how these considerations are beginning to influence policy and practice.   You will learn the foundational limitations of using technology to protect privacy and the codes of conduct emerging to guide the behavior of data scientists.  You will also learn the importance of reproducibility in data science and how the commercial cloud can help support reproducible research even for experiments involving massive datasets, complex computational infrastructures, or both.

Learning Goals: After completing this course, you will be able to:
1. Design and critique visualizations
2. Explain the state-of-the-art in privacy, ethics, governance around big data and data science
3. Use cloud computing to analyze large datasets in a reproducible way.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,60.0,33.0,67.0,1,15246
167,/learn/financial-risk-management-with-r,Financial Risk Management with R,Duke University,4.5,23398,175,67,"This course teaches you how to calculate the return of a portfolio of securities as well as quantify the market risk of that portfolio, an important skill for financial market analysts in banks, hedge funds, insurance companies, and other financial services and investment firms. Using the R programming language with Microsoft Open R and RStudio, you will use the two main tools for calculating the market risk of stock portfolios: Value-at-Risk (VaR) and Expected Shortfall (ES). You will need a beginner-level understanding of R programming to complete the assignments of this course.",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,8531
168,/learn/evaluations-ai-applications-healthcare,Evaluations of AI Applications in Healthcare,Stanford University,4.5,27691,73,22,"With artificial intelligence applications proliferating throughout the healthcare system, stakeholders are faced with both opportunities and challenges of these evolving technologies. This course explores the principles of AI deployment in healthcare and the framework used to evaluate downstream effects of AI healthcare solutions.The Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.  Visit the FAQs below for important information regarding 1) Date of original release and Termination or expiration date; 2) Accreditation and Credit Designation statements; 3) Disclosure of financial relationships for every person in control of activity content.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,3154
169,/learn/analytics-business-metrics,Business Metrics for Data-Driven Companies,Duke University,4.6,128379,7779,1612,"In this course, you will learn best practices for how to use data analytics to make any company more competitive and more profitable. You will be able to recognize the most critical business metrics and distinguish them from mere data.You’ll get a clear picture of the vital but different roles business analysts, business data analysts, and data scientists each play in various types of companies. And you’ll know exactly what skills are required to be hired for, and succeed at, these high-demand jobs.
 
Finally, you will be able to use a checklist provided in the course to score any company on how effectively it is embracing big data culture. Digital companies like Amazon, Uber and Airbnb are transforming entire industries through their creative use of big data. You’ll understand why these companies are so disruptive and how they use data-analytics techniques to out-compete traditional companies.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,23.0,11.0,23.0,1,236810
170,/learn/estrategia-marketing-digital,Marketing Digital,Universidade de São Paulo,4.8,132500,1691,502,"Aprenda a desenvolver a estratégia de marketing digital para a sua empresa ou startup, nesse curso você irá aprender sobre os principais pontos do Marketing como ROI, SEO, SEM, Testes AB e como gerenciar o funil de conversão e também como usar plataformas como Google adwords e Analytics, Facebook Ads e Email Marketing.Esse curso é ministrado por profissionais do mercado que vão apresentar como aplicar cada um dos conceitos com aulas teóricas e práticas.

Neste curso serão abordados os seguintes temas:
Diferença entre o marketing tradicional
Importância do ROI e como calcular
Introdução a funil
Google Analytics
Google Adwords 
Tipos de canais
Como funciona SEM
Como funciona SEO
Como funciona Facebook Ads
Como funciona Email Marketing
Configurando e planejando campanhas
Testes AB
Como escolher sua estratégia
Metrificação e iteração

Ao final desse curso, esperamos que você esteja familiarizado com os principais conceitos, ferramentas e metodologias do marketing digital.

Não deixe de ver as perguntas frequentes antes de se inscrever

Conheça os nossos outros cursos:
- Criação de Startups: Como desenvolver negócios inovadores
       https://www.coursera.org/learn/criacao-startups  
- UX / UI: Fundamentos para o design de interface
       https://www.coursera.org/learn/ux-ui-design-de-interface 
- Consolidando empresas: Estrutura jurídica e financeira
       https://www.coursera.org/learn/consolidando-empresas
- Inove na gestão de equipes e negócios: o crescimento da empresa
       https://www.coursera.org/learn/gestao-equipes-negocios 
- Marketing e vendas B2B: fechando novos negócios
       https://www.coursera.org/learn/marketing-vendas-b2b",16,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,40.0,14.0,31.0,0,130733
171,/learn/data-management,Research Data Management and Sharing,The University of North Carolina at Chapel Hill,4.7,21617,509,144,"This course will provide learners with an introduction to research data management and sharing. After completing this course, learners will understand the diversity of data and their management needs across the research data lifecycle, be able to identify the components of good data management plans, and be familiar with best practices for working with data including the organization, documentation, and storage and security of data. Learners will also understand the impetus and importance of archiving and sharing data as well as how to assess the trustworthiness of repositories. Today, an increasing number of funding agencies, journals, and other stakeholders are requiring data producers to share, archive, and plan for the management of their data. In order to respond to these requirements, researchers and information professionals will need the data management and curation knowledge and skills that support the long-term preservation, access, and reuse of data. Effectively managing data can also help optimize research outputs, increase the impact of research, and support open scientific inquiry. After completing this course, learners will be better equipped to manage data throughout the entire research data lifecycle from project planning to the end of the project when data ideally are shared and made available within a trustworthy repository.

This course was developed by the Curating Research Assets and Data Using Lifecycle Education (CRADLE) Project in collaboration with EDINA at the University of Edinburgh. 

This course was made possible in part by the Institute of Museum and Library Services under award #RE-06-13-0052-13. The views, findings, conclusions or recommendations expressed in this Research Data Management and Sharing MOOC do not necessarily represent those of the Institute of Museum and Library Services.

Hashtag: #RDMSmooc",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,20.0,,21.0,1,25437
172,/learn/probability-statistics,Probability and Statistics: To p or not to p?,University of London,4.6,67062,1117,391,"We live in an uncertain and complex world, yet we continually have to make decisions in the present with uncertain future outcomes.  Indeed, we should be on the look-out for ""black swans"" - low-probability high-impact events.To study, or not to study?  To invest, or not to invest?  To marry, or not to marry?

While uncertainty makes decision-making difficult, it does at least make life exciting!  If the entire future was known in advance, there would never be an element of surprise.  Whether a good future or a bad future, it would be a known future.

In this course we consider many useful tools to deal with uncertainty and help us to make informed (and hence better) decisions - essential skills for a lifetime of good decision-making.

Key topics include quantifying uncertainty with probability, descriptive statistics, point and interval estimation of means and proportions, the basics of hypothesis testing, and a selection of multivariate applications of key terms and concepts seen throughout the course.",16,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,14.0,,20.0,1,56185
173,/learn/missing-data,Dealing With Missing Data,"University of Maryland, College Park",3.8,6887,110,30,"This course will cover the steps used in weighting sample surveys, including methods for adjusting for nonresponse and using data external to the survey for calibration.  Among the techniques discussed are adjustments using estimated response propensities, poststratification, raking, and general regression estimation.  Alternative techniques for imputing values for missing items will be discussed.  For both weighting and imputation, the capabilities of different statistical software packages will be covered, including R®, Stata®, and SAS®.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,9638
174,/learn/wharton-capstone-analytics,Business Analytics Capstone,University of Pennsylvania,4.5,30033,622,152,"The Business Analytics Capstone Project gives you the opportunity to apply what you've learned about how to make data-driven decisions to a real business challenge faced by global technology companies like Yahoo, Google, and Facebook. At the end of this Capstone, you'll be able to ask the right questions of the data, and know how to use data effectively to address business challenges of your own. You’ll understand how cutting-edge businesses use data to optimize marketing, maximize revenue, make operations efficient, and make hiring and management decisions so that you can apply these strategies to your own company or business. Designed with Yahoo to give you invaluable experience in evaluating and creating data-driven decisions, the Business Analytics Capstone Project provides the chance for you to devise a plan of action for optimizing data itself to provide key insights and analysis, and to describe the interaction between key financial and non-financial indicators. Once you complete your analysis, you'll be better prepared to make better data-driven business decisions of your own.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,28.0,21.0,26.0,1,7063
175,/learn/data-analytics-business-capstone,Advanced Business Analytics Capstone,University of Colorado Boulder,4.3,12122,51,17,"The analytics process is a collection of interrelated activities that lead to better decisions and to a higher business performance. The capstone of this specialization is designed with the goal of allowing you to experience this process. The capstone project will take you from data to analysis and models, and ultimately to presentation of insights. In this capstone project, you will analyze the data on financial loans to help with the investment decisions of an investment company. You will go through all typical steps of a data analytics project, including data understanding and cleanup, data analysis, and presentation of analytical results. 
For the first week, the goal is to understand the data and prepare the data for analysis. As we discussed  in this specialization, data preprocessing and cleanup is often the first step in data analytics projects. Needless to say, this step is crucial for the success of this project.  

In the second week, you will perform some predictive analytics tasks, including classifying loans and predicting losses from defaulted loans. You will try a variety of tools and techniques  this week, as the predictive accuracy of different tools can vary quite a bit. It is rarely the case that the default model produced by ASP is the best model possible. Therefore, it is important for you to tune the different models in order to improve the performance.

Beginning in the third week, we turn our attention to prescriptive analytics, where you will provide some concrete suggestions on how to allocate investment funds using analytics tools, including clustering and simulation based optimization. You will see that allocating funds wisely is crucial for the financial return of the investment portfolio.

In the last week, you are expected to present your analytics results to your clients. Since you will obtain many results in your project, it is important for you to judiciously choose what to include in your presentation. You are also expected to follow the principles we covered in the courses in preparing your presentation.",19,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,6529
176,/learn/gis-capstone,Geospatial Analysis Project,"University of California, Davis",4.8,16951,223,67,"In this project-based course, you will design and execute a complete GIS-based analysis – from identifying a concept, question or issue you wish to develop, all the way to final data products and maps that you can add to your portfolio. Your completed project will demonstrate your mastery of the content in the GIS Specialization and is broken up into four phases:Milestone 1: Project Proposal - Conceptualize and design your project in the abstract, and write a short proposal that includes the project description, expected data needs, timeline, and how you expect to complete it.

Milestone 2: Workflow Design - Develop the analysis workflow for your project, which will typically involve creating at least one core algorithm for processing your data. The model need not be complex or complicated, but it should allow you to analyze spatial data for a new output or to create a new analytical map of some type.

Milestone 3: Data Analysis – Obtain and preprocess data, run it through your models or other workflows in order to get your rough data products, and begin creating your final map products and/or analysis.

Milestone 4: Web and Print Map Creation – Complete your project by submitting usable and attractive maps and your data and algorithm for peer review and feedback.",62,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,50.0,25.0,46.0,1,7522
177,/learn/deep-learning-reinforcement-learning,Deep Learning and Reinforcement Learning,IBM,4.7,40130,24,5,"This course introduces you to two of the most sought-after disciplines in Machine Learning: Deep Learning and Reinforcement Learning. Deep Learning is a subset of Machine Learning that has applications in both Supervised and Unsupervised Learning, and is frequently used to power most of the AI applications that we use on a daily basis. First you will learn about the theory behind Neural Networks, which are the basis of Deep Learning, as well as several modern architectures of Deep Learning. Once you have developed a few  Deep Learning models, the course will focus on Reinforcement Learning, a type of Machine Learning that has caught up more attention recently. Although currently Reinforcement Learning has only a few practical applications, it is a promising area of research in AI that might become relevant in the near future.After this course, if you have followed the courses of the IBM Specialization in order, you will have considerable practice and a solid understanding in the main types of Machine Learning which are: Supervised Learning, Unsupervised Learning, Deep Learning, and Reinforcement Learning.

By the end of this course you should be able to:
Explain the kinds of problems suitable for Unsupervised Learning approaches
Explain the curse of dimensionality, and how it makes clustering difficult with many features
Describe and use common clustering and dimensionality-reduction algorithms
Try clustering points where appropriate, compare the performance of per-cluster models
Understand metrics relevant for characterizing clusters

Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Deep Learning and Reinforcement Learning.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Unsupervised Learning, Supervised Learning, Calculus, Linear Algebra, Probability, and Statistics.",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2654
178,/learn/data-scientists-tools,The Data Scientist’s Toolbox,Johns Hopkins University,4.6,617557,31308,6659,"In this course you will get an introduction to the main tools and ideas in the data scientist's toolbox. The course gives an overview of the data, questions, and tools that data analysts and data scientists work with. There are two components to this course. The first is a conceptual introduction to the ideas behind turning data into actionable knowledge. The second is a practical introduction to the tools that will be used in the program like version control, markdown, git, GitHub, R, and RStudio.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,30.0,,32.0,1,616486
179,/learn/hypothesis-testing-public-health,Hypothesis Testing in Public Health ,Johns Hopkins University,4.8,26827,419,98,"Biostatistics is an essential skill for every public health researcher because it provides a set of precise methods for extracting meaningful conclusions from data. In this second course of the Biostatistics in Public Health Specialization, you'll learn to evaluate sample variability and apply statistical hypothesis testing methods. Along the way, you'll perform calculations and interpret real-world data from the published scientific literature. Topics include sample statistics, the central limit theorem, confidence intervals, hypothesis testing, and p values.",19,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,20.0,,25.0,1,9002
180,/learn/apply-generative-adversarial-networks-gans,Apply Generative Adversarial Networks (GANs),DeepLearning.AI,4.8,48787,278,60,"In this course, you will:- Explore the applications of GANs and examine them wrt data augmentation, privacy, and anonymity
- Leverage the image-to-image translation framework and identify applications to modalities beyond images
- Implement Pix2Pix, a paired image-to-image translation GAN, to adapt satellite images into map routes (and vice versa)
- Compare paired image-to-image translation to unpaired image-to-image translation and identify how their key difference necessitates different GAN architectures
- Implement CycleGAN, an unpaired image-to-image translation model, to adapt horses to zebras (and vice versa) with two GANs in one

The DeepLearning.AI Generative Adversarial Networks (GANs) Specialization provides an exciting introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach. It also covers social implications, including bias in ML and the ways to detect it, privacy preservation, and more.

Build a comprehensive knowledge base and gain hands-on experience in GANs. Train your own model using PyTorch, use it to create images, and evaluate a variety of advanced GANs. 

This Specialization provides an accessible pathway for all levels of learners looking to break into the GANs space or apply GANs to their own projects, even without prior familiarity with advanced math and machine learning research.",26,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,8885
181,/learn/causal-effects,Measuring Causal Effects in the Social Sciences,University of Copenhagen,4.2,8169,193,46,"How can we know if the differences in wages between men and women are caused by discrimination or differences in background characteristics? In this PhD-level course we look at causal effects as opposed to spurious relationships. We will discuss how they can be identified in the social sciences using quantitative data, and describe how this can help us understand social mechanisms.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17.0,17.0,,1,13266
182,/learn/reproducible-research,Reproducible Research,Johns Hopkins University,4.6,53699,4024,574,"This course focuses on the concepts and tools behind reporting modern data analyses in a reproducible manner. Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them.  The need for reproducibility is increasing dramatically as data analyses become more complex, involving larger datasets and more sophisticated computations. Reproducibility allows for people to focus on the actual content of a data analysis, rather than on superficial details reported in a written summary. In addition, reproducibility makes an analysis more useful to others because the data and code that actually conducted the analysis are available. This course will focus on literate statistical analysis tools which allow one to publish data analyses in a single document that allows others to easily execute the same analysis to obtain the same results.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,35.0,13.0,31.0,1,90766
183,/learn/data-analysis-capstone,Data Analysis and Interpretation Capstone,Wesleyan University,4.7,2492,38,7,"The Capstone project will allow you to continue to apply and refine the data analytic techniques learned from the previous courses in the Specialization to address an important issue in society. You will use real world data to complete a project with our industry and academic partners. For example, you can work with our industry partner, DRIVENDATA, to help them solve some of the world's biggest social challenges! DRIVENDATA at www.drivendata.org, is committed to bringing cutting-edge practices in data science and crowdsourcing to some of the world's biggest social challenges and the organizations taking them on. Or, you can work with our other industry partner, The Connection (www.theconnectioninc.org) to help them better understand recidivism risk for people on parole seeking substance use treatment. For more than 40 years, The Connection has been one of Connecticut’s leading private, nonprofit human service and community development agencies. Each month, thousands of people are assisted by The Connection’s diverse behavioral health, family support and community justice programs. The Connection’s Institute for Innovative Practice was created in 2010 to bridge the gap between researchers and practitioners in the behavioral health and criminal justice fields with the goal of developing maximally effective, evidence-based treatment programs. 

A major component of the Capstone project is for you to be able to choose the information from your analyses that best conveys results and implications, and to tell a compelling story with this information. By the end of the course, you will have a professional quality report of your findings that can be shown to colleagues and potential employers to demonstrate the skills you learned by completing the Specialization.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,,50.0,1,3257
184,/learn/gis-mapping-spatial-analysis-capstone,"GIS, Mapping, and Spatial Analysis Capstone",University of Toronto,4.9,15848,200,67,"In this capstone course, you will apply everything you have learned by designing and then completing your own GIS project. You will plan out your project by writing a brief proposal that explains what you plan to do and why. You will then find data for a topic and location of your choice, and perform analysis and create maps that allow you to try out different tools and data sets. The results of your work will be assembled into an Esri story map, which is a web site with maps, images, text, and video. The goal is for you to have a finished product that you can share, and that demonstrates what you have learned.Note: software is not provided for this course.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,9110
185,/learn/feature-engineering-matlab,Data Processing and Feature Engineering with MATLAB,MathWorks,4.7,23233,277,97,"In this course, you will build on the skills learned in Exploratory Data Analysis with MATLAB to lay the foundation required for predictive modeling.  This intermediate-level course is useful to anyone who needs to combine data from multiple sources or times and has an interest in modeling.  These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background. To be successful in this course, you should have some background in basic statistics (histograms, averages, standard deviation, curve fitting, interpolation) and have completed Exploratory Data Analysis with MATLAB. 

Throughout the course, you will merge data from different data sets and handle common scenarios, such as missing data.  In the last module of the course, you will explore special techniques for handling textual, audio, and image data, which are common in data science and more advanced modeling.   By the end of this course, you will learn how to visualize your data, clean it up and arrange it for analysis, and identify the qualities necessary to answer your questions.  You will be able to visualize the distribution of your data and use visual inspection to address artifacts that affect accurate modeling.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,10647
186,/learn/data-what-it-is-what-can-we-do-with-it,"Data – What It Is, What We Can Do With It",Johns Hopkins University,4.5,18850,49,10,"This course introduces students to data and statistics.  By the end of the course, students should be able to interpret descriptive statistics, causal analyses and visualizations to draw meaningful insights.  The course first introduces a framework for thinking about the various purposes of statistical analysis.  We’ll talk about how analysts use data for descriptive, causal and predictive inference.  We’ll then cover how to develop a research study for causal analysis, compute and interpret descriptive statistics and design effective visualizations.  The course will help you to become a thoughtful and critical consumer of analytics. 

If you are in a field that increasingly relies on data-driven decision making, but you feel unequipped to interpret and evaluate data, this course will help you develop these fundamental tools of data literacy.",11,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,1,2096
187,/learn/julia-programming,Julia Scientific Programming,University of Cape Town,4.5,31193,368,123,"This four-module course introduces users to Julia as a first language.  Julia is a high-level, high-performance dynamic programming language developed specifically for scientific computing. This language will be particularly useful for applications in physics, chemistry, astronomy, engineering, data science, bioinformatics and many more. As open source software, you will always have it available throughout your working life. It can also be used from the command line, program files or a new type of interface known as a Jupyter notebook (which is freely available as a service from JuliaBox.com).Julia is designed to address the requirements of high-performance numerical and scientific computing while also being effective for general-purpose programming. You will be able to access all the available processors and memory, scrape data from anywhere on the web, and have it always accessible through any device you care to use as long as it has a browser.  Join us to discover new computing possibilities. Let's get started on learning Julia.

By the end of the course you will be able to:
- Programme using the Julia language by practising through assignments
- Write your own simple Julia programs from scratch
- Understand the advantages and capacities of Julia as a computing language
- Work in Jupyter notebooks using the Julia language
- Use various Julia packages such as  Plots, DataFrames and Stats

The course is delivered through video lectures, on-screen demonstrations, quizzes and practical peer-reviewed projects designed to give you an opportunity to work with the packages.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,17.0,,17.0,1,28861
188,/learn/supervised-learning-regression,Supervised Learning: Regression,IBM,4.8,44472,74,13,"This course introduces you to one of the main types of modelling families of supervised Machine Learning: Regression. You will learn how to train regression models to predict continuous outcomes and how to use error metrics to compare across different models. This course also walks you through best practices, including train and test splits, and regularization techniques.By the end of this course you should be able to:
Differentiate uses and applications of classification and regression in the context of supervised machine learning 
Describe and use linear regression models
Use a variety of error metrics to compare and select a linear regression model that best suits your data
Articulate why regularization may help prevent overfitting
Use regularization regressions: Ridge, LASSO, and Elastic net
 
Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience  with Supervised Machine Learning Regression techniques in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Probability, and Statistics.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,3708
189,/learn/text-mining-analytics,Hands-on Text Mining and Analytics,Yonsei University,3.9,5276,39,9,"This course provides an unique opportunity for you to learn key components of text mining and analytics aided by the real world datasets and the text mining toolkit written in Java. Hands-on experience in core text mining techniques including text preprocessing, sentiment analysis, and topic modeling help learners be trained to be a competent data scientists. Empowered by bringing lecture notes together with lab sessions based on the y-TextMiner toolkit developed for the class, learners will be able to develop interesting text mining applications.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,12720
190,/learn/regression-models,Regression Models,Johns Hopkins University,4.4,75626,3219,545,"Linear models, as their name implies, relates an outcome to a set of predictors of interest using linear assumptions.  Regression models, a subset of linear models, are the most important statistical analysis tool in a data scientist’s toolkit. This course covers regression analysis, least squares and inference using regression models. Special cases of the regression model, ANOVA and ANCOVA will be covered as well. Analysis of residuals and variability will be investigated. The course will cover modern thinking on model selection and novel uses of regression models including scatterplot smoothing.",54,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,23.0,14.0,19.0,1,127224
191,/learn/recommender-systems-introduction,Introduction to Recommender Systems:  Non-Personalized and Content-Based,University of Minnesota,4.5,18549,574,120,"This course, which is designed to serve as the first course in the Recommender Systems specialization, introduces the concept of recommender systems, reviews several examples in detail, and leads you through non-personalized recommendation using summary statistics and product associations, basic stereotype-based or demographic recommendations, and content-based filtering recommendations. After completing this course, you will be able to compute a variety of recommendations from datasets using basic spreadsheet tools, and if you complete the honors track you will also have programmed these recommendations using the open source LensKit recommender toolkit.  

In addition to detailed lectures and interactive exercises, this course features interviews with several leaders in research and practice on advanced topics and current directions in recommender systems.",23,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,42.0,20.0,50.0,1,28987
192,/learn/matrix-methods,Matrix Methods,University of Minnesota,4.1,7663,165,45,"Mathematical Matrix Methods lie at the root of most methods of machine learning and data analysis of tabular data.  Learn the basics of Matrix Methods, including matrix-matrix multiplication, solving linear equations, orthogonality, and best least squares approximation.   Discover the Singular Value Decomposition that plays a fundamental role in dimensionality reduction, Principal Component Analysis, and noise reduction.  Optional examples using Python are used to illustrate the concepts and allow the learner to experiment with the algorithms.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,6655
193,/learn/gis-data-acquisition-map-design,GIS Data Acquisition and Map Design,University of Toronto,4.9,42967,454,139,"In this course, you will learn how to find GIS data for your own projects, and how to create a well-designed map that effectively communicates your message. The first section focuses on the basic building blocks of GIS data, so that you know what types of GIS files exist, and the implications of choosing one type over another. Next, we'll discuss metadata (which is information about a data set) so you know how to evaluate a data set before you decide to use it, as well as preparing data by merging and clipping files as needed. We'll then talk about how to take non-GIS data, such as a list of addresses, and convert it into ""mappable"" data using geocoding. Finally, you'll learn about how to take data that you have found and design a map using cartographic principles. In the course project, you will find your own data and create your own quantitative map.Note: software is not provided for this course.",20,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,25.0,50.0,,1,15958
194,/learn/basic-statistics,Basic Statistics,University of Amsterdam,4.6,261218,3706,939,"Understanding statistics is essential to understand research in the social and behavioral sciences. In this course you will learn the basics of statistics; not just how to calculate them, but also how to evaluate them. This course will also prepare you for the next course in the specialization - the course Inferential Statistics. In the first part of the course we will discuss methods of descriptive statistics. You will learn what cases and variables are and how you can compute measures of central tendency (mean, median and mode) and dispersion (standard deviation and variance). Next, we discuss how to assess relationships between variables, and we introduce the concepts correlation and regression. 

The second part of the course is concerned with the basics of probability: calculating probabilities, probability distributions and sampling distributions. You need to know about these things in order to understand how inferential statistics work. 

The third part of the course consists of an introduction to methods of inferential statistics - methods that help us decide whether the patterns we see in our data are strong enough to draw conclusions about the underlying population we are interested in. We will discuss confidence intervals and significance tests.

You will not only learn about all these statistical concepts, you will also be trained to calculate and generate these statistics yourself using freely available statistical software.",27,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,28.0,,38.0,1,228848
195,/learn/computational-neuroscience,Computational Neuroscience,University of Washington,4.6,62429,834,197,"This course provides an introduction to basic computational methods for understanding what nervous systems do and for determining how they function. We will explore the computational principles governing various aspects of vision, sensory-motor control, learning, and memory. Specific topics that will be covered include representation of information by spiking neurons, processing of information in neural networks, and algorithms for adaptation and learning. We will make use of Matlab/Octave/Python demonstrations and exercises to gain a deeper understanding of concepts and methods introduced in the course. The course is primarily aimed at third- or fourth-year undergraduates and beginning graduate students, as well as professionals and distance learners interested in learning how the brain processes information.",26,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,15.0,,,1,83862
196,/learn/wharton-decision-making-scenarios,Decision-Making and Scenarios,University of Pennsylvania,4.6,19223,1584,214,"This course is designed to show you how use quantitative models to transform data into better business decisions. You’ll learn both how to use models to facilitate decision-making and also how to structure decision-making for optimum results. Two of Wharton’s most acclaimed professors will show you the step-by-step processes of modeling common business and financial scenarios, so you can significantly improve your ability to structure complex problems and derive useful insights about alternatives. Once you’ve created models of existing realities, possible risks, and alternative scenarios, you can determine the best solution for your business or enterprise, using the decision-making tools and techniques you’ve learned in this course.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,20.0,,20.0,1,36146
197,/learn/excel-data-visualization,Data Visualization in Excel,Macquarie University,4.9,90171,50,20,"In an age now driven by ""big data"", we need to cut through the noise and present key information in a way that can be quickly consumed and acted upon making data visualization an increasingly important skill. Visualizations need to not only present data in an easy to understand and attractive way, but they must also provide context for the data, tell a story, achieving that fine balance between form and function. Excel has many rivals in this space, but it is still an excellent choice, particularly if it's where your data resides. It offers a wealth of tools for creating visualizations other than charts and the chart options available are constantly increasing and improving, so the newer versions now include waterfall charts, sunburst diagrams and even map charts. But what sets Excel apart is its flexibility, it gives us total creative control over our designs so if needed we could produce our own animated custom chart to tell the right story for our data.Over five weeks we will explore Excel's rich selection of visualization tools using practical case studies as seen through the eyes of Rohan, an environmental analyst. Rohan is required to produce visualizations that will show trends, forecasts, breakdowns and comparisons for a large variety of environmental data sets. As well as utilising the usual chart types he wants to use conditional formats, sparklines, specialised charts and even create his own animated charts and infographics. In some cases, he will also need to prepare the data using pivot tables to drill down and answer very specific questions. We are going to help him achieve all this and present our finished visualizations in attractive reports and dashboards that use tools like slicers and macros for automation and interactivity.

These are the topics we will cover:
Week 1: 	Dynamic visualizations with conditional formatting, custom number formatting, sparklines and macros
Week 2: 	Charting techniques for telling the right story
Week 3: 	Creating specialised and custom charts
Week 4: 	Summarising and filtering data with pivot tables and pivot charts
Week 5: 	Creating interactive dashboards in Excel

This is the second course in our Specialization on Data Analytics and Visualization. The first course: Excel Fundamentals for Data Analysis, covers data preparation and cleaning but also teaches some of the prerequisites for this course like tables and named ranges as well as text, lookup and logical functions. To get the most out of this course we would recommend you do the first course or have experience with these topics. In this course we focus on Data Visualization in Excel, join us for this exciting journey.",18,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,1,5230
198,/learn/excel-essentials-es,Habilidades de Excel para el negocio: Conceptos básicos,Macquarie University,4.6,52668,13,4,"En este primer curso de la especialización de habilidades de Excel para el negocio, aprenderá los conceptos básicos de Microsoft Excel. En seis semanas, podrá navegar, de forma experta, a través de la interfaz de usuario de Excel, realizar cálculos básicos con fórmulas y funciones, dar formato profesional a hojas de cálculo y crear visualizaciones de datos a través de gráficos y cuadros.Ya sea que usted sea autodidacta y desee eliminar ciertas deficiencias a fin de obtener una mejor eficiencia y productividad, o si nunca ha usado Excel antes, este curso lo preparará con una base sólida para convertirse en un usuario seguro y desarrollar habilidades más avanzadas en cursos posteriores. 

Hemos reunido un gran equipo de enseñanza que estará con usted en cada paso del camino. Una amplia gama de cuestionarios de práctica y desafíos le brindarán grandes oportunidades para desarrollar sus habilidades. Trabaje en cada desafío nuevo con nuestro equipo y en poco tiempo se sorprenderá con lo lejos que ha llegado. 

El software de hoja de cálculo es uno de los componentes de software más ubicuos que se utilizan en lugares de trabajo de todo el mundo. Aprender a operar con confianza este software significa agregar un activo muy valioso a su cartera de empleabilidad. En un momento en que los trabajos que requieren habilidades digitales están creciendo mucho más rápido que los trabajos que no las requieren, asegúrese de colocarse por delante del resto agregando habilidades de Excel a su cartera de empleo.",26,1,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,,,,1,1642
199,/learn/big-data-proyecto,Big Data: capstone project,Universitat Autònoma de Barcelona,4.7,2090,44,21,"En este último curso de la Especialización Big Data el estudiante tendrá la oportunidad de aplicar algunas de las herramientas y métodos aprendidos en los cursos anteriores en un caso práctico.El objetivo de este Capstone Project es mostrar un ejemplo del trabajo que se realiza diariamente en el departamento de Cosmología del Port d’Informació Científica, en Barcelona. Se trata de crear un clasificador para imágenes de galaxias, a partir de datos del proyecto GalaxyZoo e imágenes y datos del telescopio Sloan Digital Sky Survey. Los trabajos y ejercicios guiados llevarán al estudiante a la exploración y analisis de estos datos, hasta realizar una herramienta automática de Machine Learning.

El proceso seguido por los estudiantes en este curso se podría aplicar en cualquier otra disciplina, por ejemplo en las ciencias sociales, en un estudio de mercado o en cualquier ámbito que comporte toma de decisiones a partir de un gran volumen de datos.",13,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,,,,0,3649
200,/learn/analytics-excel,Mastering Data Analysis in Excel,Duke University,4.2,129694,3675,881,"Important: The focus of this course is on math - specifically, data-analysis concepts and methods - not on Excel for its own sake. We use Excel to do our calculations, and all math formulas are given as Excel Spreadsheets, but we do not attempt to cover Excel Macros, Visual Basic, Pivot Tables, or other intermediate-to-advanced Excel functionality.This course will prepare you to design and implement realistic predictive models based on data. In the Final Project (module 6) you will assume the role of a business data analyst for a bank, and develop two different predictive models to determine which applicants for credit cards should be accepted and which rejected. Your first model will focus on minimizing default risk, and your second on maximizing bank profits. The two models should demonstrate to you in a practical, hands-on way the idea that your choice of business metric drives your choice of an optimal model.

The second big idea this course seeks to demonstrate is that your data-analysis results cannot and should not aim to eliminate all uncertainty. Your role as a data-analyst is to reduce uncertainty for decision-makers by a financially valuable increment, while quantifying how much uncertainty remains. You will learn to calculate and apply to real-world examples the most important uncertainty measures used in business, including classification error rates, entropy of information, and confidence intervals for linear regression.

All the data you need is provided within the course, all assignments are designed to be done in MS Excel, and you will learn enough Excel to complete all assignments. The course will give you enough practice with Excel to become fluent in its most commonly used business functions, and you’ll be ready to learn any other Excel functionality you might need in the future (module 1).

The course does not cover Visual Basic or Pivot Tables and you will not need them to complete the assignments. All advanced concepts are demonstrated in individual Excel spreadsheet templates that you can use to answer relevant questions. You will emerge with substantial vocabulary and practical knowledge of how to apply business data analysis methods based on binary classification (module 2), information theory and entropy measures (module 3), and linear regression (module 4 and 5), all using no software tools more complex than Excel.",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,15.0,,15.0,1,312782
201,/learn/random-models-nested-split-plot-designs,"Random Models, Nested and Split-plot Designs",Arizona State University,4.6,3904,25,5,"Many experiments involve factors whose levels are chosen at random. A well-know situation is the study of measurement systems to determine their capability.  This course presents the design and analysis of these types of experiments, including modern methods for estimating the components of variability in these systems. The course also covers experiments with nested factors, and experiments with hard-to-change factors that require split-plot designs. We also provide an overview of designs for experiments with response distributions from nonnormal response distributions and experiments with covariates.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,1585
202,/learn/linear-regression-business-statistics,Linear Regression for Business Statistics,Rice University,4.8,59152,1180,196,"Regression Analysis is perhaps the single most important Business Statistics tool used in the industry. Regression is the engine behind a multitude of data analytics applications used for many forms of forecasting and prediction.  This is the fourth course in the specialization, ""Business Statistics and Analysis"". The course  introduces you to the very important tool known as Linear Regression. You will learn to apply various procedures such as dummy variable regressions, transforming variables, and interaction effects. All these are introduced and explained using easy to understand examples in Microsoft Excel.
The focus of the course is on understanding and application, rather than detailed mathematical derivations.
Note: This course uses the ‘Data Analysis’ tool box which is standard with the Windows version of Microsoft Excel. It is also standard with the 2016 or later Mac version of Excel. However, it is not standard with earlier versions of Excel for Mac. 


WEEK 1
Module 1: Regression Analysis: An Introduction
In this module you will get introduced to the Linear Regression Model. We will build a regression model and estimate it using Excel. We will use the estimated model to infer relationships between various variables and use the model to make predictions. The module also introduces the notion of errors, residuals and R-square in a regression model.

Topics covered include:
•	Introducing the Linear Regression
•	Building a Regression Model and estimating it using Excel
•	Making inferences using the estimated model
•	Using the Regression model to make predictions
•	Errors, Residuals and R-square
 

WEEK 2
Module 2: Regression Analysis: Hypothesis Testing and Goodness of Fit
This module presents different hypothesis tests you could do using the Regression output. These tests are an important part of inference and the module introduces them using Excel based examples. The p-values are introduced along with goodness of fit measures R-square and the adjusted R-square. Towards the end of module we introduce the ‘Dummy variable regression’ which is used to incorporate categorical variables in a regression. 

Topics covered include:
•	Hypothesis testing in a Linear Regression
•	‘Goodness of Fit’ measures (R-square, adjusted R-square)
•	Dummy variable Regression (using Categorical variables in a Regression)
 

WEEK 3
Module 3: Regression Analysis: Dummy Variables, Multicollinearity
This module continues with the application of Dummy variable Regression. You get to understand the interpretation of Regression output in the presence of categorical variables. Examples are worked out to re-inforce various concepts introduced. The module also explains what is Multicollinearity and how to deal with it. 

Topics covered include:
•	Dummy variable Regression (using Categorical variables in a Regression)
•	Interpretation of coefficients and p-values in the presence of Dummy variables
•	Multicollinearity in Regression Models
 

WEEK 4
Module 4: Regression Analysis: Various Extensions
The module extends your understanding of the Linear Regression, introducing techniques such as mean-centering of variables and building confidence bounds for predictions using the Regression model. A powerful regression extension known as ‘Interaction variables’ is introduced and explained using examples. We also study the transformation of variables in a regression and in that context introduce the log-log and the semi-log regression models. 

Topics covered include:
•	Mean centering of variables in a Regression model
•	Building confidence bounds for predictions using a Regression model
•	Interaction effects in a Regression
•	Transformation of variables
•	The log-log and semi-log regression models",28,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,25.0,11.0,33.0,1,32266
203,/learn/mining-medical-data,Foundations of mining non-structured medical data,EIT Digital ,3.9,2258,19,7,"The goal of this course is to understand the foundations of Big Data and the data that is being generated in the health domain and how the use of technology would help to integrate and exploit all those data to extract meaningful information that can be later used in different sectors of the health domain from physicians to management, from patients to care givers, etc. The course will offer to the student a high-level perspective of the importance of the medical context within the European context, the types of data that are managed in the health (clinical) context, the challenges to be addressed in the mining of unstructured medical data (text and image) as well as the opportunities from the analytical point of view with an introduction to the basics of data analytics field.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,2149
204,/learn/python-statistics-financial-analysis,Python and Statistics for Financial Analysis,The Hong Kong University of Science and Technology,4.4,115537,2406,536,"Course Overview: https://youtu.be/JgFV5qzAYnoPython is now becoming the number 1 programming language for data science. Due to python’s simplicity and high readability, it is gaining its importance in the financial industry.  The course combines both python coding and statistical concepts and applies into analyzing financial data, such as stock data.

By the end of the course, you can achieve the following using python:

- Import, pre-process, save and visualize financial data into pandas Dataframe

- Manipulate the existing financial data by generating new variables using multiple columns

- Recall and apply the important statistical concepts (random variable, frequency, distribution, population and sample, confidence interval, linear regression, etc. ) into financial contexts

- Build a trading model using multiple linear regression model 

- Evaluate the performance of the trading model using different investment indicators

Jupyter Notebook environment is configured in the course platform for practicing python coding without installing any client applications.",13,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,,,,1,86764
205,/learn/social-economic-networks,Social and Economic Networks:  Models and Analysis,Stanford University,4.8,36588,614,138,"Learn how to model social and economic networks and their impact on human behavior.  How do networks form, why do they exhibit certain patterns, and how does their structure impact diffusion, learning, and other behaviors?   We will bring together models and techniques from economics, sociology, math, physics, statistics and computer science to answer these questions.The course begins with some empirical background on social and economic networks, and an overview of concepts used to describe and measure networks. Next, we will cover a set of models of how networks form, including random network models as well as strategic formation models, and some hybrids. We will then discuss a series of models of how networks impact behavior, including contagion, diffusion, learning, and peer influences.

You can find a more detailed syllabus here:  http://web.stanford.edu/~jacksonm/Networks-Online-Syllabus.pdf 

You can find a short introductory videao here: http://web.stanford.edu/~jacksonm/Intro_Networks.mp4",30,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,11.0,29.0,1,51776
206,/learn/data-visualization,Data Management and Visualization,Wesleyan University,4.4,23831,873,248,"Whether being used to customize advertising to millions of website visitors or streamline inventory ordering at a small restaurant, data is becoming more integral to success. Too often, we’re not sure how use data to find answers to the questions that will make us more successful in what we do. In this course, you will discover what data is and think about what questions you have that can be answered by the data – even if you’ve never thought about data before. Based on existing data, you will learn to develop a research question, describe the variables and their relationships, calculate basic statistics, and present your results clearly. By the end of the course, you will be able to use powerful data analysis tools – either SAS or Python – to manage and visualize your data, including how to deal with missing data, variable groups, and graphs. Throughout the course, you will share your progress with others to gain valuable feedback, while also learning how your peers use data to answer their own questions.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,36.0,,44.0,1,72469
207,/learn/data-visualization-dashboards-excel-cognos,Data Visualization and Dashboards with Excel and Cognos,IBM,4.7,218770,426,64,"This course covers some of the first steps in the development of data visualizations using spreadsheets and dashboards. Begin the process of telling a story with your data by creating the many types of charts that are available in spreadsheets like Excel. Explore the different tools of a spreadsheet, such as the important pivot function and the ability to create dashboards and learn how each one has its own unique property to transform your data. Continue to gain valuable experience by becoming familiar with the popular analytics tool - IBM Cognos Analytics - to create interactive dashboards.By completing this course, you will have a basic understanding of using spreadsheets as a data visualization tool. You will gain the ability to effectively create data visualizations, such as charts or graphs, and will begin to see how they play a key role in communicating your data analysis findings. All of this can be accomplished by learning the basics of data analysis with Excel and IBM Cognos Analytics, without having to write any code. By the end of this course you will be able to describe common dashboarding tools used by a data analyst, design and create a dashboard in a cloud platform, and begin to elevate your confidence level in creating intermediate level data visualizations. 

Throughout this course you will encounter numerous hands-on labs and a final project. With each lab, gain hands-on experience with creating basic and advanced charts, then continue through the course and begin creating dashboards with spreadsheets and IBM Cognos Analytics. You will then end this course by creating a set of data visualizations with IBM Cognos Analytics and creating an interactive dashboard that can be shared with peers, professional communities or prospective employers.

This course does not require any prior data analysis, or computer science experience. All you need to get started is basic computer literacy, high school level math, access to a modern web browser such as Chrome or Firefox, the ability to create a Microsoft account to access Excel for the Web, and a basic understanding of Excel spreadsheets.",10,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,,,,0,11867
208,/learn/fundamental-machine-learning-healthcare,Fundamentals of Machine Learning for Healthcare,Stanford University,4.8,36032,118,37,"Machine learning and artificial intelligence hold the potential to transform healthcare and open up a world of incredible promise. But we will never realize the potential of these technologies unless all stakeholders have basic competencies in both healthcare and machine learning concepts and principles. This course will introduce the fundamental concepts and principles of machine learning as it applies to medicine and healthcare. We will explore machine learning approaches, medical use cases, metrics unique to healthcare, as well as best practices for designing, building, and evaluating machine learning applications in healthcare.

The course will empower those with non-engineering backgrounds in healthcare, health policy, pharmaceutical development, as well as data science with the knowledge to critically evaluate and use these technologies.

 
Co-author: Geoffrey Angus
 
Contributing Editors:
Mars Huang
Jin Long
Shannon Crawford
Oge Marques


The Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.  Visit the FAQs below for important information regarding 1) Date of original release and Termination or expiration date; 2) Accreditation and Credit Designation statements; 3) Disclosure of financial relationships for every person in control of activity content.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,5535
209,/learn/excel-basics-data-analysis-ibm,Excel Basics for Data Analysis,IBM,4.7,483678,761,127,"This course is designed to provide you with basic working knowledge for using Excel spreadsheets for Data Analysis. It covers some of the first steps for working with spreadsheets and their usage in the process of analyzing data.  It includes plenty of videos, demos, and examples for you to learn, followed by step-by-step instructions for you to apply and practice on a live spreadsheet.Excel is an essential tool for working with data - whether for business, marketing, data analytics, or research. This course is suitable for those aspiring to take up Data Analysis or Data Science as a profession, as well as those who just want to use Excel for data analysis in their own domains. You will gain valuable experience in cleansing and wrangling data using functions and then analyze your data using techniques like filtering, sorting and creating pivot tables.   

This course starts with an introduction to spreadsheets like Microsoft Excel and Google Sheets and loading data from multiple formats. With this introduction you will then learn to perform some basic level data wrangling and cleansing tasks and continue to expand your knowledge of analyzing data through the use of filtering, sorting, and using pivot tables within the spreadsheet. By performing these tasks throughout the course, it will give you an understanding of how spreadsheets can be used as a data analysis tool and understand its limitations. 

There is a strong focus on practice and applied learning in this course. With each lab, you will gain hands-on experience in manipulating data and begin to understand the important role of spreadsheets. Clean and analyze your data faster by understanding functions in the formatting of data. You will then convert your data to a pivot table and learn its features to make your data organized and readable. The final project enables you to show off your newly acquired data analysis skills. By the end of this course you will have worked with several data sets and spreadsheets and demonstrated the basics of cleaning and analyzing data all without having to learn any code. 

Getting started with Excel is made easy in this course. It does not require any prior experience with spreadsheets or coding. Nor does it require downloads or installation of any software. All you need is a device with a modern web browser, and ability to create a Microsoft account to access Excel online at no-cost.  However if you already have a desktop version of Excel, you can follow along quite easily as well.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,25268
210,/learn/importance-of-listening,The Importance of Listening,Northwestern University,4.6,30487,1514,303,"In this second MOOC in the Social Marketing Specialization - ""The Importance of Listening"" - you will go deep into the Big Data of social and gain a more complete picture of what can be learned from interactions on social sites. You will be amazed at just how much information can be extracted from a single post, picture, or video. In this MOOC, guest speakers from Social Gist, BroadReader, Lexalytics, Semantria, Radian6, and IBM's Bluemix and Social Media Analytics Tools (SMA) will join Professor Hlavac to take you through the full range of analytics tools and options available to you and how to get the most from them. The best part, most of them will be available to you through the MOOC for free! Those purchasing the MOOC will receive special tools, templates, and videos to enhance your learning experience. In completing this course you will develop a fuller understanding of the data and will be able to increase the effectiveness of your content strategy by making better decisions and spotting crises before they happen! MOOC 2 bonus content in the paid toolkit includes access to Semantria's analytics engine to extract some data on the markets you are developing and have it analyzed. As a student in this course, you are being provided the opportunity to access IBM Bluemix® platform-as-a-service trial for up to six months at no-charge with no credit card (up to a $1500 value).

NOTE: By enrolling in this course, given access to IBM's Bluemix technology for one month for free as well as Lexalytics' Semantria tool. For those earning a Course Certificate, you will be given an additional five months of Bluemix and three months of Semantria at no cost with a special key code. By enrolling for a Course Certificate for this MOOC, you are acknowledging that your email will be shared with Lexalytics for the sole and express purpose of generating your individual key code. After the key code has been generated, Lexalytics will delete your email from its records. 

Additional MOOC 2 faculty include: 
* Steve Dodd (SVP Business Development, Effyis - dba BoardReader and Socialgist - Global Social Media Content Access) 
* Seth Redmore (CMO, Lexalytics, Inc.)
* Chris Gruber (Social Media Analytics Solution Architect, IBM)
* Russell Beardall (Cloud Architect, IBM) 
* Tom Collinger (Executive Director Spiegel Research Center and Senior Director Distance Learning, Medill Integrated Marketing Communications, Northwestern)
* Tressie Lieberman (VP Digital Innovation, Taco Bell)",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,35.0,,30.0,1,41842
211,/learn/data-analysis-project-pwc,Data Analysis and Presentation Skills: the PwC Approach Final Project,PwC,4.8,22185,193,40,"In this Capstone Project, you'll bring together all the new skills and insights you've learned through the four courses. You'll be given a 'mock' client problem and a data set. You'll need to analyze the data to gain business insights, research the client's domain area, and create recommendations. You'll then need to visualize the data in a client-facing presentation. You'll bring it all together in a recorded video presentation.This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,20.0,20.0,0,2503
212,/learn/scala-capstone,Functional Programming in Scala Capstone,École Polytechnique Fédérale de Lausanne,4.4,6684,526,90,"In the final capstone project you will apply the skills you learned by building a large data-intensive application using real-world data.You will implement a complete application processing several gigabytes of data. This application will show interactive visualizations of the evolution of temperatures over time all over the world.

The development of such an application will involve:
 — transforming data provided by weather stations into meaningful information like, for instance, the average temperature of each point of the globe over the last ten years ;
 — then, making images from this information by using spatial and linear interpolation techniques ;
 — finally, implementing how the user interface will react to users’ actions.",27,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,12.0,35.0,0,11690
213,/learn/designexperiments,"Designing, Running, and Analyzing Experiments",University of California San Diego,3.6,20595,533,200,"You may never be sure whether you have an effective user experience until you have tested it with users. In this course, you’ll learn how to design user-centered experiments, how to run such experiments, and how to analyze data from these experiments in order to evaluate and validate user experiences. You will work through real-world examples of experiments from the fields of UX, IxD, and HCI, understanding issues in experiment design and analysis. You will analyze multiple data sets using recipes given to you in the R statistical programming language -- no prior programming experience is assumed or required, but you will be required to read, understand, and modify code snippets provided to you. By the end of the course, you will be able to knowledgeably design, run, and analyze your own experiments that give statistical weight to your designs.",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,19.0,,24.0,1,26499
214,/learn/wharton-introduction-spreadsheets-models,Introduction to Spreadsheets and Models,University of Pennsylvania,4.2,51986,3339,616,"The simple spreadsheet is one of the most powerful data analysis tools that exists, and it’s available to almost anyone. Major corporations and small businesses alike use spreadsheet models to determine where key measures of their success are now, and where they are likely to be in the future. But in order to get the most out of a spreadsheet, you have the know-how to use it. This course is designed to give you an introduction to basic spreadsheet tools and formulas so that you can begin harness the power of spreadsheets to map the data you have now and to predict the data you may have in the future. Through short, easy-to-follow demonstrations, you’ll learn how to use Excel or Sheets so that you can begin to build models and decision trees in future courses in this Specialization. Basic familiarity with, and access to, Excel or Sheets is required.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,27.0,,28.0,1,86893
215,/learn/process-mining,Process Mining: Data science in Action,Eindhoven University of Technology,4.7,61621,904,234,"Process mining is the missing link between model-based process analysis and data-oriented analysis techniques. Through concrete data sets and easy to use software the course provides data science knowledge that can be applied directly to analyze and improve processes in a variety of domains.Data science is the profession of the future, because organizations that are unable to use (big) data in a smart way will not survive. It is not sufficient to focus on data storage and data analysis. The data scientist also needs to relate data to process analysis. Process mining bridges the gap between traditional model-based process analysis (e.g., simulation and other business process management techniques) and data-centric analysis techniques such as machine learning and data mining. Process mining seeks the confrontation between event data (i.e., observed behavior) and process models (hand-made or discovered automatically). This technology has become available only recently, but it can be applied to any type of operational processes (organizations and systems). Example applications include: analyzing treatment processes in hospitals, improving customer service processes in a multinational, understanding the browsing behavior of customers using booking site, analyzing failures of a baggage handling system, and improving the user interface of an X-ray machine. All of these applications have in common that dynamic behavior needs to be related to process models. Hence, we refer to this as ""data science in action"".

The course explains the key analysis techniques in process mining. Participants will learn various process discovery algorithms. These can be used to automatically learn process models from raw event data. Various other process analysis techniques that use event data will be presented. Moreover, the course will provide easy-to-use software, real-life data sets, and practical skills to directly apply the theory in a variety of application domains.

This course starts with an overview of approaches and technologies that use event data to support decision making and business process (re)design. Then the course focuses on process mining as a bridge between data mining and business process modeling. The course is at an introductory level with various practical assignments.

The course covers the three main types of process mining.

1. The first type of process mining is discovery. A discovery technique takes an event log and produces a process model without using any a-priori information. An example is the Alpha-algorithm that takes an event log and produces a process model (a Petri net) explaining the behavior recorded in the log.

2. The second type of process mining is conformance. Here, an existing process model is compared with an event log of the same process. Conformance checking can be used to check if reality, as recorded in the log, conforms to the model and vice versa.

3. The third type of process mining is enhancement. Here, the idea is to extend or improve an existing process model using information about the actual process recorded in some event log. Whereas conformance checking measures the alignment between model and reality, this third type of process mining aims at changing or extending the a-priori model. An example is the extension of a process model with performance information, e.g., showing bottlenecks. Process mining techniques can be used in an offline, but also online setting. The latter is known as operational support. An example is the detection of non-conformance at the moment the deviation actually takes place. Another example is time prediction for running cases, i.e., given a partially executed case the remaining processing time is estimated based on historic information of similar cases.

Process mining provides not only a bridge between data mining and business process management; it also helps to address the classical divide between ""business"" and ""IT"". Evidence-based business process management based on process mining helps to create a common ground for business process improvement and information systems development.

The course uses many examples using real-life event logs to illustrate the concepts and algorithms. After taking this course, one is able to run process mining projects and have a good understanding of the Business Process Intelligence field.

After taking this course you should:
- have a good understanding of Business Process Intelligence techniques (in particular process mining),
- understand the role of Big Data in today’s society,
- be able to relate process mining techniques to other analysis techniques such as simulation, business intelligence, data mining, machine learning, and verification,
- be able to apply basic process discovery techniques to learn a process model from an event log (both manually and using tools),
- be able to apply basic conformance checking techniques to compare event logs and process models (both manually and using tools),
- be able to extend a process model with information extracted from the event log (e.g., show bottlenecks),
- have a good understanding of the data needed to start a process mining project,
- be able to characterize the questions that can be answered based on such event data,
- explain how process mining can also be used for operational support (prediction and recommendation), and
- be able to conduct process mining projects in a structured manner.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,26.0,,18.0,1,51322
216,/learn/gcp-big-data-ml-fundamentals-jp,Google Cloud Platform Big Data and Machine Learning Fundamentals 日本語版,Google Cloud,4.4,4403,131,15,"この 2 週間の速習オンデマンド コースでは、Google Cloud Platform（GCP）のビッグデータ機能と機械学習機能を紹介します。Google Cloud Platform の概要を簡単に説明した後、データ処理機能について詳しく説明します。このコースを修了すると、受講者は次のことができるようになります。
• Google Cloud Platform のビッグデータと機械学習に関係する主要プロダクトの目的と価値を理解する
• Cloud SQL と Cloud Dataproc を使用して既存の MySQL と Hadoop、Pig、Spark、Hive のワークロードを Google Cloud Platform に移行する
• BigQuery と Cloud Datalab を使用してインタラクティブなデータ解析を実行する
• Cloud SQL、Bigtable、Datastore のいずれかを選択する
• TensorFlow を使用してニューラル ネットワークをトレーニングし、利用する
• Google Cloud Platform のさまざまなデータ処理プロダクトについて理解し、選択する

このコースは、次の 1 つ以上の分野で 1 年程度の経験がある方を対象としています。
• SQL などの一般的なクエリ言語
• 抽出、変換、読み込みの操作
• データ モデリング
• 機械学習または統計
• Python でのプログラミング

Google アカウントに関する注意点:
• 現在 Google サービスは中国では使用できません。",13,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,50.0,50.0,,0,3255
217,/learn/data-science-project,Data Science Capstone,Johns Hopkins University,4.5,35208,1154,302,"The capstone project class will allow students to create a usable/public data product that can be used to show your skills to potential employers. Projects will be drawn from real-world problems and will be conducted with industry, government, and academic partners.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,38.0,19.0,32.0,1,32979
218,/learn/statistics-project,Statistics with R Capstone,Duke University,4.6,7109,196,48,"The capstone project will be an analysis using R that answers a specific scientific/business question provided by the course team. A large and complex dataset will be provided to learners and the analysis will require the application of a variety of methods and techniques introduced in the previous courses, including exploratory data analysis through data visualization and numerical summaries, statistical inference, and modeling as well as interpretations of these results in the context of the data and the research question. The analysis will implement both frequentist and Bayesian techniques and discuss in context of the data how these two approaches are similar and different, and what these differences mean for conclusions that can be drawn from the data.A sampling of the final projects will be featured on the Duke Statistical Science department website.

Note: Only learners who have passed the four previous courses in the specialization are eligible to take the Capstone.",6,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,17.0,17.0,1,6964
219,/learn/ai2,人工智慧：機器學習與理論基礎 (Artificial Intelligence - Learning & Theory),National Taiwan University,4.7,4882,31,3,"本課程第二部分著重在和人工智慧密不可分的機器學習。課程內容包含了機器學習基礎理論（包含 1990 年代發展的VC理論）、分類器（包含決策樹及支援向量機）、神經網路（包含深度學習）及增強式學習（包含深度增強式學習。此部份技術包含最早追溯至 1950 年代直到最近 2016 年附近的最新發展。此課程從基礎理論開始，簡介了各機器學習主流技法以及從淺層學習架構演變到最近深度架構的轉換。

本課程之核心目標為：
（一）使同學對人工智慧相關的機器學習技術有基礎概念
（二）同學能夠理解機器學習基礎理論、分類器、神經網路、增強式學習
（三）同學能將相關技術應用到自己的問題上

修課前，基礎背景知識：
需要的先備知識：計算機概論
建議的先備知識：資料結構與演算法",12,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,,,,1,6719
220,/learn/cloud-computing-basics,Cloud Computing Basics (Cloud 101),LearnQuest,4.5,91317,4967,1373,"Welcome to Cloud Computing Basics (Cloud 101). Over the next few weeks, we will discuss the basics of Cloud computing: what it is, what it supports, and how it is delivered. We will delve into storage services, Cloud economics, levels of managed infrastructure, and Azure services. We will also explore different deployment models of Cloud computing, as well as several hosting scenarios. Last but not least, we will compare some of the cloud platforms and discuss the future of cloud computing.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,12.0,18.0,,0,105884
221,/learn/big-data-project,Big Data - Capstone Project,University of California San Diego,4.4,15762,377,95,"Welcome to the Capstone Project for Big Data! In this culminating project, you will build a big data ecosystem using tools and methods form the earlier courses in this specialization. You will analyze a data set simulating big data generated from a large number of users who are playing our imaginary game ""Catch the Pink Flamingo"". During the five week Capstone Project, you will walk through the typical big data science steps for acquiring, exploring, preparing, analyzing, and reporting. In the first two weeks, we will introduce you to the data set and guide you through some exploratory analysis using tools such as Splunk and Open Office. Then we will move into more challenging big data problems requiring the more advanced tools you have learned including KNIME, Spark's MLLib and Gephi. Finally, during the fifth and final week, we will show you how to bring it all together to create engaging and compelling reports and slide presentations. As a result of our collaboration with Splunk, a software company focus on analyzing machine-generated big data, learners with the top projects will be eligible to present to Splunk and meet Splunk recruiters and engineering leadership.",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,27.0,13.0,21.0,1,12902
222,/learn/fitting-statistical-models-data-python,Fitting Statistical Models to Data with Python,University of Michigan,4.4,35745,515,94,"In this course, we will expand our exploration of statistical inference techniques by focusing on the science and art of fitting statistical models to data. We will build on the concepts presented in the Statistical Inference course (Course 2) to emphasize the importance of connecting research questions to our data analysis methods. We will also focus on various modeling objectives, including making inference about relationships between variables and generating predictions for future observations.This course will introduce and explore various statistical modeling techniques, including linear regression, logistic regression, generalized linear models, hierarchical and mixed effects (or multilevel) models, and Bayesian inference techniques. All techniques will be illustrated using a variety of real data sets, and the course will emphasize different modeling approaches for different types of data sets, depending on the study design underlying the data (referring back to Course 1, Understanding and Visualizing Data with Python).

During these lab-based sessions, learners will work through tutorials focusing on specific case studies to help solidify the week’s statistical concepts, which will include further deep dives into Python libraries including Statsmodels, Pandas, and Seaborn. This course utilizes the Jupyter Notebook environment within Coursera.",15,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,1,22030
223,/learn/excel-aplicado-negocios-avanzado,Excel aplicado a los negocios (Nivel Avanzado),Universidad Austral,4.8,216011,2128,914,"Objetivos Generales: Al finalizar el curso, podrás:1.- ENTENDER y profundizar convenientemente aspectos específicos de   diferentes formas de trabajo (individual o grupal), 
2.- EVALUAR el uso de funciones avanzadas para manipular datos y CREAR tus propios análisis utilizando técnicas específicas tales como tablas dinámicas, análisis de hipótesis, administración de escenarios, tablas de simple y doble entrada, análisis de optimización de recursos. 
3.- ANALIZAR cómo vincular Excel con otras aplicaciones importando información desde archivos de texto y bases de datos, exportando información a archivos de texto de diversas formas. 
4.- ENTENDER  el uso de macros lo que te permitirá vislumbrar otro universo de aplicaciones que harán mucho más productiva tu labor.

Los ejemplos sobre los cuales se apoyan los contenidos dictados por los profesores, tienen una profunda aplicabilidad al mundo de los negocios, con lo que su inmediata utilización empresarial está al alcance de la mano.
Finalmente, los profesores que han diseñado y elaborado este curso para ti, no solamente dan una visión académica de los usos avanzados del software, sino que, debido a su gran trayectoria profesional apoyada justamente en un uso intensivo y profundo de Excel, te transmitirán su propia vivencia, lo cual te permitirá tener una visión más concreta de las posibilidades que te brinda esta herramienta.",25,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,26.0,10.0,36.0,0,122396
224,/learn/statistical-analysis-hypothesis-testing-sas,Introduction to Statistical Analysis:  Hypothesis Testing,SAS,4.9,12518,29,5,"This introductory course is for SAS software users who perform statistical analyses using SAS/STAT software. The focus is on t tests, ANOVA, and linear regression, and includes a brief introduction to logistic regression.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2958
225,/learn/streaming-analytics-systems-gcp,Building Resilient Streaming Analytics Systems on GCP,Google Cloud,4.6,45594,967,115,"*Note: this is a new course with updated content from what you may have seen in the previous version of this Specialization.Processing streaming data is becoming increasingly popular as streaming enables businesses to get real-time metrics on business operations. This course covers how to build streaming data pipelines on Google Cloud Platform. Cloud Pub/Sub is described for handling incoming streaming data. The course also covers how to apply aggregations and transformations to streaming data using Cloud Dataflow, and how to store processed records to BigQuery or Cloud Bigtable for analysis. Learners will get hands-on experience building streaming data pipeline components on Google Cloud Platform using QwikLabs.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,20455
226,/learn/data-structures,Data Structures,University of California San Diego,4.6,182940,4121,690,"A good algorithm usually comes together with a set of good data structures that allow the algorithm to manipulate the data efficiently. In this course, we consider the common data structures that are used in various computational problems. You will learn how these data structures are implemented in different programming languages and will practice implementing them in our programming assignments. This will help you to understand what is going on inside a particular built-in implementation of a data structure and what to expect from it. You will also learn typical use cases for these data structures.A few examples of questions that we are going to cover in this class are the following:
1. What is a good strategy of resizing a dynamic array?
2. How priority queues are implemented in C++, Java, and Python?
3. How to implement a hash table so that the amortized running time of all operations is O(1) on average?
4. What are good strategies to keep a binary tree balanced? 

You will also learn how services like Dropbox manage to upload some large files instantly and to save a lot of storage space!",25,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,30.0,11.0,28.0,1,181661
227,/learn/hypothesis-testing-confidence-intervals,Business Applications of Hypothesis Testing and Confidence Interval Estimation ,Rice University,4.8,48168,1098,188,"Confidence intervals and Hypothesis tests are very important tools in the Business Statistics toolbox. A mastery over these topics will help enhance your business decision making and allow you to understand and measure the extent of ‘risk’ or ‘uncertainty’ in various business processes. This is the third course in the specialization ""Business Statistics and Analysis"" and the course  advances your knowledge about Business Statistics by introducing you to Confidence Intervals and Hypothesis Testing. We first conceptually understand these tools and their business application. We then introduce various calculations to constructing confidence intervals and to conduct different kinds of Hypothesis Tests. These are done by easy to understand applications.

To successfully complete course assignments, students must have access to a Windows version of Microsoft Excel 2010 or later. Please note that earlier versions of Microsoft Excel (2007 and earlier) will not be compatible to some Excel functions covered in this course. 


WEEK 1
Module 1: Confidence Interval - Introduction
In this module you will get to conceptually understand what a confidence interval is and how is its constructed. We will introduce the various building blocks for the confidence interval such as the t-distribution, the t-statistic, the z-statistic and their various excel formulas. We will then use these building blocks to construct confidence intervals.

Topics covered include:
•	Introducing the t-distribution, the T.DIST and T.INV excel functions
•	Conceptual understanding of a Confidence Interval
•	The z-statistic and the t-statistic
•	Constructing a Confidence Interval using z-statistic and t-statistic 


WEEK 2
Module 2: Confidence Interval - Applications
This module presents various business applications of the confidence interval including an application where we use the confidence interval to calculate an appropriate sample size. We also introduce with an application, the confidence interval for a population proportion. Towards the close of module we start introducing the concept of Hypothesis Testing.

Topics covered include:
•	Applications of Confidence Interval
•	Confidence Interval for a Population Proportion
•	Sample Size Calculation
•	Hypothesis Testing, An Introduction


WEEK 3
Module 3: Hypothesis Testing
This module introduces Hypothesis Testing. You get to understand the logic behind hypothesis tests. The four steps for conducting a hypothesis test are introduced and you get to apply them for hypothesis tests for a population mean as well as population proportion. You will understand the difference between single tail hypothesis tests and two tail hypothesis tests and also the Type I and Type II errors associated with hypothesis tests and ways to reduce such errors. 

Topics covered include:
•	The Logic of Hypothesis Testing
•	The Four Steps for conducting a Hypothesis Test
•	Single Tail and Two Tail Hypothesis Tests
•	Guidelines, Formulas and an Application of Hypothesis Test
•	Hypothesis Test for a Population Proportion
•	Type I and Type II Errors in a Hypothesis 


WEEK 4
Module 4: Hypothesis Test - Differences in Mean
In this module, you'll apply Hypothesis Tests to test the difference between two different data, such hypothesis tests are called difference in means tests. We will introduce the three kinds of difference in means test and apply them to various business applications. We will also introduce the Excel dialog box to conduct such hypothesis tests.

Topics covered include:
•	Introducing the Difference-In-Means Hypothesis Test
•	Applications of the Difference-In-Means Hypothesis Test
•	The Equal & Unequal Variance Assumption and the Paired t-test for difference in means.
•	Some more applications",25,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,60.0,,50.0,1,23392
228,/learn/dwdesign,"Data Warehouse Concepts, Design, and Data Integration",University of Colorado System,4.4,40058,931,188,"This is the second course in the Data Warehousing for Business Intelligence specialization. Ideally, the courses should be taken in sequence.In this course, you will learn exciting concepts and skills for designing data warehouses and creating data integration workflows. These are fundamental skills for data warehouse developers and administrators. You will have hands-on experience for data warehouse design and use open source products for manipulating pivot tables and creating data integration workflows. In the data integration assignment, you can use either Oracle, MySQL, or PostgreSQL databases. You will also gain conceptual background about maturity models, architectures, multidimensional models, and management practices, providing an organizational perspective about data warehouse development. If you are currently a business or information technology professional and want to become a data warehouse designer or administrator, this course will give you the knowledge and skills to do that. By the end of the course, you will have the design experience, software background, and organizational context that prepares you to succeed with data warehouse development projects. 

In this course, you will create data warehouse designs and data integration workflows that satisfy the business intelligence needs of organizations. When you’re done with this course, you’ll be able to:
   * Evaluate an organization for data warehouse maturity and business architecture alignment;
   * Create a data warehouse design and reflect on alternative design methodologies and design goals;
   * Create data integration workflows using prominent open source software;
   * Reflect on the role of change data, refresh constraints, refresh frequency trade-offs, and data quality goals in data integration process design; and
   * Perform operations on pivot tables to satisfy typical business analysis requests using prominent open source software",23,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,29.0,23.0,22.0,1,50377
229,/learn/prediction-control-function-approximation,Prediction and Control with Function Approximation,University of Alberta,4.8,45009,606,107,"In this course, you will learn how to solve problems with large, high-dimensional, and potentially infinite state spaces. You will see that estimating value functions can be cast as a supervised learning problem---function approximation---allowing you to build agents that carefully balance generalization and discrimination in order to maximize reward. We will begin this journey by investigating how our policy evaluation or prediction methods like Monte Carlo and TD can be extended to the function approximation setting. You will learn about feature construction techniques for RL, and representation learning via neural networks and backprop. We conclude this course with a deep-dive into policy gradient methods; a way to learn policies directly without learning a value function. In this course you will solve two continuous-state control tasks and investigate the benefits of policy gradient methods in a continuous-action environment. Prerequisites: This course strongly builds on the fundamentals of Courses 1 and 2, and learners should have completed these before starting this course.  Learners should also be comfortable with probabilities & expectations, basic linear algebra, basic calculus, Python 3.0 (at least 1 year), and  implementing algorithms from pseudocode.

By the end of this course, you will be able to: 

-Understand how to use supervised learning approaches to approximate value functions
-Understand objectives for prediction (value estimation) under function approximation
-Implement TD with function approximation (state aggregation), on an environment with an infinite state space (continuous state space)
-Understand fixed basis and neural network approaches to feature construction 
-Implement TD with neural network function approximation in a continuous state environment
-Understand new difficulties in exploration when moving to function approximation
-Contrast discounted problem formulations for control versus an average reward problem formulation
-Implement expected Sarsa and Q-learning with function approximation on a continuous state control task
-Understand objectives for directly estimating policies (policy gradient objectives)
-Implement a policy gradient method (called Actor-Critic) on a discrete state environment",22,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,1,13854
230,/learn/functional-mri,Principles of fMRI 1,Johns Hopkins University,4.6,21996,688,141,"Functional Magnetic Resonance Imaging (fMRI) is the most widely used technique for investigating the living, functioning human brain as people perform tasks and experience mental states. It is a convergence point for multidisciplinary work from many disciplines. Psychologists, statisticians, physicists, computer scientists, neuroscientists, medical researchers, behavioral scientists, engineers, public health researchers, biologists, and others are coming together to advance our understanding of the human mind and brain.  This course covers the design, acquisition, and analysis of Functional Magnetic Resonance Imaging (fMRI) data, including psychological inference, MR Physics, K Space, experimental design, pre-processing of fMRI data, as well as Generalized Linear Models (GLM’s).  A book related to the class can be found here: https://leanpub.com/principlesoffmri.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,33.0,,50.0,1,31013
231,/learn/excel-para-negocios,Fundamentos de Excel para Negocios,Universidad Austral,4.8,384989,3882,1603,"Descripción del curso: Cuando finalices este curso habrás logrado un gran número de habilidades como introducir información, ordenarla, manipularla, realizar cálculos de diversa índole (matemáticos, trigonométricos, estadísticos, financieros, ingenieriles, probabilísticos), extraer conclusiones, trabajar con fechas y horas, construir gráficos, imprimir reportes y muchas más.

Asimismo, los ejemplos sobre los cuales se apoyan los contenidos dictados en este curso tienen una profunda aplicabilidad al mundo de los negocios, con lo que su inmediata utilización empresarial está al alcance de la mano.

Finalmente, los profesores que han diseñado y elaborado este curso para ti, no solamente dan una visión académica del software sino que, debido a su gran trayectoria profesional apoyada justamente en una profunda utilización de Excel, te transmitirán su propia vivencia que te permitirá tener una visión más concreta de las posibilidades que te brinda esta herramienta.",20,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,29.0,25.0,17.0,0,237295
232,/learn/automated-reasoning-sat,Automated Reasoning: satisfiability,EIT Digital ,4.8,6049,30,7,"In this course you will learn how to apply satisfiability (SAT/SMT) tools to solve a wide range of problems.Several basic examples are given to get the flavor of the applications: fitting rectangles to be applied for printing posters, scheduling problems, solving puzzles, and program correctness. Also underlying theory is presented: resolution as a basic approach for propositional satisfiability, the CDCL framework to scale up for big formulas, and the simplex method to deal with linear inequallities.

The light weight approach to following this course is just watching the lectures and do the corresponding quizzes. To get a flavor of the topic this may work out fine. However, the much more interesting approach is to use this as a basis to apply SAT/SMT yourself on several problems, for instance on the problems presented in the honor's assignment.",25,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,2882
233,/learn/ecology,Ecology: from cells to Gaia,National Research Tomsk State University,4.4,5842,201,46,"This course presents the principles of evolution and ecology for citizens and students interested in studying biology and environmental sciences. It discusses major ideas and results. Recent advances have energised these fields with evidence that has implications beyond their boundaries: ideas, mechanisms, and processes that should form part of the toolkit of all biologists and educated citizens.Major topics covered by the course include fundamental principles of ecology, how organisms interact with each other and their environment, evolutionary processes, population dynamics, communities, energy flow and ecosystems, human influences on ecosystems, and the integration and scaling of ecological processes through systems ecology.
 
This course will also review major ecological concepts, identify the techniques used by ecologists, provide an overview of local and global environmental issues, and examine individual, group and governmental activities important for protecting natural ecosystems. The course has been designed to provide information, to direct the student toward pertinent literature, to identify problems and issues, to utilise research methodology for the study of ecology and evolution, and to consider appropriate solutions and analytical techniques. 

Needed Learner Background: general biology and a good understanding of English.

This course has the following expectations and results:
1) covers the theoretical and practical issues involved in ecology and evolution,
2) conducting surveys and inventories in ecology, 
3) analyzing the information gathered, 
4) and applying their analysis to ecological and conservation problems.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,,33.0,1,9501
234,/learn/ml-foundations,Machine Learning Foundations: A Case Study Approach,University of Washington,4.6,196744,12272,2938,"Do you have data and wonder what it can tell you?  Do you need a deeper understanding of the core ways in which machine learning can improve your business?  Do you want to be able to converse with specialists about anything from regression and classification to deep learning and recommender systems?In this course, you will get hands-on experience with machine learning from a series of practical case-studies.  At the end of the first course you will have studied how to predict house prices based on house-level features, analyze sentiment from user reviews, retrieve documents of interest, recommend products, and search for images.  Through hands-on practice with these use cases, you will be able to apply machine learning methods in a wide range of domains.

This first course treats the machine learning method as a black box.  Using this abstraction, you will focus on understanding tasks of interest, matching these tasks to machine learning tools, and assessing the quality of the output. In subsequent courses, you will delve into the components of this black box by examining models and algorithms.  Together, these pieces form the machine learning pipeline, which you will use in developing intelligent applications.

Learning Outcomes:  By the end of this course, you will be able to:
   -Identify potential applications of machine learning in practice.  
   -Describe the core differences in analyses enabled by regression, classification, and clustering.
   -Select the appropriate machine learning task for a potential application.  
   -Apply regression, classification, clustering, retrieval, recommender systems, and deep learning.
   -Represent your data as features to serve as input to machine learning models. 
   -Assess the model quality in terms of relevant error metrics for each task.
   -Utilize a dataset to fit a model to analyze new data.
   -Build an end-to-end application that uses machine learning at its core.  
   -Implement these techniques in Python.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,27.0,,28.0,1,334111
235,/learn/big-data-essentials,"Big Data Essentials: HDFS, MapReduce and Spark RDD",Yandex,4.0,69691,512,136,"Have you ever heard about such technologies as HDFS, MapReduce, Spark? Always wanted to learn these new tools but missed concise starting material? Don’t miss this course either!In this 6-week course you will:
- learn some basic technologies of the modern Big Data landscape, namely: HDFS, MapReduce and Spark;
- be guided both through systems internals and their applications;
- learn about distributed file systems, why they exist and what function they serve;
- grasp the MapReduce framework, a workhorse for many modern Big Data applications;
- apply the framework to process texts and solve sample business cases;
- learn about Spark, the next-generation computational framework;
- build a strong understanding of Spark basic concepts;
- develop skills to apply these tools to creating solutions in finance, social networks, telecommunications and many other fields.

Your learning experience will be as close to real life as possible with the chance to evaluate your practical assignments on a real cluster. No mocking, a friendly considerate atmosphere to make the process of your learning smooth and enjoyable.
 
Get ready to work with real datasets alongside with real masters!

Special thanks to:
- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.
- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching  MapReduce, Hadoop  and friends since 2008. Now he is leading the infrastructure team.
- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.
- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.",41,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,20.0,12.0,40.0,0,48089
236,/learn/mongodb-aggregation-framework,MongoDB Aggregation Framework,MongoDB Inc.,4.6,8579,41,11,"This course will teach you how to perform data analysis using MongoDB's powerful Aggregation Framework.You'll begin this course by building a foundation of essential aggregation knowledge. By understanding these features of the Aggregation Framework you will learn how to ask complex questions of your data. This will lay the groundwork for the remainder of the course where you'll dive deep and learn about schema design, relational data migrations, and machine learning with 
MongoDB.

By the end of this course you'll understand how to best use MongoDB and its Aggregation Framework in your own data science workflow.",19,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,50.0,,,0,7673
237,/learn/sql-data-science,Databases and SQL for Data Science with Python,IBM,4.7,760616,13028,1522,"Much of the world's data resides in databases. SQL (or Structured Query Language) is a powerful language which is used for communicating with and extracting data from databases. A working knowledge of databases and SQL is a must if you want to become a data scientist.The purpose of this course is to introduce relational database concepts and help you learn and apply foundational knowledge of the SQL language. It is also intended to get you started with performing SQL access in a data science environment.  

The emphasis in this course is on hands-on and practical learning . As such, you will work with real databases, real data science tools, and real-world datasets. You will create a database instance in the cloud. Through a series of hands-on labs you will practice building and running SQL queries. You will also learn how to access databases from Jupyter notebooks using SQL and Python.

No prior knowledge of databases, SQL, Python, or programming is required.

Anyone can audit this course at no-charge. If you choose to take this course and earn the Coursera course certificate, you can also earn an IBM digital badge upon successful completion of the course.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.",19,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,33.0,,38.0,0,180981
238,/learn/bioconductor,Bioconductor for Genomic Data Science,Johns Hopkins University,3.9,14939,290,55,Learn to use tools from the Bioconductor project to perform analysis of genomic data. This is the fifth course in the Genomic Big Data Specialization from Johns Hopkins University.,9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,16482
239,/learn/business-analytics-decision-making,Business Analytics for Decision Making,University of Colorado Boulder,4.6,50821,1507,393,"In this course you will learn how to create models for decision making. We will start with cluster analysis, a technique for data reduction that is very useful in market segmentation. You will then learn the basics of Monte Carlo simulation that will help you model the uncertainty that is prevalent in many business decisions. A key element of decision making is to identify the best course of action. Since businesses problems often have too many alternative solutions, you will learn how optimization can help you identify the best option. What is really exciting about this course is that you won’t need to know a computer language or advanced statistics to learn about these predictive and prescriptive analytic models. The Analytic Solver Platform and basic knowledge of Excel is all you’ll need. Learners participating in assignments will be able to get free access to the Analytic Solver Platform.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,69090
240,/learn/google-machine-learning-es,How Google does Machine Learning en Español,Google Cloud,4.6,6827,184,63,"¿Qué es el aprendizaje automático y qué tipos de problemas puede solucionar? Google concibe el aprendizaje automático de una forma algo diferente: considera que se trata no solo de datos, sino también de lógica. Hablaremos de por qué es útil para los científicos de datos concebirlo así cuando piensan en compilar una canalización de modelos de aprendizaje automático. Luego, analizaremos las cinco fases de la transformación de un posible caso de uso en un recurso que pueda aprovechar la tecnología de aprendizaje automático. También consideramos por qué es importante no omitir ninguna fase. Finalizamos con un reconocimiento de los sesgos que puede amplificar el aprendizaje automático y cómo reconocerlos.
 
 >>> Al inscribirse en esta especialización, acepta las Condiciones del Servicio de Qwiklabs, que se indican en las Preguntas frecuentes. Puede consultarlas en https://qwiklabs.com/terms_of_service. <<<",8,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,50.0,,50.0,0,5817
241,/learn/ibm-ai-workflow-feature-engineering-bias-detection,AI Workflow: Feature Engineering and Bias Detection,IBM,4.4,7051,57,7,"This is the third course in the IBM AI Enterprise Workflow Certification specialization.    You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  Course 3 introduces you to the next stage of the workflow for our hypothetical media company.  In this stage of work you will learn best practices for feature engineering, handling class imbalances and detecting bias in the data.  Class imbalances can seriously affect the validity of your machine learning models, and the mitigation of bias in data is essential to reducing the risk associated with biased models.  These topics will be followed by sections on best practices for dimension reduction, outlier detection, and unsupervised learning techniques for finding patterns in your data.  The case studies will focus on topic modeling and data visualization.
 
By the end of this course you will be able to:
1.  Employ the tools that help address class and class imbalance issues
2.  Explain the ethical considerations regarding bias in data
3.  Employ ai Fairness 360 open source libraries to detect bias in models
4.  Employ dimension reduction techniques for both EDA and transformations stages
5.  Describe topic modeling techniques in natural language processing
6.  Use topic modeling and visualization to explore text data
7.  Employ outlier handling best practices in high dimension data
8.  Employ outlier detection algorithms as a quality assurance tool and a modeling tool
9.  Employ unsupervised learning techniques using pipelines as part of the AI workflow
10.  Employ basic clustering algorithms
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 and 2 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2219
242,/learn/convolutional-neural-networks,Convolutional Neural Networks,DeepLearning.AI,4.9,776476,38539,5063,"In the fourth course of the Deep Learning Specialization, you will understand how computer vision has evolved and become familiar with its exciting applications such as autonomous driving, face recognition, reading radiology images, and more.By the end, you will be able to build a convolutional neural network, including recent variations such as residual networks; apply convolutional networks to visual detection and recognition tasks; and use neural style transfer to generate art and apply these algorithms to a variety of image, video, and other 2D or 3D data. 

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",34,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,37.0,12.0,36.0,0,355097
243,/learn/dataviz-visual-analytics,Visual Analytics with Tableau,"University of California, Davis",4.6,64248,1499,281,"In this third course of the specialization, we’ll drill deeper into the tools Tableau offers in the areas of charting, dates, table calculations and mapping. We’ll explore the best choices for charts, based on the type of data you are using. We’ll look at specific types of charts including scatter plots, Gantt charts, histograms, bullet charts and several others, and we’ll address charting guidelines. We’ll define discrete and continuous dates, and examine when to use each one to explain your data.  You’ll learn how to create custom and quick table calculations and how to create parameters. We’ll also introduce mapping and explore how Tableau can use different types of geographic data, how to connect to multiple data sources and how to create custom maps.",9,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,32.0,12.0,29.0,1,35123
244,/learn/intro-analyticthinking-datascience-datamining,"Intro to Analytic Thinking, Data Science, and Data Mining","University of California, Irvine",4.0,5823,32,8,"Welcome to Introduction to Analytic Thinking, Data Science, and Data Mining. In this course, we will begin with an exploration of the field and profession of data science with a focus on the skills and ethical considerations required when working with data. We will review the types of business problems data science can solve and discuss the application of the CRISP-DM process to data mining efforts. A brief overview of Descriptive, Predictive, and Prescriptive Analytics will be provided, and we will conclude the course with an exploratory activity to learn more about the tools and resources you might find in a data science toolkit.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,1700
245,/learn/foundations-data,"Foundations: Data, Data, Everywhere",Google,4.8,7020418,1771,415,"This is the first course in the Google Data Analytics Certificate. These courses will equip you with the skills you need to apply to introductory-level data analyst jobs. Organizations of all kinds need data analysts to help them improve their processes, identify opportunities and trends, launch new products, and make thoughtful decisions. In this course, you’ll be introduced to the world of data analytics through hands-on curriculum developed by Google. The material shared covers plenty of key data analytics topics, and it’s designed to give you an overview of what’s to come in the Google Data Analytics Certificate. Current Google data analysts will instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
- Gain an understanding of the practices and processes used by a junior or associate data analyst in their day-to-day job. 
- Learn about key analytical skills (data cleaning, data analysis, data visualization) and tools (spreadsheets, SQL, R programming, Tableau) that you can add to your professional toolbox. 
- Discover a wide variety of terms and concepts relevant to the role of a junior data analyst, such as the data life cycle and the data analysis process. 
- Evaluate the role of analytics in the data ecosystem. 
- Conduct an analytical thinking self-assessment. 
- Explore job opportunities available to you upon program completion, and learn about best practices in the job search.",22,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,0,83948
246,/learn/crash-course-in-causality,A Crash Course in Causality:  Inferring Causal Effects from Observational Data,University of Pennsylvania,4.7,48281,340,116,"We have all heard the phrase “correlation does not equal causation.”  What, then, does equal causation?  This course aims to answer that question and more!  Over a period of 5 weeks, you will learn how causal effects are defined, what assumptions about your data and models are necessary, and how to implement and interpret some popular statistical methods.  Learners will have the opportunity to apply these methods to example data in R (free statistical software environment).

At the end of the course, learners should be able to:
1.  Define causal effects using potential outcomes
2.  Describe the difference between association and causation
3.  Express assumptions with causal graphs
4.  Implement several types of causal inference methods (e.g. matching, instrumental variables, inverse probability of treatment weighting)
5.  Identify which causal assumptions are necessary for each type of statistical method

So join us.... and discover for yourself why modern statistical methods for estimating causal effects are indispensable in so many fields of study!",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,22.0,,33.0,1,23838
247,/learn/analytics-tableau,Data Visualization and Communication with Tableau,Duke University,4.7,153239,2901,676,"One of the skills that characterizes great business data analysts is the ability to communicate practical implications of quantitative analyses to any kind of audience member.  Even the most sophisticated statistical analyses are not useful to a business if they do not lead to actionable advice, or if the answers to those business questions are not conveyed in a way that non-technical people can understand.  In this course you will learn how to become a master at communicating business-relevant implications of data analyses.  By the end, you will know how to structure your data analysis projects to ensure the fruits of your hard labor yield results for your stakeholders.  You will also know how to streamline your analyses and highlight their implications efficiently using visualizations in Tableau, the most popular visualization program in the business world.  Using other Tableau features, you will be able to make effective visualizations that harness the human brain’s innate perceptual and cognitive tendencies to convey conclusions directly and clearly.  Finally, you will be practiced in designing and persuasively presenting business “data stories” that use these visualizations, capitalizing on business-tested methods and design principles.",25,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,30.0,,36.0,1,178945
248,/learn/python-programming,Python Programming Essentials,Rice University,4.8,51000,2773,688,"This course will introduce you to the wonderful world of Python programming!  We'll learn about the essential elements of programming and how to construct basic Python programs. We will cover expressions, variables, functions, logic, and conditionals, which are foundational concepts in computer programming. We will also teach you how to use Python modules, which enable you to benefit from the vast array of functionality that is already a part of the Python language. These concepts and skills will help you to begin to think like a computer programmer and to understand how to go about writing Python programs.By the end of the course, you will be able to write short Python programs that are able to accomplish real, practical tasks. This course is the foundation for building expertise in Python programming. As the first course in a specialization, it provides the necessary building blocks for you to succeed at learning to write more complex Python programs.

This course uses Python 3.  While many Python programs continue to use Python 2, Python 3 is the future of the Python programming language. This first course will use a Python 3 version of the CodeSkulptor development environment, which is specifically designed to help beginning programmers learn quickly.  CodeSkulptor runs within any modern web browser and does not require you to install any software, allowing you to start writing and running small programs immediately.  In the later courses in this specialization,  we will help you to move to more sophisticated desktop development environments.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,30.0,18.0,32.0,1,66574
249,/learn/search-engine-optimization,Introduction to Search Engine Optimization,"University of California, Davis",4.6,173609,7789,2099,"Ever wonder how major search engines such as Google, Bing and Yahoo rank your website within their searches? Or how content such as videos or local listings are shown and ranked based on what the search engine considers most relevant to users? Welcome to the world of Search Engine Optimization (SEO). This course is the first within the SEO Specialization and it is intended to give you a taste of SEO with some fun practices to get seen in Google.You will be introduced to the foundational elements of how the most popular search engine, Google, works, how the SEO landscape is constantly changing and what you can expect in the future. You discuss core SEO strategies and tactics used to drive more organic search results to a specific website or set of websites, as well as tactics to avoid to prevent penalization from Google. We hope this taste of SEO, will entice you to continue through the Specialization!",20,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,41.0,19.0,42.0,1,186051
250,/learn/iiot-google-cloud-platform,Industrial IoT on Google Cloud Platform,Google Cloud,4.5,49107,2302,665,"By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<Welcome to the Coursera course, Industrial Internet of Things (IoT) on Google Cloud Platform (GCP) brought to you by the Google Cloud team. I’m Catherine Gamboa and I’m going to be your guide.

This course covers the entire Industrial IoT network architecture from sensors and devices to analysis. The course discusses sensors and devices but the focus is on the cloud side.  You'll learn about the importance of scaling, device communication, and processing streaming data. The course uses simulated devices in the labs to allow you to concentrate on learning the cloud side of IIoT.  The course is a little different than most Coursera courses because there is very little video. Most of the learning is done with short readings, quizzes, and labs.  

This course takes about two weeks to complete, 11-12 hours of work with 6 of those hours spent in labs.  By the end of this course, you’ll be able to: create a streaming data pipeline, to create registries with Cloud IoT Core, topics and subscriptions with Cloud Pub/Sub, store data on Google Cloud Storage, query the data in BigQuery, and gain data insights with Dataprep.  You'll learn and practice these skills in 7 labs.  Then you'll have an opportunity to test yourself in an optional capstone lab using simulated devices or Cloud IoT Core Inspector.",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,22.0,21.0,13.0,0,67928
251,/learn/reinforcement-learning-in-finance,Reinforcement Learning in Finance,New York University,3.6,17660,105,28,"This course aims at introducing the fundamental concepts of Reinforcement Learning (RL), and develop use cases for applications of RL for option valuation, trading, and asset management. By the end of this course, students will be able to
- Use reinforcement learning to solve classical problems of Finance such as portfolio optimization, optimal trading, and option pricing and risk management.
- Practice on valuable examples such as famous Q-learning using financial problems.
- Apply their knowledge acquired in the course to a simple model for market dynamics that is obtained using reinforcement learning as the course project.

Prerequisites are the courses ""Guided Tour of Machine Learning in Finance"" and ""Fundamentals of Machine Learning in Finance"". Students are expected to know the lognormal process and how it can be simulated. Knowledge of option pricing is not assumed but desirable.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,14680
252,/learn/getting-started-with-google-sheets,Getting Started with Google Sheets,Google Cloud,4.7,91255,946,237,"Google Sheets is a robust, cloud-based application that empowers you to create sophisticated spreadsheets. Whether you are working at your desk—or from your smartphone or tablet on-the-go—Google Sheets helps you organize, analyze, and share your most important data. In this course for Sheets users, you’ll learn how to make your own supercharged spreadsheets. First, you’ll learn how to input and format your data. Next, you’ll learn how formulas, functions and a few exclusive Google Sheets features can accelerate your data analysis. Finally, you’ll get tips for sharing your spreadsheets and collaborating on them with your team.About the Instructor
Malia is a tech professional based in Los Angeles who uses G Suite and Google Sheets everyday to manage projects, collaborate with remote teams, and make data-driven decisions.",5,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,33.0,17.0,,0,48970
253,/learn/sas-macro-language,SAS Macro Language,SAS,4.9,24539,43,8,"In this course, you learn advanced techniques within the DATA step and procedures to manipulate data.Course Learning Objectives: (3+ per course)
“By the end of this course, a learner will be able to…”
●	Perform text substitution in SAS code.
●	Use macro variables and macro functions.
●	Automate and customize the production of SAS code.
●	Conditionally or iteratively construct SAS code.
●	Write self-modifying, data-driven programs.",19,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,2046
254,/learn/communicating-business-analytics-results,Communicating Business Analytics Results,University of Colorado Boulder,4.5,10200,383,79,"The analytical process does not end with models than can predict with accuracy or prescribe the best solution to business problems. Developing these models and gaining insights from data do not necessarily lead to successful implementations. This depends on the ability to communicate results to those who make decisions. Presenting findings to decision makers who are not familiar with the language of analytics presents a challenge. In this course you will learn how to communicate analytics results to  stakeholders who do not understand the details of analytics but want evidence of analysis and data. You will be able to choose the right vehicles to present quantitative information, including those based on principles of data visualization. You will also learn how to develop and deliver data-analytics stories that provide context, insight, and interpretation.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,25.0,,50.0,1,19183
255,/learn/language-processing,Natural Language Processing,HSE University,4.5,62710,762,194,"This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. Upon completing, you will be able to recognize NLP tasks in your day-to-day work, propose approaches, and judge what techniques are likely to work well.  The final project is devoted to one of the most hot topics in today’s NLP. You will build your own conversational chat-bot that will assist with search on StackOverflow website. The project will be based on practical assignments of the course, that will give you hands-on experience with such tasks as text classification, named entities recognition, and duplicates detection. Throughout the lectures, we will aim at finding a balance between traditional and deep learning techniques in NLP and cover them in parallel. For example, we will discuss word alignment models in machine translation and see how similar it is to attention mechanism in encoder-decoder neural networks. Core techniques are not treated as black boxes. On the contrary, you will get in-depth understanding of what’s happening inside. To succeed in that, we expect your familiarity with the basics of linear algebra and probability theory, machine learning setup, and deep neural networks. Some materials are based on one-month-old papers and introduce you to the very state-of-the-art in NLP research.

Do you have technical problems? Write to us: coursera@hse.ru",32,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,42.0,43.0,38.0,1,96065
256,/learn/forensic-accounting,Forensic Accounting and Fraud Examination,West Virginia University,4.7,88538,3459,1042,"Everyday across the world, thousands of businesses are victimized by fraud.  Who commits these bad acts?  Why? And, how? In this course we are going to help you answer the questions: who commits fraud, why and how.  We’ll also help you develop skills for catching them.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,21.0,10.0,23.0,1,66454
257,/learn/analytics-mysql,Managing Big Data with MySQL,Duke University,4.7,114372,3635,837,"This course is an introduction to how to use relational databases in business analysis.  You will learn how relational databases work, and how to use entity-relationship diagrams to display the structure of the data held within them.  This knowledge will help you understand how data needs to be collected in business contexts, and help you identify features you want to consider if you are involved in implementing new data collection efforts.  You will also learn how to execute the most useful query and table aggregation statements for business analysts, and practice using them with real databases. No more waiting 48 hours for someone else in the company to provide data to you – you will be able to get the data by yourself!By the end of this course, you will have a clear understanding of how relational databases work, and have a portfolio of queries you can show potential employers. Businesses are collecting increasing amounts of information with the hope that data will yield novel insights into how to improve businesses. Analysts that understand how to access this data – this means you! – will have a strong competitive advantage in this data-smitten business world.",32,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,42.0,23.0,42.0,1,164018
258,/learn/classification-vector-spaces-in-nlp,Natural Language Processing with Classification and Vector Spaces,DeepLearning.AI,4.7,323609,2496,528,"In Course 1 of the Natural Language Processing Specialization, offered by deeplearning.ai, you will:   a) Perform sentiment analysis of tweets using logistic regression and then naïve Bayes, 
b) Use vector space models to discover relationships between words and use PCA to reduce the dimensionality of the vector space and visualize those relationships, and
c) Write a simple English to French translation algorithm using pre-computed word embeddings and locality sensitive hashing to relate words via approximate k-nearest neighbor search.   
    
Please make sure that you’re comfortable programming in Python and have a basic knowledge of machine learning, matrix multiplications, and conditional probability.   
   
By the end of this Specialization, you will have designed NLP applications that perform question-answering and sentiment analysis, created tools to translate languages and summarize text, and even built a chatbot!   
   
This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. Łukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.",31,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,72908
259,/learn/computational-social-science-methods,Computational Social Science Methods,"University of California, Davis",4.7,13988,195,49,"This course gives you an overview of the current opportunities and the omnipresent reach of computational social science. The results are all around us, every day, reaching from the services provided by the world’s most valuable companies, over the hidden influence of governmental agencies, to the power of social and political movements. All of them study human behavior in order to shape it. In short, all of them do social science by computational means.In this course we answer three questions:
I.    Why Computational Social Science (CSS) now? 
II.    What does CSS cover?
III.    What are examples of CSS?

In this last part, we take a bird’s-eye view on four main applications of CSS. First, Prof. Blumenstock from UC Berkeley discusses how we can gain insights by studying the massive digital footprint left behind today’s social interactions, especially to foster international development. Second, Prof. Shelton from UC Riverside introduces us to the world of machine learning, including the basic concepts behind this current driver of much of today's computational landscape. Prof. Fowler, from UC San Diego introduces us to the power of social networks, and finally, Prof. Smaldino, from UC Merced, explains how computer simulation help us to untangle some of the mysteries of social emergence.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,7287
260,/learn/dataviz-project,Data Visualization with Tableau Project,"University of California, Davis",4.7,40174,376,61,"In this project-based course, you will follow your own interests to create a portfolio worthy single-frame viz or multi-frame data story that will be shared on Tableau Public. You will use all the skills taught in this Specialization to complete this project step-by-step, with guidance from your instructors along the way. You will first create a project proposal to identify your goals for the project, including the question you wish to answer or explore with data. You will then find data that will provide the information you are seeking. You will then import that data into Tableau and  prepare it for analysis. Next you will create a dashboard that will allow you to explore the data in depth and identify meaningful insights. You will then give structure to your data story by writing the story arc in narrative form. Finally, you will consult your design checklist to craft the final viz or data story in Tableau. This is your opportunity to show the world what you’re capable of - so think big, and have confidence in your skills!",12,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,18.0,10.0,,1,17662
261,/learn/information-theory,Information Theory,The Chinese University of Hong Kong,4.7,9717,80,9,"The lectures of this course are based on the first 11 chapters of Prof. Raymond Yeung’s textbook entitled Information Theory and Network Coding (Springer 2008).  This book and its predecessor, A First Course in Information Theory (Kluwer 2002, essentially the first edition of the 2008 book), have been adopted by over 60 universities around the world as either a textbook or reference text.At the completion of this course, the student should be able to:
1) Demonstrate knowledge and understanding of the fundamentals of information theory.
2) Appreciate the notion of fundamental limits in communication systems and more generally all systems.
3) Develop deeper understanding of communication systems.
4) Apply the concepts of information theory to various disciplines in information science.",33,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,11001
262,/learn/qualitative-methods,Qualitative Research Methods,University of Amsterdam,4.6,89209,983,347,"In this course you will be introduced to the basic ideas behind the qualitative research in social science. You will learn about data collection, description, analysis and interpretation in qualitative research. Qualitative research often involves an iterative process. We will focus on the ingredients required for this process: data collection and analysis.You won't learn how to use qualitative methods by just watching video's, so we put much stress on collecting data through observation and interviewing and on analysing and interpreting the collected data in other assignments.
Obviously, the most important concepts in qualitative research will be discussed, just as we will discuss quality criteria, good practices, ethics, writing some methods of analysis, and mixing methods.
We hope to take away some prejudice, and enthuse many students for qualitative research.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,78519
263,/learn/data-science-for-business-innovation,Data Science for Business Innovation,EIT Digital ,4.2,9194,128,38,"The course is a compendium of the must-have expertise in data science for executive and middle-management to foster data-driven innovation. It consists of introductory lectures spanning big data, machine learning, data valorization and communication. Topics cover the essential concepts and intuitions on data needs, data analysis, machine learning methods, respective pros and cons, and practical applicability issues.	The course covers terminology and concepts, tools and methods, use cases and success stories of data science applications. 
The course explains what is Data Science and why it is so hyped. It discusses the value that Data Science can create, the main classes of problems that Data Science can solve, the difference is between descriptive, predictive and prescriptive analytics, and the roles of machine learning and artificial intelligence.

From a more technical perspective, the course covers supervised, unsupervised and semi-supervised methods, and explains what can be obtained with classification, clustering, and regression techniques. It discusses the role of NoSQL data models and technologies, and the role and impact of scalable cloud-based computation platforms.
All topics are covered with example-based lectures, discussing use cases, success stories and realistic examples.",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,6229
264,/learn/ibm-unsupervised-learning, Unsupervised Learning,IBM,4.8,30135,43,10,"This course introduces you to one of the main types of Machine Learning: Unsupervised Learning. You will learn how to find insights from data sets that do not have a target or labeled variable. You will learn several clustering and dimension reduction algorithms for unsupervised learning as well as how to select the algorithm that best suits your data. The hands-on section of this course focuses on using best practices for unsupervised learning.By the end of this course you should be able to:
Explain the kinds of problems suitable for Unsupervised Learning approaches
Explain the curse of dimensionality, and how it makes clustering difficult with many features
Describe and use common clustering and dimensionality-reduction algorithms
Try clustering points where appropriate, compare the performance of per-cluster models
Understand metrics relevant for characterizing clusters

Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Unsupervised Machine Learning techniques in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Probability, and Statistics.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,2818
265,/learn/analytics-capstone,Increasing Real Estate Management Profits: Harnessing Data Analytics,Duke University,4.7,21930,223,49,"In this final course you will complete a Capstone Project using data analysis to recommend a method for improving profits for your company, Watershed Property Management, Inc. Watershed is responsible for managing thousands of residential rental properties throughout the United States. Your job is to persuade Watershed’s management team to pursue a new strategy for managing its properties that will increase their profits. To do this, you will: (1) Elicit information about important variables relevant to your analysis; (2) Draw upon your new MySQL database skills to extract relevant data from a real estate database; (3) Implement data analysis in Excel to identify the best opportunities for Watershed to increase revenue and maximize profits, while managing any new risks; (4) Create a Tableau dashboard to show Watershed executives the results of a sensitivity analysis; and (5) Articulate a significant and innovative business process change for Watershed based on your data analysis, that you will recommend to company executives. Airbnb, our Capstone’s official Sponsor, provided input on the project design. The top 10 Capstone completers each year will have the opportunity to present their work directly to senior data scientists at Airbnb live for feedback and discussion.

""Note: Only learners who have passed the four previous courses in the specialization are eligible to take the Capstone.""",23,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,47.0,50.0,27.0,1,12405
266,/learn/managing-data-analysis,Managing Data Analysis,Johns Hopkins University,4.6,35504,3082,434,"This one-week course describes the process of analyzing data and how to manage that process. We describe the iterative nature of data analysis and the role of stating a sharp question, exploratory data analysis, inference, formal statistical modeling, interpretation, and communication. In addition, we will describe how to direct analytic activities within a team and to drive the data analysis process towards coherent and useful results. This is a focused course designed to rapidly get you up to speed on the process of data analysis and how it can be managed. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.

After completing this course you will know how to….

1. Describe the basic data analysis iteration
2. Identify different types of questions and translate them to specific datasets
3. Describe different types of data pulls
4. Explore datasets to determine if data are appropriate for a given question
5. Direct model building efforts in common data analyses
6. Interpret the results from common data analyses
7. Integrate statistical findings to form coherent data analysis presentations

Commitment: 1 week of study, 4-6 hours

Course cover image by fdecomite. Creative Commons BY https://flic.kr/p/4HjmvD",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,28.0,,26.0,1,59021
267,/learn/custom-distributed-training-with-tensorflow,Custom and Distributed Training with TensorFlow,DeepLearning.AI,4.8,52862,125,19,"In this course, you will:• Learn about Tensor objects, the fundamental building blocks of TensorFlow, understand the difference between the eager and graph modes in TensorFlow, and learn how to use a TensorFlow tool to calculate gradients.
• Build your own custom training loops using GradientTape and TensorFlow Datasets to gain more flexibility and visibility with your model training. 
• Learn about the benefits of generating code that runs in graph mode, take a peek at what graph code looks like, and practice generating this more efficient code automatically with TensorFlow’s tools.
• Harness the power of distributed training to process more data and train larger models, faster, get an overview of various distributed training strategies, and practice working with a strategy that trains on multiple GPU cores, and another that trains on multiple TPU cores.


The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture and tools that help them create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",24,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,4365
268,/learn/geodesign,Geodesign: Change Your World,The Pennsylvania State University,4.7,7125,42,15,"What happens when creativity and science come together?  The power to design our world is unleashed, providing tools to inform choices about how we live!  Geodesign is the glue—it’s a process that deploys creativity to connect information to people, using collaboration to better inform how we design our world.This course includes well-illustrated lectures by the instructor, but also guest lectures each week to ensure you are hearing a variety of viewpoints.  Each week you will also be able to examine what geodesign is through interactive mapping that showcases real-word Case Study examples of geodesign from around the globe.  As you move along in the course, you will discover the interrelationships of both the physical and human aspects that contribute to how geodesign strategies are composed.  The course concludes with you outlining your own Geodesign Challenge, and receiving feedback about that from your peers.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,80.0,,50.0,1,5804
269,/learn/statistical-inference,Statistical Inference,Johns Hopkins University,4.2,118014,4212,852,"Statistical inference is the process of drawing conclusions about populations or scientific truths from data. There are many modes of performing inference including statistical modeling, data oriented strategies and explicit use of designs and randomization in analyses. Furthermore, there are broad theories (frequentists, Bayesian, likelihood, design based, …) and numerous complexities (missing data, observed and unobserved confounding, biases) for performing inference. A practitioner can often be left in a debilitating maze of techniques, philosophies and nuance. This course presents the fundamentals of inference in a practical approach for getting things done. After taking this course, students will understand the broad directions of statistical inference and use this information for making informed choices in analyzing data.",54,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,33.0,11.0,37.0,1,150668
270,/learn/introducao-big-data,Introdução ao Big Data ,Fundação Instituto de Administração,4.6,7388,301,91,"Este curso é indicado para profissionais que desejam entender de forma fácil o que é Big Data, conhecer algumas tecnologias de Big Data, ter acesso a algumas aplicações de Analytics, Internet das Coisas - IOT e de Big Data. Ao final do curso você será capaz de participar de um projeto de Big Data contribuindo com estratégias e direcionando o projeto para a escolha da adequada técnica de análise de dados.",16,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,60.0,27.0,67.0,0,13970
271,/learn/probabilistic-graphical-models-2-inference,Probabilistic Graphical Models 2: Inference,Stanford University,4.6,16285,463,73,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. This course is the second in a sequence of three. Following the first course, which focused on representation, this course addresses the question of probabilistic inference: how a PGM can be used to answer questions. Even though a PGM generally describes a very high dimensional distribution, its structure is designed so as to allow questions to be answered efficiently. The course presents both exact and approximate algorithms for different types of inference tasks, and discusses where each could best be applied. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of the most commonly used exact and approximate algorithms are implemented and applied to a real-world problem.",38,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,18.0,18.0,17.0,1,20864
272,/learn/linear-models,Advanced Linear Models for Data Science 1: Least Squares,Johns Hopkins University,4.4,9851,150,38,"Welcome to the Advanced Linear Models for Data Science Class 1: Least Squares. This class is an introduction to least squares from a linear algebraic and mathematical perspective. Before beginning the class make sure that you have the following:- A basic understanding of linear algebra and multivariate calculus.
- A basic understanding of statistics and regression models.
- At least a little familiarity with proof based mathematics.
- Basic knowledge of the R programming language.

After taking this course, students will have a firm foundation in a linear algebraic treatment of regression modeling. This will greatly augment applied data scientists' general understanding of regression models.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,24161
273,/learn/reproducible-templates-analysis,Reproducible Templates for Analysis and Dissemination ,Emory University,4.6,4152,16,10,"This course will assist you with recreating work that a previous coworker completed, revisiting a project you abandoned some time ago, or simply reproducing a document with a consistent format and workflow. Incomplete information about how the work was done, where the files are, and which is the most recent version can give rise to many complications. This course  focuses on the proper documentation creation process, allowing you and your colleagues to easily reproduce the components of your workflow. Throughout this course, you'll receive helpful demonstrations of RStudio and the R Markdown language and engage in active learning opportunities to help you build a professional online portfolio.",20,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,1593
274,/learn/big-data-machine-learning,Machine Learning With Big Data,University of California San Diego,4.6,35296,2302,485,"Want to make sense of the volumes of data you have collected?  Need to incorporate data-driven decisions into your process?  This course provides an overview of machine learning techniques to explore, analyze, and leverage data.  You will be introduced to tools and algorithms you can use to create machine learning models that learn from data, and to scale those models up to big data problems.At the end of the course, you will be able to:
•	Design an approach to leverage data using the steps in the machine learning process.
•	Apply machine learning techniques to explore and prepare data for modeling.
•	Identify the type of machine learning problem in order to apply the appropriate set of techniques.
•	Construct models that learn from data using widely available open source tools.
•	Analyze big data problems using scalable machine learning algorithms on Spark.

Software Requirements: 
Cloudera VM, KNIME, Spark",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,41.0,14.0,42.0,1,58983
275,/learn/meaningful-marketing-insights,Meaningful Marketing Insights,Emory University,4.3,19752,226,59,"With marketers are poised to be the largest users of data within the organization, there is a need to make sense of the variety of consumer data that the organization collects. Surveys, transaction histories and billing records can all provide insight into consumers’ future behavior, provided that they are interpreted correctly. In Introduction to Marketing Analytics, we introduce the tools that learners will need to convert raw data into marketing insights. The included exercises are conducted using Microsoft Excel, ensuring that learners will have the tools they need to extract information from the data available to them. The course provides learners with exposure to essential tools including exploratory data analysis, as well as regression methods that can be used to investigate the impact of marketing activity on aggregate data (e.g., sales) and on individual-level choice data (e.g., brand choices). To successfully complete the assignments in this course, you will require Microsoft Excel. If you do not have Excel, you can download a free 30-day trial here: https://products.office.com/en-us/try",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,17.0,,33.0,1,26182
276,/learn/financial-regulation,Financial Regulation in Emerging Markets and the Rise of Fintech Companies,University of Cape Town,4.6,6974,113,25,"This course gives an overview of the changing regulatory environment since the 1997 Asian and 2008 global financial crisis. Following these two major crises, governments around the globe enacted a set of far-reaching new financial regulations that are aimed towards safeguarding financial stability. However, banks find it increasingly difficult to be profitable in this new regulatory environment. Technology, at the same time, has taken important leaps forward with the emergence of sophisticated models of artificial intelligence and the invention of the blockchain. These two developments fuel the emergence of fintech companies around the world. This course discusses fintech regulation in emerging markets using case studies from China and South Africa. The course pays special attention to the socioeconomic environment in emerging markets, as well as to political risk as a major source of uncertainty for fintech entrepreneurs. Peer-to-peer lending and remittances are used as leading examples for fintech innovation in emerging markets.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,50.0,25.0,,1,6517
277,/learn/inferential-statistics,Inferential Statistics,University of Amsterdam,4.3,36541,486,142,"Inferential statistics are concerned with making inferences based on relations found in the sample, to relations in the population. Inferential statistics help us decide, for example, whether the differences between groups that we see in our data are strong enough to provide support for our hypothesis that group differences exist in general, in the entire population.We will start by considering the basic principles of significance testing: the sampling and test statistic distribution, p-value, significance level, power and type I and type II errors. Then we will consider a large number of statistical tests and techniques that help us make inferences for different types of data and different types of research designs. For each individual statistical test we will consider how it works, for what data and design it is appropriate and how results should be interpreted. You will also learn how to perform these tests using freely available software. 

For those who are already familiar with statistical testing: We will look at z-tests for 1 and 2 proportions,  McNemar's test for dependent proportions, t-tests for 1 mean (paired differences) and 2 means, the Chi-square test for independence, Fisher’s exact test, simple regression (linear and exponential) and multiple regression (linear and logistic), one way and factorial analysis of variance, and non-parametric tests (Wilcoxon, Kruskal-Wallis, sign test,  signed-rank test, runs test).",23,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,35.0,,50.0,1,52579
278,/learn/nosql-databases,NoSQL systems,Universidad Nacional Autónoma de México,4.2,13288,112,26,"Welcome to the specialization course of NoSQL Systems. This course will be completed on six weeks, it will be supported with videos and exercises that will allow you to identify the differences between the relational and NoSQL databases. 
As part of these alternative technologies the student will learn the main characteristics and how to implement the typical NoSQL databases, such as Key-value, columnar, document and graph. 
Let's start!

After completing this course, a learner will be able to
●	Identify what type of NoSQL database to implement based on business requirements (key-value, document, full text, graph, etc.)
●	Apply NoSQL data modeling from application specific queries
●	Use Atomic Aggregates and denormalization as data modelling techniques to optimize query processing

Software to download:
MongoDB
Neo4j
SAPIQ
Cassandra

In case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,8027
279,/learn/probability-intro,Introduction to Probability and Data with R,Duke University,4.7,180927,4771,1139,"This course introduces you to sampling and exploring data, as well as basic probability theory and Bayes' rule. You will examine various types of sampling methods, and discuss how such methods can impact the scope of inference. A variety of exploratory data analysis techniques will be covered, including numeric summary statistics and basic data visualization. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The concepts and techniques in this course will serve as building blocks for the inference and modeling courses in the Specialization.",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,28.0,13.0,30.0,1,219734
280,/learn/mlops-fundamentals,MLOps (Machine Learning Operations) Fundamentals,Google Cloud,4.0,88607,198,67,"This course introduces participants to MLOps tools and best practices for deploying, evaluating, monitoring and operating production ML systems on Google Cloud. MLOps is a discipline focused on the deployment, testing, monitoring, and automation of ML systems in production. Machine Learning Engineering professionals use tools for continuous improvement and evaluation of deployed models. They work with (or can be) Data Scientists, who develop models, to enable velocity and rigor in deploying the best performing models.This course is primarily intended for the following participants:
Data Scientists looking to quickly go from machine learning prototype to production to deliver business impact.
Software Engineers looking to develop Machine Learning Engineering skills.
ML Engineers who want to adopt Google Cloud for their ML production projects.



>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",14,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,,,,0,15964
281,/learn/nlp-sequence-models,Sequence Models,DeepLearning.AI,4.8,519191,26390,3112,"In the fifth course of the Deep Learning Specialization, you will become familiar with NLP models and their exciting applications such as speech recognition, music synthesis, chatbots, machine translation, natural language understanding, and more that have become possible with the evolution of sequence algorithms thanks to deep learning. By the end, you will be able to build and train Recurrent Neural Networks and commonly-used variants such as GRUs and LSTMs; apply RNNs to Character-level Language Modeling; gain experience with natural language processing and Word Embeddings; and use HuggingFace tokenizers and transformer models to solve different NLP tasks such as NER and Question Answering.

DeepLearning.AI is proud to partner with NVIDIA Deep Learning Institute (DLI) to provide a programming assignment on Machine Translation with Deep Learning. Get an opportunity to build a deep learning project with leading-edge techniques using industry-relevant use cases.

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",16,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,39.0,13.0,38.0,0,284932
282,/learn/adquisicion-almacenamiento-de-datos,Big Data: adquisición y almacenamiento de datos,Universitat Autònoma de Barcelona,4.4,18061,556,243,"¿Estás interesado en tener un conocimiento más detallado sobre las herramientas y aplicaciones Big Data?En este curso aprenderás los principios para comprender la terminología, conceptos básicos y herramientas más importantes para resolver problemas de análisis de datos enfocándonos en los problemas y las aplicaciones. El objetivo es proporcionar una visión de sistema para entender los retos más importantes que nos encontramos cuando trabajamos en entornos con grandes volúmenes de datos.

En el curso se plantea una introducción a diversas herramientas utilizadas de forma común en la comunidad como Hadoop, Spark o Hive y tendrás que resolver diferentes retos de análisis de datos mediante su uso.

Al terminar el curso habrás adquirido conocimientos sobre el ecosistema de herramientas Big Data incluyendo ejemplos de uso con problemas industriales y científicos. Tendrás una serie de recursos sobre cómo un análisis a realizar se traduce en  una serie de operaciones de recolección de datos, monitorización, almacenamiento, análisis y creación de informes sobre los resultados obtenidos. También adquirirás un criterio para elegir cuál es la herramienta más adecuada para resolver un cierto problema de análisis de datos a partir de los requerimientos de uso de las herramientas. 

El curso está orientado tanto a estudiantes universitarios de primeros cursos de estudios universitarios relacionados con la informática, la ingeniería o las matemáticas, como a otros estudiantes con conocimientos de programación, interesados en aprender cómo utilizar de análisis de datos con herramientas de código abierto.  Para realizar los ejercicios es necesario utilizar una máquina virtual que deberá ser instalada en tu ordenador.",11,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,50.0,50.0,33.0,0,13835
283,/learn/introduction-to-ai,Introduction to Artificial Intelligence (AI),IBM,4.7,252295,7237,1597,"In this course you will learn what Artificial Intelligence (AI) is, explore use cases and applications of AI, understand AI concepts and terms like machine learning, deep learning and neural networks. You will be exposed to various issues and concerns surrounding AI such as ethics and bias, & jobs, and get advice from experts about learning and starting a career in AI.  You will also demonstrate AI in action with a mini project.This course does not require any programming or computer science expertise and is designed to introduce the basics of AI to anyone whether you have a technical background or not.",8,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,15.0,13.0,,0,125164
284,/learn/network-biology,Network Analysis in Systems Biology,Icahn School of Medicine at Mount Sinai,4.5,15603,171,25,"An introduction to data integration and statistical methods used in contemporary Systems Biology, Bioinformatics and Systems Pharmacology research. The course covers methods to process raw data from genome-wide mRNA expression studies (microarrays and RNA-seq) including data normalization, differential expression, clustering, enrichment analysis and network construction. The course contains practical tutorials for using tools and setting up pipelines, but it also covers the mathematics behind the methods applied within the tools. The course is mostly appropriate for beginning graduate students and advanced undergraduates majoring in fields such as biology, math, physics, chemistry, computer science, biomedical and electrical engineering. The course should be useful for researchers who encounter large datasets in their own research. The course presents software tools developed by the Ma’ayan Laboratory (http://labs.icahn.mssm.edu/maayanlab/) from the Icahn School of Medicine at Mount Sinai, but also other freely available data analysis and visualization tools. The ultimate aim of the course is to enable participants to utilize the methods presented in this course for analyzing their own data for their own projects. For those participants that do not work in the field, the course introduces the current research challenges faced in the field of computational systems biology.",30,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,25.0,25.0,50.0,0,16746
285,/learn/generative-deep-learning-with-tensorflow,Generative Deep Learning with TensorFlow,DeepLearning.AI,4.9,42334,64,9,"In this course, you will: a) Learn neural style transfer using transfer learning: extract the content of an image (eg. swan), and the style of a painting (eg. cubist or impressionist), and combine the content and style into a new image. 
b) Build simple AutoEncoders on the familiar MNIST dataset, and more complex deep and convolutional architectures on the Fashion MNIST dataset, understand the difference in results of the DNN and CNN AutoEncoder models, identify ways to de-noise noisy images, and build a CNN AutoEncoder using TensorFlow to output a clean image from a noisy one.
c) Explore Variational AutoEncoders (VAEs) to generate entirely new data, and generate anime faces to compare them against reference images. 
d) Learn about GANs; their invention, properties, architecture, and how they vary from VAEs, understand the function of the generator and the discriminator within the model, the concept of 2 training phases and the role of introduced noise, and build your own GAN that can generate faces.

The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture, and gives them the tools to create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",22,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,3025
286,/learn/convolutional-neural-networks-tensorflow,Convolutional Neural Networks in TensorFlow,DeepLearning.AI,4.7,298473,6417,999,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This course is part of the upcoming Machine Learning in Tensorflow Specialization and will teach you best practices for using TensorFlow, a popular open-source framework for machine learning.In Course 2 of the deeplearning.ai TensorFlow Specialization, you will learn advanced techniques to improve the computer vision model you built in Course 1. You will explore how to work with real-world images in different shapes and sizes, visualize the journey of an image through convolutions to understand how a computer “sees” information, plot loss and accuracy, and explore strategies to prevent overfitting, including augmentation and dropout. Finally, Course 2 will introduce you to transfer learning and how learned features can be extracted from models. 

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.",26,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,11.0,,,0,89235
287,/learn/information-visualization-applied-perception,Information Visualization: Applied Perception,New York University,4.8,11205,86,24,This module aims at introducing fundamental concepts of visual perception applied to information visualization. These concepts help the student ideate and evaluate visualization designs in terms of how well they leverage the capabilities of the human perceptual machinery.,12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,50.0,25.0,,1,3304
288,/learn/training-others-nursing-informatics,Nursing Informatics Training and Education,University of Minnesota,4.8,4549,57,16,"In this fourth of our five courses, I will go deeper into the training and education leadership skills that are helpful for nursing informatics leaders. I will also guide you through the process of preparing a course document or syllabus for the nursing informatics specialty both in academic settings and in practice or industry.Following are the course objectives:
1. Describe relevant nursing informatics course development in clinical and academic settings to understand similarities and differences in informatics teaching and education across settings.
2. Describe informatics education and training needs for diverse participants with various experience levels to enable development of appropriate training and education materials.
3. Develop a prototype course syllabus and introductory recorded message to apply learning in a simulated setting.
4. Describe the benefits of formal and informal mentoring for nursing informaticians to advance career opportunities and support the nursing informatics specialty.",21,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,3075
289,/learn/hadoop,Hadoop Platform and Application Framework,University of California San Diego,4.0,36569,3220,756,"This course is for novice programmers or business people who would like to understand the core tools used to wrangle and analyze big data. With no prior experience, you will have the opportunity to walk through hands-on examples with Hadoop and Spark frameworks, two of the most common in the industry. You will be comfortable explaining the specific components and basic processes of the Hadoop architecture, software stack, and execution environment.   In the assignments you will be guided in how data scientists apply the important concepts and techniques such as Map-Reduce that are used to solve fundamental problems in big data.  You'll feel empowered to have conversations about big data and the data analysis process.",26,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,30.0,11.0,29.0,1,138675
290,/learn/sas-programming-advanced,Doing More with SAS Programming,SAS,4.8,67547,641,105,"This course is for business analysts and SAS programmers who want to learn data manipulation techniques using the SAS DATA step and procedures to access, transform, and summarize data. The course builds on the concepts that are presented in the Getting Started with SAS Programming course and is not recommended for beginning SAS software users.In this course you learn how to understand and control DATA step processing, create an accumulating column and process data in groups, manipulate data with functions, convert column type, create custom formats, concatenate and merge tables, process repetitive code, and restructure tables. This course addresses Base SAS software.

Before attending this course, you should be able to write DATA step code to access data, subset rows and columns, compute new columns, and process data conditionally. You should also be able to sort tables using the SORT procedure and
apply SAS formats.",24,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,33.0,50.0,,0,20077
291,/learn/pca-machine-learning,Mathematics for Machine Learning: PCA,Imperial College London,4.0,258020,2541,628,"This intermediate-level course introduces the mathematical foundations to derive Principal Component Analysis (PCA), a fundamental dimensionality reduction technique. We'll cover some basic statistics of data sets, such as mean values and variances, we'll compute distances and angles between vectors using inner products and derive orthogonal projections of data onto lower-dimensional subspaces. Using all these tools, we'll then derive PCA as a method that minimizes the average squared reconstruction error between data points and their reconstruction.At the end of this course, you'll be familiar with important mathematical concepts and you can implement PCA all by yourself. If you’re struggling, you'll find a set of jupyter notebooks that will allow you to explore properties of the techniques and walk you through what you need to do to get on track. If you are already an expert, this course may refresh some of your knowledge.

The lectures, examples and exercises require:
1. Some ability of abstract thinking
2. Good background in linear algebra (e.g., matrix and vector algebra, linear independence, basis)
3. Basic background in multivariate calculus (e.g., partial derivatives, basic optimization)
4. Basic knowledge in python programming and numpy

Disclaimer: This course is substantially more abstract and requires more programming than the other two courses of the specialization. However, this type of abstract thinking, algebraic manipulation and programming is necessary if you want to understand and develop machine learning algorithms.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,44.0,,47.0,1,57716
292,/learn/geospatial,Maps and the Geospatial Revolution,The Pennsylvania State University,4.7,10524,203,71,"Learn how advances in geospatial technology and analytical methods have changed how we do everything, and discover how to make maps and analyze geographic patterns using the latest tools.The past decade has seen an explosion of new mechanisms for understanding and using location information in widely-accessible technologies. This Geospatial Revolution has resulted in the development of consumer GPS tools, interactive web maps, and location-aware mobile devices. These radical advances are making it possible for people from all walks of life to use, collect, and understand spatial information like never before.
 
This course brings together core concepts in cartography, geographic information systems, and spatial thinking with real-world examples to provide the fundamentals necessary to engage with Geography beyond the surface-level. We will explore what makes spatial information special, how spatial data is created, how spatial analysis is conducted, and how to design maps so that they’re effective at telling the stories we wish to share. To gain experience using this knowledge, we will work with the latest mapping and analysis software to explore geographic problems.",20,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,12.0,,,1,20231
293,/learn/introduction-to-designing-data-lakes-in-aws,Introduction to Designing Data Lakes on AWS,Amazon Web Services,4.7,31669,37,15,"In this class, Introduction to Designing Data Lakes on AWS, we will help you understand how to create and operate a data lake in a secure and scalable way, without previous knowledge of data science! Starting with the ""WHY"" you may want a data lake, we will look at the Data-Lake value proposition, characteristics and components.Designing a data lake is challenging because of the scale and growth of data. Developers need to understand best practices to avoid common mistakes that could be hard to rectify. In this course we will cover the foundations of what a Data Lake is, how to ingest and organize data into the Data Lake, and dive into the data processing that can be done to optimize performance and costs when consuming the data at scale. This course is for professionals (Architects, System Administrators and DevOps) who need to design and build an architecture for secure and scalable Data Lake components. Students will learn about the use cases for a Data Lake and, contrast that with a traditional infrastructure of servers and storage.",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,2944
294,/learn/python-for-data-visualization,Data Visualization with Python,IBM,4.5,410575,9007,1302,"""A picture is worth a thousand words"". We are all familiar with this expression. It especially applies when trying to explain the insight obtained from the analysis of increasingly large datasets. Data visualization plays an essential role in the representation of both small and large-scale data.One of the key skills of a data scientist is the ability to tell a compelling story, visualizing data and findings in an approachable and stimulating way. Learning how to leverage a software tool to visualize data will also enable you to extract information, better understand the data, and make more effective decisions.

The main goal of this Data Visualization with Python course is to teach you how to take data that at first glance has little meaning and present that data in a form that makes sense to people. Various techniques have been developed for presenting data visually but in this course, we will be using several data visualization libraries in Python, namely Matplotlib, Seaborn, and Folium.

LIMITED TIME OFFER: Subscription is only $39 USD per month for access to graded materials and a certificate.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,30.0,,26.0,0,112223
295,/learn/understanding-china-history-part-1,"Understanding China, 1700-2000: A Data Analytic Approach, Part 1",The Hong Kong University of Science and Technology,4.6,3773,91,22,"The purpose of this course is to summarize new directions in Chinese history and social science produced by the creation and analysis of big historical datasets based on newly opened Chinese archival holdings, and to organize this knowledge in a framework that encourages learning about China in comparative perspective.Our course demonstrates how a new scholarship of discovery is redefining what is singular about modern China and modern Chinese history. Current understandings of human history and social theory are based largely on Western experience or on non-Western experience seen through a Western lens. This course offers alternative perspectives derived from Chinese experience over the last three centuries. We present specific case studies of this new scholarship of discovery divided into two stand-alone parts, which means that students can take any part without prior or subsequent attendance of the other part.

Part 1 (this course) focuses on comparative inequality and opportunity and addresses two related questions ‘Who rises to the top?’ and ‘Who gets what?’.

Part 2 (https://www.coursera.org/learn/understanding-china-history-part-2) turns to an arguably even more important question ‘Who are we?’ as seen through the framework of comparative population behavior - mortality, marriage, and reproduction – and their interaction with economic conditions and human values. We do so because mortality and reproduction are fundamental and universal, because they differ historically just as radically between China and the West as patterns of inequality and opportunity, and because these differences demonstrate the mutability of human behavior and values.

Course Overview video: https://youtu.be/dzUPRyJ4ETk",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,6836
296,/learn/erasmus-econometrics,Econometrics: Methods and Applications,Erasmus University Rotterdam,4.6,67435,1033,223,"Welcome!Do you wish to know how to analyze and solve business and economic questions with data analysis tools? Then Econometrics by Erasmus University Rotterdam is the right course for you, as you learn how to translate data into models to make forecasts and to support decision making.

* What do I learn?
When you know econometrics, you are able to translate data into models to make forecasts and to support decision making in a wide variety of fields, ranging from macroeconomics to finance and marketing. Our course starts with introductory lectures on simple and multiple regression, followed by topics of special interest to deal with model specification, endogenous variables, binary choice data, and time series data.  You learn these key topics in econometrics by watching the videos with in-video quizzes and by making post-video training exercises. 

* Do I need prior knowledge?
The course is suitable for (advanced undergraduate) students in economics, finance, business, engineering, and data analysis, as well as for those who work in these fields. The course requires some basics of matrices, probability, and statistics, which are reviewed in the Building Blocks module. If you are searching for a MOOC on econometrics of a more introductory nature that needs less background in mathematics, you may be interested in the Coursera course “Enjoyable Econometrics” that is also from Erasmus University Rotterdam.

* What literature can I consult to support my studies?
You can follow the MOOC without studying additional sources. Further reading of the discussed topics (including the Building Blocks) is provided in the textbook that we wrote and on which the MOOC is based: Econometric Methods with Applications in Business and Economics, Oxford University Press. The connection between the MOOC modules and the book chapters is shown in the Course Guide – Further Information – How can I continue my studies.

* Will there be teaching assistants active to guide me through the course?
Staff and PhD students of our Econometric Institute will provide guidance in January and February of each year. In other periods, we provide only elementary guidance. We always advise you to connect with fellow learners of this course to discuss topics and exercises.

* How will I get a certificate?
To gain the certificate of this course, you are asked to make six Test Exercises (one per module) and a Case Project. Further, you perform peer-reviewing activities of the work of three of your fellow learners of this MOOC. You gain the certificate if you pass all seven assignments.

Have a nice journey into the world of Econometrics!
The Econometrics team",66,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,27.0,20.0,27.0,1,137917
297,/learn/real-life-data-science,Data Science in Real Life,Johns Hopkins University,4.4,19301,2228,267,"Have you ever had the perfect data science experience? The data pull went perfectly. There were no merging errors or missing data. Hypotheses were clearly defined prior to analyses. Randomization was performed for the treatment of interest. The analytic plan was outlined prior to analysis and followed exactly. The conclusions were clear and actionable decisions were obvious. Has that every happened to you? Of course not. Data analysis in real life is messy. How does one manage a team facing real data analyses? In this one-week course, we contrast the ideal with what happens in real life. By contrasting the ideal, you will learn key concepts that will help you manage real life analyses. This is a focused course designed to rapidly get you up to speed on doing data science in real life. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.

After completing this course you will know how to:

1, Describe the “perfect” data science experience
2. Identify strengths and weaknesses in experimental designs
3. Describe possible pitfalls when pulling / assembling data and learn solutions for managing data pulls.
4. Challenge statistical modeling assumptions and drive feedback to data analysts
5. Describe common pitfalls in communicating data analyses
6. Get a glimpse into a day in the life of a data analysis manager.

The course will be taught at a conceptual level for active managers of data scientists and statisticians.  Some key concepts being discussed include:
1. Experimental design, randomization, A/B testing
2. Causal inference, counterfactuals, 
3. Strategies for managing data quality.
4. Bias and confounding
5. Contrasting machine learning versus classical statistical inference

Course promo:
https://www.youtube.com/watch?v=9BIYmw5wnBI

Course cover image by Jonathan Gross. Creative Commons BY-ND https://flic.kr/p/q1vudb",7,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,14.0,,33.0,1,45131
298,/learn/gcp-production-ml-systems,Production Machine Learning Systems,Google Cloud,4.6,24852,835,92,"In the second course of this specialization, we will dive into the components and best practices of a high-performing ML system in production environments. Prerequisites: Basic SQL, familiarity with Python and TensorFlow",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,14.0,,25.0,0,18147
299,/learn/statistics-for-humanities,Статистические методы в гуманитарных исследованиях,National Research Tomsk State University,4.7,13074,53,18,"Курс включает рассмотрение всех основных этапов статистического анализа, начиная от изучения предметной области и правильного сбора данных, заканчивая оценкой адекватности построенной модели и ее интерпретации на языке исходной проблемы. Программа курса построена таким образом, что, начинаясь с основ, будет понятна и доступна слушателям, не имеющим специальной подготовки в области статистического анализа. Однако, по мере продвижения и углубления, в рамках программы рассматриваются более серьезные и глубокие методы исследования. В рамках курса слушатели приобретут базовые навыки работы в программах статистической обработки данных SPSS, Statistica; особый акцент делается на пакет R.Возможна разработка заданий различной сложности для слушателей различного уровня подготовки. 
Цель: ознакомить слушателей с основными статистическими методами, применяемыми при анализе данных в различных областях гуманитарных наук, психологии, социологии, лингвистики и пр., научить решать задачи статистического анализа данных, начиная от формулирования исходных задач соответствующей предметной области на языке прикладной статистики, выбора методов решения и критериев качества полученных решений и заканчивая формулировкой полученных выводов на языке предметной области.


По итогам курса слушатели смогут:
1. Проводить предварительную обработку данных для статистических исследований
2. Применять статистические методы для анализа данных
3. Применять пакеты прикладных программ для реализации статистических методов
4. Интерпретировать полученные результаты

Сертификат о прохождении данного курса дает дополнительные баллы при поступлении в магистратуру Национального исследовательского Томского государственного университета. Перечень магистерских программ находится по ссылке: https://pro-online.tsu.ru/edu/student/table.php",20,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,,,,1,5063
300,/learn/r-data-visualization,Building Data Visualization Tools,Johns Hopkins University,3.9,5085,148,38,"The data science revolution has produced reams of new data from a wide variety of new sources. These new datasets are being used to answer new questions in way never before conceived. Visualization remains one of the most powerful ways draw conclusions from data, but the influx of new data types requires the development of new visualization techniques and building blocks. This course provides you with the skills for creating those new visualization building blocks. We focus on the ggplot2 framework and describe how to use and extend the system to suit the specific needs of your organization or team. Upon completing this course, learners will be able to build the tools needed to visualize a wide variety of data types and will have the fundamentals needed to address new data types as they come about.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,20.0,,33.0,1,10973
301,/learn/business-intelligence-tools,"Business Intelligence Concepts, Tools, and Applications",University of Colorado System,4.5,32638,573,105,"This is the fourth course in the Data Warehouse for Business Intelligence specialization. Ideally, the courses should be taken in sequence.  In this course, you will gain the knowledge and skills for using data warehouses for business intelligence purposes and for working as a business intelligence developer. You’ll have the opportunity to work with large data sets in a data warehouse environment and will learn the use of MicroStrategy's Online Analytical Processing (OLAP) and Visualization capabilities to create visualizations and dashboards. The course gives an overview of how business intelligence technologies can support decision making across any number of business sectors. These technologies have had a profound impact on corporate strategy, performance, and competitiveness and broadly encompass  decision support systems, business intelligence systems, and visual analytics. Modules are organized around the business intelligence concepts, tools, and applications, and the use of data warehouse for business reporting and online analytical processing, for creating visualizations and dashboards, and for business performance management and descriptive analytics.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,36.0,17.0,50.0,1,36430
302,/learn/intro-tensorflow-es,Intro to TensorFlow en Español,Google Cloud,4.4,2206,115,28,"Este curso se enfoca en aprovechar la flexibilidad y facilidad de uso de TensorFlow 2.x y Keras para compilar, entrenar e implementar modelos de aprendizaje automático.  Aprenderá sobre la jerarquía de la API de TensorFlow 2.x y conocerá los componentes principales de TensorFlow mediante ejercicios prácticos.  Le mostraremos cómo trabajar con conjuntos de datos y columnas de atributos. Aprenderá a diseñar y compilar una canalización de datos de entrada de TensorFlow 2.x.  Adquirirá experiencia práctica en la carga de arreglos de NumPy, imágenes y datos de texto con tf.data.Dataset, así como de datos de CSV con Pandas. También adquirirá experiencia práctica en la creación de columnas de atributos numéricas, categóricas, agrupadas en depósitos y con hash.Además, le presentaremos las API secuencial y funcional de Keras para mostrarle cómo crear modelos de aprendizaje profundo.  Hablaremos sobre las funciones de activación, pérdida y optimización.  Nuestros labs prácticos sobre los notebooks de Jupyter le permitirán compilar modelos de aprendizaje automático de regresión lineal básica, y de regresión logística básica y avanzada.  Aprenderá a entrenar, implementar y llevar a producción modelos de aprendizaje automático a gran escala con AI Platform de Cloud.",18,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,,,,0,3493
303,/learn/stats-for-data-analysis,Построение выводов по данным,Moscow Institute of Physics and Technology,4.7,45909,994,147,"Влияет ли знание методов анализа данных на уровень заработной платы? Работает ли система оценки кредитоспособности клиентов банка? Действительно ли новый баннер лучше старого? Чтобы ответить на такие вопросы, нужно собрать данные. Данные почти всегда содержат шум, поэтому утверждения, которые можно сделать на их основе, верны не всегда, а только с определённой вероятностью. Строить наиболее корректные выводы и численно оценивать степень уверенности в них помогают методы статистики. Как можно оценивать неизвестные параметры системы по небольшому количеству наблюдений? Как измерить точность таких оценок? Какие данные нужны, чтобы ответить на ваш вопрос, и на какие вопросы можно ответить с помощью уже имеющихся данных? Вы узнаете все, что нужно для успешного превращения данных в выводы — организация экспериментов, A/B-тестирование, универсальные методы оценки параметров и проверки гипотез, корреляции и причинно-следственные связи.

Видео курса разработаны на Python 2. Задания и ноутбуки к ним адаптированы к Python 3.",27,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,43.0,50.0,33.0,0,20480
304,/learn/machinnoe-obuchenie-v-finansah,Машинное обучение в финансах,SberUniversity,4.5,9378,77,34,"Машинное обучение (Machine Learning, или ML) — это дисциплина о том, как на основе различных алгоритмов обучить компьютер распознавать, классифицировать и предсказывать объекты. Машинное обучение подарило нам эффективный поиск и персонализированный контент в интернете, а в последнее время активно используется в финансах и банковской сфере — наш курс именно об этом!Применение методов ML помогает банку более оперативно принимать решения. Сможет ли вернуть кредит конкретный клиент? Как изменится объем вкладов и кредитов в ближайшей перспективе? Как оптимизировать внутренние процессы?  Эти и многие другие проблемы финансовой сферы помогают решать на практике передовые методы ML.

Если вы студент и видите свое будущее в ML в финансах, но еще не до конца понимаете, чем будете заниматься; или уже работаете в банковской/IT сфере и хотите улучшить свои знания и квалификацию, а может быть, вы просто активно интересуетесь последними тенденциями применения ML — добро пожаловать на онлайн-курс «Машинное обучение в финансах» от команды финансистов Сбербанка!

Наш курс практико-ориентированный: вы узнаете о внедрении и применении ML на примере трейдинга, прогнозировании операционного дохода банка, автоматизации внутренних процессов и др., а также пройдете несколько практических заданий с использованием языка программирования Python. На второй неделе курса используется вероятностный язык программирования Stan. В лекциях и домашних заданиях по прогнозированию представлены базовые примеры моделей в Stan и ссылки на более детальное ознакомление с языком. Освоив эту программу, слушатель научится применять на практике многие методы ML и получит конкурентное преимущество для трудоустройства в финансовой и IT сфере.",21,1,1,1,0,1,0,0,0,0,0,1,0,0,0,0,0,,,,1,7771
305,/learn/advanced-data-science-capstone,Advanced Data Science Capstone,IBM,4.6,13154,352,63,"This project completer has proven a deep understanding on massive parallel data processing, data exploration and visualization, advanced machine learning and deep learning and how to apply his knowledge in a real-world practical use case where he justifies architectural decisions, proves understanding the characteristics of different algorithms, frameworks and technologies and how they impact model performance and scalability. Please note: You are requested to create a short video presentation at the end of the course. This is mandatory to pass. You don't need to share the video in public.",9,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,57.0,,67.0,0,11960
306,/learn/information-visualization-advanced-techniques,Information Visualization: Advanced Techniques,New York University,4.7,11506,27,10,"This course aims to introduce learners to advanced visualization techniques beyond the basic charts covered in Information Visualization: Fundamentals. These techniques are organized around data types to cover advance methods for: temporal and spatial data, networks and trees and textual data. In this module we also teach learners how to develop innovative techniques in D3.js.Learning Goals
Goal: Analyze the design space of visualization solutions for various kinds of data visualization problems. Learn what designs are available for a given problem and what are their respective advantages and disadvantages.
- Temporal
- Spatial
- Spatio-Temporal
- Networks
- Trees
- Text

This is the fourth course in the Information Visualization Specialization. The course expects you to have some basic knowledge of programming as well as some basic visualization skills (as those introduced in the first course of the specialization).",16,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,2895
307,/learn/tensorflow-sequences-time-series-and-prediction,"Sequences, Time Series and Prediction",DeepLearning.AI,4.7,175122,3771,607,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This Specialization will teach you best practices for using TensorFlow, a popular open-source framework for machine learning.In this fourth course, you will learn how to build time series models in TensorFlow. You’ll first implement best practices to prepare time series data. You’ll also explore how RNNs and 1D ConvNets can be used for prediction. Finally, you’ll apply everything you’ve learned throughout the Specialization to build a sunspot prediction model using real-world data!

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.",13,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,74883
308,/learn/advanced-reports-sas-va,Creating Advanced Reports with SAS Visual Analytics,SAS,4.7,5245,151,18,"In this course, you learn how to create advanced data items, filters, and parameters in SAS Visual Analytics.",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,7391
309,/learn/gcp-exploring-preparing-data-bigquery,Exploring ​and ​Preparing ​your ​Data with BigQuery,Google Cloud,4.7,95376,2306,375,"Welcome to the Coursera specialization, From Data to Insights with Google Cloud Platform brought to you by the Google Cloud team. I’m Evan Jones (a data enthusiast) and I’m going to be your guide.This first course in this specialization is Exploring and Preparing your Data with BigQuery. Here we will see what the common challenges faced by data analysts are and how to solve them with the big data tools on Google Cloud Platform. You’ll pick up some SQL along the way and become very familiar with using BigQuery and Cloud Dataprep to analyze and transform your datasets.

This course should take about one week to complete, 5-7 total hours of work.  By the end of this course, you’ll be able to query and draw insight from millions of records in our BigQuery public datasets. You’ll learn how to assess the quality of your datasets and develop an automated data cleansing pipeline that will output to BigQuery. Lastly, you’ll get to practice writing and troubleshooting SQL on a real Google Analytics e-commerce dataset to drive marketing insights.

>>> By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,23.0,12.0,27.0,0,43377
310,/learn/data-analysis-project,Анализ данных: финальный проект,Moscow Institute of Physics and Technology,4.7,16790,317,61,"Финальный проект даст вам возможность применить полученные в рамках специализации знания к задаче из реального мира. Под руководством успешных специалистов в науке о данных вы сможете поработать над актуальным проектом в одной из областей: электронная коммерция, социальные медиа, информационный поиск, бизнес-аналитика и др.В отличие от задач, основанных на модельных данных, работа над проектом из реальной жизни даст вам возможность самостоятельно пройти все этапы анализа данных — от подготовки данных до построения финальной модели и оценки её качества. В результате в вашем арсенале появится проект, который вы сможете использовать на практике и самостоятельно развивать в дальнейшем.

Наличие такого проекта станет вашим конкурентным преимуществом, ведь вы всегда сможете продемонстрировать успешный проект потенциальному работодателю.

Видео курса разработаны на Python 2. Задания и ноутбуки к ним адаптированы к Python 3.",44,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,65.0,,75.0,0,3564
311,/learn/factorial-fractional-factorial-designs,Factorial and Fractional Factorial Designs,Arizona State University,4.8,11447,35,7,"Many experiments in engineering, science and business involve several factors.  This course is an introduction to these types of multifactor experiments.  The appropriate experimental strategy for these situations is based on the factorial design, a type of experiment where factors are varied together.  This course focuses on designing these types of experiments and on using the ANOVA for analyzing the resulting data.  These types of experiments often include nuisance factors, and  the blocking principle can be used in factorial designs to handle these situations.  As the number of factors of interest grows full factorials become too expensive and fractional versions of the factorial design are useful.  This course will  cover the benefits of fractional factorials, along with methods for constructing and analyzing the data from these experiments.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,2330
312,/learn/sql-server-shujuku-jishu,SQL Server数据库技术,Xi'an Jiaotong University,4.7,2454,61,10,在信息化社会，充分有效地管理和利用各类信息资源，是进行科学研究和决策管理的前提。数据库技术是有效地管理和利用各类信息资源的重要技术手段。通过本课程，你将获得数据库技术的基本知识，学会通过SQL Server数据库管理系统管理数据，包括安装数据库管理系统，创建数据库和数据表，插入数据和维护数据等，特别是可以使用SQL Server按各种条件查询需要的信息。,9,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,1,,,,1,7203
313,/learn/analticas-y-mtricas-de-marketing,Analíticas y Métricas de Marketing,Tecnológico de Monterrey,4.9,18169,23,13,"En este primer curso se comprenderá el comportamiento de los usuarios y el impacto en la medición de interacciones que se dan en las Páginas web, Landing page o búsquedas de información de navegadores tradicionales. También podremos distinguir las principales herramientas de la analítica que se utilizan en el mercado y la importancia en el uso de Google Analytics. También será relevante identificar los principales objetivos comerciales y de marca a través del uso de las herramientas y métricas de analítica web.Los objetivos del curso son los siguientes:
1. Comprender el comportamiento de los usuarios y el impacto en la medición de interacciones que se dan en las Páginas web, Landing page o búsquedas de información de navegadores tradicionales.
2. Distinguir las principales herramientas de analítica que se utilizan en el mercado y la importancia en el uso de Google Analytics.
3. Identificar los principales objetivos comerciales y de marca a través del uso de las herramientas y métricas de analítica web.

Es importante aclarar que junto con los alcances de los cursos 1 y 2 podremos entender la importancia que tienen las métricas en Marketing, haciendo un enlace entre lo tradicional y lo digital, con la intención de proporcionar las habilidades para desarrollar y editar sitios web para hacerlos más atractivos, así como enlazarlos con el uso de las redes sociales adecuadas para lograr un match con la estrategia organizacional y alcanzar los objetivos que tenga la organización.",29,1,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,,,,0,2260
314,/learn/recommendation-models-gcp,Recommendation Systems with TensorFlow on GCP,Google Cloud,4.5,18617,402,69,"In this course, you'll apply your knowledge of classification models and embeddings to build a ML pipeline that functions as a recommendation engine.• Devise a content-based recommendation engine
• Implement a collaborative filtering recommendation engine
• Build a hybrid recommendation engine with user and content embeddings

>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,40.0,29.0,20.0,0,12799
315,/learn/build-better-generative-adversarial-networks-gans,Build Better Generative Adversarial Networks (GANs),DeepLearning.AI,4.7,61131,370,58,"In this course, you will:- Assess the challenges of evaluating GANs and compare different generative models
- Use the Fréchet Inception Distance (FID) method to evaluate the fidelity and diversity of GANs
- Identify sources of bias and the ways to detect it in GANs
- Learn and implement the techniques associated with the state-of-the-art StyleGANs

The DeepLearning.AI Generative Adversarial Networks (GANs) Specialization provides an exciting introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach. It also covers social implications, including bias in ML and the ways to detect it, privacy preservation, and more.

Build a comprehensive knowledge base and gain hands-on experience in GANs. Train your own model using PyTorch, use it to create images, and evaluate a variety of advanced GANs. 

This Specialization provides an accessible pathway for all levels of learners looking to break into the GANs space or apply GANs to their own projects, even without prior familiarity with advanced math and machine learning research.",29,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,,,,0,10835
316,/learn/r-programming,R Programming,Johns Hopkins University,4.5,608565,20676,4438,"In this course you will learn how to program in R and how to use R for effective data analysis. You will learn how to install and configure software necessary for a statistical programming environment and describe generic programming language concepts as they are implemented in a high-level statistical language. The course covers practical issues in statistical computing which includes programming in R, reading data into R, accessing R packages, writing R functions, debugging, profiling R code, and organizing and commenting R code. Topics in statistical data analysis will provide working examples.",57,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,30.0,11.0,30.0,1,604890
317,/learn/competitive-data-science,How to Win a Data Science Competition: Learn from Top Kagglers,HSE University,4.7,141931,1078,261,"If you want to break into competitive data science, then this course is for you! Participating in predictive modelling competitions can help you gain practical experience, improve and harness your data modelling skills in various domains such as credit, insurance, marketing, natural language processing, sales’ forecasting and computer vision to name a few. At the same time you get to do it in a competitive context against thousands of participants where each one tries to build the most predictive algorithm. Pushing each other to the limit can result in better performance and smaller prediction errors. Being able to achieve high ranks consistently can help you accelerate your career in data science.In this course, you will learn to analyse and solve competitively such predictive modelling tasks. 

When you finish this class, you will:

- Understand how to solve predictive modelling competitions efficiently and learn which of the skills obtained can be applicable to real-world tasks.
- Learn how to preprocess the data and generate new features from various sources such as text and images.
- Be taught advanced feature engineering techniques like generating mean-encodings, using aggregated statistical measures or finding nearest neighbors as a means to improve your predictions.
- Be able to form reliable cross validation methodologies that help you benchmark your solutions and avoid overfitting or underfitting when tested with unobserved (test) data. 
- Gain experience of analysing and interpreting the data. You will become aware of inconsistencies, high noise levels, errors and other data-related issues such as leakages and you will learn how to overcome them. 
- Acquire knowledge of different algorithms and learn how to efficiently tune their hyperparameters and achieve top performance. 
- Master the art of combining different machine learning models and learn how to ensemble. 
- Get exposed to past (winning) solutions and codes and learn how to read them.

Disclaimer : This is not a machine learning course in the general sense. This course will teach you how to get high-rank solutions against thousands of competitors with focus on practical usage of machine learning methods rather than the theoretical underpinnings behind them.

Prerequisites: 
- Python: work with DataFrames in pandas, plot figures in matplotlib, import and train models from scikit-learn, XGBoost, LightGBM.
- Machine Learning: basic understanding of linear models, K-NN, random forest, gradient boosting and neural networks.

Do you have technical problems? Write to us: coursera@hse.ru",54,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,14.0,10.0,,1,98371
318,/learn/healthcare-data-models,Healthcare Data Models,"University of California, Davis",4.4,6097,33,10,"Career prospects are bright for those qualified to work in healthcare data analytics. Perhaps you work in data analytics, but are considering a move into healthcare where your work can improve people’s quality of life. If so, this course gives you a glimpse into why this work matters, what you’d be doing in this role, and what takes place on the Path to Value where data is gathered from patients at the point of care, moves into data warehouses to be prepared for analysis, then moves along the data pipeline to be transformed into valuable insights that can save lives, reduce costs, to improve healthcare and make it more accessible and affordable. Perhaps you work in healthcare but are considering a transition into a new role. If so, this course will help you see if this career path is one you want to pursue. You’ll get an overview of common data models and their uses. You’ll learn how various systems integrate data, how to ensure clear communication, measure and improve data quality. Data analytics in healthcare serves doctors, clinicians, patients, care providers, and those who carry out the business of improving health outcomes. This course of study will give you a clear picture of data analysis in today’s fast-changing healthcare field and the opportunities it holds for you.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,3563
319,/learn/scientific-approach-innovation-management,A Scientific Approach to Innovation Management,Università Bocconi,4.6,7741,49,16,"How can innovators understand if their idea is worth developing and pursuing? In this course, we lay out a systematic process to make strategic decisions about innovative product or services that will help entrepreneurs, managers and innovators to avoid common pitfalls. We teach students to assess the feasibility of an innovative idea through problem-framing techniques and rigorous data analysis labelled ‘a scientific approach’. The course is highly interactive and includes exercises and real-world applications. We will also show the implications of a scientific approach to innovation management through a wide range of examples and case studies.",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,4884
320,/learn/code-free-data-science,Code Free Data Science,University of California San Diego,4.4,12101,72,26,"The Code Free Data Science class is designed for learners seeking to gain or expand their knowledge in the area of Data Science.  Participants will receive the basic training in effective predictive analytic approaches accompanying the growing discipline of Data Science without any programming requirements.  Machine Learning methods will be presented by utilizing the KNIME Analytics Platform to discover patterns and relationships in data. Predicting future trends and behaviors allows for proactive, data-driven decisions.  During the class learners will acquire new skills to apply predictive algorithms to real data, evaluate, validate and interpret the results without any pre requisites for any kind of programming.  Participants will gain the essential skills to design, build, verify and test predictive models.  You Will Learn
•	How to design Data Science workflows without any programming involved
•	Essential Data Science skills to design, build, test and evaluate predictive models
•	Data Manipulation, preparation and Classification and clustering methods
•	Ways to apply Data Science algorithms to real data and evaluate and interpret the results",14,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,50.0,,,1,8654
321,/learn/population-health-predictive-analytics,Population Health: Predictive Analytics,Universiteit Leiden,5.0,5404,10,8,"Predictive analytics has a longstanding tradition in medicine. Developing better prediction models is a critical step in the pursuit of improved health care: we need these tools to guide our decision-making on preventive measures, and individualized treatments. In order to effectively use and develop these models, we must understand them better. In this course, you will learn how to make accurate prediction tools, and how to assess their validity. First, we will discuss the role of predictive analytics for prevention, diagnosis, and effectiveness. Then, we look at key concepts such as study design, sample size and overfitting.Furthermore, we comprehensively discuss important modelling issues such as missing values, non-linear relations and model selection. The importance of the bias-variance tradeoff and its role in prediction is also addressed. Finally, we look at various way to evaluate a model - through performance measures, and by assessing both internal and external validity. We also discuss how to update a model to a specific setting.

Throughout the course, we illustrate the concepts introduced in the lectures using R. You need not install R on your computer to follow the course: you will be able to access R and all the example datasets within the Coursera environment. We do however make references to further packages that you can use for certain type of analyses – feel free to install and use them on your computer.

Furthermore, each module can also contain practice quiz questions. In these, you will pass regardless of whether you provided a right or wrong answer. You will learn the most by first thinking about the answers themselves and then checking your answers with the correct answers and explanations provided.

This course is part of a Master's program Population Health Management at Leiden University (currently in development).",18,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,,,,0,1877
322,/learn/spatial-data-science,Spatial Data Science and Applications,Yonsei University,4.4,19782,384,128,"Spatial (map) is considered as a core infrastructure of modern IT world, which is substantiated by business transactions of major IT companies such as Apple, Google, Microsoft, Amazon, Intel, and Uber, and even motor companies such as Audi, BMW, and Mercedes. Consequently, they are bound to hire more and more spatial data scientists.  Based on such business trend, this course is designed to present a firm understanding of spatial data science to the learners, who would have a basic knowledge of data science and data analysis, and eventually to make their expertise differentiated from other nominal data scientists and data analysts.  Additionally, this course could make learners realize the value of spatial big data and the power of open source software's to deal with spatial data science problems.This course will start with defining spatial data science and answering why spatial is special from three different perspectives - business, technology, and data in the first week.  In the second week, four disciplines related to spatial data science - GIS, DBMS, Data Analytics, and Big Data Systems, and the related open source software's - QGIS, PostgreSQL, PostGIS, R, and Hadoop tools are introduced together.  During the third, fourth, and fifth weeks, you will learn the four disciplines one by one from the principle to applications.  In the final week, five real world problems and the corresponding solutions are presented with step-by-step procedures in environment of open source software's.",12,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,26.0,21.0,20.0,1,16382
323,/learn/big-data-language-1,Big data and Language 1,Korea Advanced Institute of Science and Technology(KAIST),4.5,9090,75,17,"In this course, students will understand characteristics of language through big data. Students will learn how to collect and analyze big data, and find linguistic features from the data. A number of approaches to the linguistic analysis of written and spoken texts will be discussed.The class will consist of lecture videos which are approximately 1 hour and a quiz for each week. There will be a final project which requires students to conduct research on text data and language.",4,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,,,,0,3985
324,/learn/python-social-network-analysis,Applied Social Network Analysis in Python,University of Michigan,4.7,71586,2402,403,"This course will introduce the learner to network analysis through tutorials using the NetworkX library. The course begins with an understanding of what network analysis is and motivations for why we might model phenomena as networks. The second week introduces the concept of connectivity and network robustness. The third week will explore ways of measuring the importance or centrality of a node in a network. The final week will explore the evolution of networks over time and cover models of network generation and the link prediction problem. This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.",29,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,37.0,23.0,34.0,1,76996
325,/learn/gcp-big-data-ml-fundamentals-es,Google Cloud Platform Big Data and Machine Learning Fundamentals en Español,Google Cloud,4.7,7503,595,190,"En este curso a pedido y acelerado de 1 semana, los participantes descubrirán las capacidades de los macrodatos y del aprendizaje automático de Google Cloud Platform (GCP). Además, se proporciona una descripción general rápida de Google Cloud Platform y más detalles sobre las capacidades de procesamiento de datos.Al finalizar este curso, los participantes podrán hacer lo siguiente:
• Identificar el propósito y el valor de los productos clave de macrodatos y aprendizaje automático disponibles en Google Cloud Platform
• Usar Cloud SQL y Cloud Dataproc para migrar las cargas de trabajo existentes de MySQL y Hadoop/Pig/Spark/Hive a Google Cloud Platform
• Usar BigQuery y Cloud Datalab para llevar a cabo un análisis de datos interactivo
• Elegir entre Cloud SQL, Bigtable y Datastore
• Entrenar y usar una red neuronal mediante TensorFlow
• Elegir entre los diferentes productos de procesamiento de datos disponibles en Google Cloud Platform

Antes de inscribirse en este curso, los participantes deben tener aproximadamente un (1) año de experiencia en uno o más de los siguientes:
• Un lenguaje de consulta común, como SQL
• Actividades de extracción, transformación y carga
• Modelado de datos
• Aprendizaje automático o estadísticas
• Programación en Python

Notas de la Cuenta de Google:
• Actualmente, los servicios de Google no están disponibles en China.",13,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,45.0,12.0,20.0,0,17092
326,/learn/introduction-experimental-design-basics,Experimental Design Basics,Arizona State University,4.7,32452,118,30,"This is a basic course in designing experiments and analyzing the resulting data. The course objective is to learn how to plan, design and conduct experiments efficiently and effectively, and analyze the resulting data to obtain objective conclusions. Both design and statistical analysis issues are discussed. Opportunities to use the principles taught in the course arise in all aspects of today’s industrial and business environment. Applications from various fields will be illustrated throughout the course.  Computer software packages (JMP, Design-Expert, Minitab) will be used to implement the methods presented and will be illustrated extensively. All experiments are designed experiments; some of them are poorly designed, and others are well-designed. Well-designed experiments allow you to obtain reliable, valid results faster, easier, and with fewer resources than with poorly-designed experiments. You will learn how to plan, conduct and analyze experiments efficiently in this course.",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,1,7351
327,/learn/data-products,Developing Data Products,Johns Hopkins University,4.6,42224,2186,405,"A data product is the production output from a statistical analysis. Data products automate complex analysis tasks or use technology to expand the utility of a data informed model, algorithm or inference. This course covers the basics of creating data products using Shiny, R packages, and interactive graphics. The course will focus on the statistical fundamentals of creating a data product that can be used to tell a story about data to a mass audience.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,34.0,14.0,30.0,1,76157
328,/learn/deep-neural-networks-with-pytorch,Deep Neural Networks with PyTorch,IBM,4.4,128990,851,192,"The course will teach you how to develop deep learning models using  Pytorch. The course will start with Pytorch's  tensors and Automatic differentiation package. Then each section will cover different models starting off with fundamentals such as Linear Regression, and logistic/softmax regression. Followed by  Feedforward deep neural networks, the role of different activation functions, normalization and dropout layers. Then Convolutional Neural Networks and Transfer learning will be covered. Finally, several other Deep learning methods will be covered.Learning Outcomes:
After completing this course, learners will be able to:
•	explain and apply their knowledge of Deep Neural Networks and related machine learning methods
•	know how to use Python libraries such as PyTorch  for Deep Learning applications 
•	build Deep Neural Networks using PyTorch",31,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,22589
329,/learn/advanced-r,Advanced R Programming,Johns Hopkins University,4.3,24219,530,131,"This course covers advanced topics in R programming that are necessary for developing powerful, robust, and reusable data science tools. Topics covered include functional programming in R, robust error handling, object oriented programming, profiling and benchmarking, debugging, and proper design of functions. Upon completing this course you will be able to identify and abstract common data analysis tasks and to encapsulate them in user-facing functions. Because every data science environment encounters unique data challenges, there is always a need to develop custom software specific to your organization’s mission. You will also be able to define new data types in R and to develop a universe of functionality specific to those data types to enable cleaner execution of data science tasks and stronger reusability within a team.",18,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,12.0,,22.0,1,26963
330,/learn/machine-learning-applications-big-data,Big Data Applications: Machine Learning at Scale,Yandex,3.8,6791,86,22,"Machine learning is transforming the world around us. To become successful, you’d better know what kinds of problems can be solved with machine learning, and how they can be solved. Don’t know where to start? The answer is one button away.During this course you will:
- Identify practical problems which can be solved with machine learning
- Build, tune and apply linear models with Spark MLLib
- Understand methods of text processing
- Fit decision trees and boost them with ensemble learning
- Construct your own recommender system.
 
As a practical assignment, you will 
- build and apply linear models for classification and regression tasks; 
- learn how to work with texts; 
- automatically construct decision trees and improve their performance with ensemble learning; 
- finally, you will build your own recommender system!

With these skills, you will be able to tackle many practical machine learning tasks.
 
We provide the tools, you choose the place of application to make this world of machines more intelligent.

Special thanks to:
- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.
- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching  MapReduce, Hadoop and friends since 2008. Now he is leading the infrastructure team.
- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.
- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.",28,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,0,10426
331,/learn/data-analytics-for-lean-six-sigma,Data Analytics for Lean Six Sigma,University of Amsterdam,4.8,57417,2215,758,"Welcome to this course on Data Analytics for Lean Six Sigma. In this course you will learn data analytics techniques that are typically useful within Lean Six Sigma improvement projects. At the end of this course you are able to analyse and interpret data gathered within such a project. You will be able to use Minitab to analyse the data. I will also briefly explain what Lean Six Sigma is.

I will emphasize on use of data analytics tools and the interpretation of the outcome. I will use many different examples from actual Lean Six Sigma projects to illustrate all tools. I will not discuss any mathematical background. 

The setting we chose for our data example is a Lean Six Sigma improvement project. However data analytics tools are very widely applicable. So you will find that you will learn techniques that you can use in a broader setting apart from improvement projects. 

I hope that you enjoy this course and good luck!
Dr. Inez Zwetsloot & the IBIS UvA team",11,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,27.0,11.0,30.0,1,39579
332,/learn/big-data-introduction,Introduction to Big Data,University of California San Diego,4.6,258963,9562,2257,"Interested in increasing your knowledge of the Big Data landscape?  This course is for those new to data science and interested in understanding why the Big Data Era has come to be.  It is for those who want to become conversant with the terminology and the core concepts behind big data problems, applications, and systems.  It is for those who want to start thinking about how Big Data might be useful in their business or career.  It provides an introduction to one of the most common frameworks, Hadoop, that has made big data analysis easier and more accessible -- increasing the potential for data to transform our world!At the end of this course, you will be able to:

* Describe the Big Data landscape including examples of real world big data problems including the three key sources of Big Data: people, organizations, and sensors. 

* Explain the V’s of Big Data (volume, velocity, variety, veracity, valence, and value) and why each impacts data collection, monitoring, storage, analysis and reporting.

* Get value out of Big Data by using a 5-step process to structure your analysis. 

* Identify what are and what are not big data problems and be able to recast big data problems as data science questions.

* Provide an explanation of the architectural components and programming models used for scalable big data analysis.

* Summarize the features and value of core Hadoop stack components including the YARN resource and job management system, the HDFS file system and the MapReduce programming model.

* Install and run a program using Hadoop!

This course is for those new to data science.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  

Hardware Requirements:
(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size.  

Software Requirements:
This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge. Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,36.0,12.0,40.0,1,250777
333,/learn/visualization-for-data-journalism,Visualization for Data Journalism,University of Illinois at Urbana-Champaign,4.5,7074,41,19,"While telling stories with data has been part of the news practice since its earliest days, it is in the midst of a renaissance. Graphics desks which used to be deemed as “the art department,” a subfield outside the work of newsrooms, are becoming a core part of newsrooms’ operation. Those people (they often have various titles: data journalists, news artists, graphic reporters, developers, etc.) who design news graphics are expected to be full-fledged journalists and work closely with reporters and editors. The purpose of this class is to learn how to think about the visual presentation of data, how and why it works, and how to doit the right way. We will learn how to make graphs like The New York Times, Vox, Pew, and FiveThirtyEight. In the end, you can share–embed your beautiful charts in publications, blog posts, and websites.This course assumes you understand basic coding skills, preferably Python. However, we also provide a brief review on Python in Module 1, in case you want to refresh yourself on the basics and perform simple data analysis.",18,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,,,,1,4886
334,/learn/machine-learning-under-the-hood,"Machine Learning Under the Hood: The Technical Tips, Tricks, and Pitfalls",SAS,4.8,10352,44,19,"Machine learning. Your team needs it, your boss demands it, and your career loves it. After all, LinkedIn places it as one of the top few ""Skills Companies Need Most"" and as the very top emerging job in the U.S.If you want to participate in the deployment of machine learning (aka predictive analytics), you've got to learn how it works. Even if you work as a business leader rather than a hands-on practitioner – even if you won't crunch the numbers yourself – you need to grasp the underlying mechanics in order to help navigate the overall project. Whether you're an executive, decision maker, or operational manager overseeing how predictive models integrate to drive decisions, the more you know, the better.

And yet, looking under the hood will delight you. The science behind machine learning intrigues and surprises, and an intuitive understanding is not hard to come by. With its impact on the world growing so quickly, it's time to demystify the predictive power of data – and how to scientifically tap it.

This course will show you how machine learning works. It covers the foundational underpinnings, the way insights are gleaned from data, how we can trust these insights are reliable, and how well predictive models perform – which can be established with pretty straightforward arithmetic. These are things every business professional needs to know, in addition to the quants.

And this course continues beyond machine learning standards to also cover cutting-edge, advanced methods, as well as preparing you to circumvent prevalent pitfalls that seldom receive the attention they deserve. The course dives deeply into these topics, and yet remains accessible to non-technical learners and newcomers.

With this course, you'll learn what works and what doesn't – the good, the bad, and the fuzzy: 

– How predictive modeling algorithms work, including decision trees, logistic regression, and neural networks

– Treacherous pitfalls such as overfitting, p-hacking, and presuming causation from correlations

– How to interpret a predictive model in detail and explain how it works

– Advanced methods such as ensembles and uplift modeling (aka persuasion modeling)

– How to pick a tool, selecting from the many machine learning software options

– How to evaluate a predictive model, reporting on its performance in business terms

– How to screen a predictive model for potential bias against protected classes – aka AI ethics

IN-DEPTH YET ACCESSIBLE. Brought to you by industry leader Eric Siegel – a winner of teaching awards when he was a professor at Columbia University – this curriculum stands out as one of the most thorough, engaging, and surprisingly accessible on the subject of machine learning.

NO HANDS-ON AND NO HEAVY MATH. Rather than a hands-on training, this course serves both business leaders and burgeoning data scientists alike with expansive coverage of the state-of-the-art techniques and the most pernicious pitfalls. There are no exercises involving coding or the use of machine learning software. However, for one of the assessments, you'll perform a hands-on exercise, creating a predictive model by hand in Excel or Google Sheets and visualizing how it improves before your eyes.

BUT TECHNICAL LEARNERS SHOULD TAKE ANOTHER LOOK. Before jumping straight into the hands-on, as quants are inclined to do, consider one thing: This curriculum provides complementary know-how that all great techies also need to master. It contextualizes the core technology with a strong conceptual framework and covers topics that are generally omitted from even the most technical of courses, including uplift modeling (aka persuasion modeling) and some particularly treacherous pitfalls.

VENDOR-NEUTRAL. This course includes illuminating software demos of machine learning in action using SAS products. However, the curriculum is vendor-neutral and universally-applicable. The contents and learning objectives apply, regardless of which machine learning software tools you end up choosing to work with.

PREREQUISITES. Before this course, learners should take the first two of this specialization's three courses, ""The Power of Machine Learning"" and ""Launching Machine Learning.""",17,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,,,,0,3029
335,/learn/wharton-operations-analytics,Operations Analytics,University of Pennsylvania,4.7,50599,4623,896,"This course is designed to impact the way you think about transforming data into better decisions. Recent extraordinary improvements in data-collecting technologies have changed the way firms make informed and effective business decisions. The course on operations analytics, taught by three of Wharton’s leading experts, focuses on how the data can be used to profitably match supply with demand in various business settings. In this course, you will learn how to model future demand uncertainties, how to predict the outcomes of competing policy choices and how to choose the best course of action in the face of risk. The course will introduce frameworks and ideas that provide insights into a spectrum of real-world business challenges, will teach you methods and software available for tackling these challenges quantitatively as well as the issues involved in gathering the relevant data.This course is appropriate for beginners and business professionals with no prior analytics experience.",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,39.0,17.0,33.0,1,91248
336,/learn/data-insights-gcp-apply-ml,Applying Machine Learning to your Data with GCP,Google Cloud,4.7,23685,705,76,"In this module, we define what Machine Learning is and how it can benefit your business. You'll see a few demos of ML in action and learn key ML terms like instances, features, and labels. In the interactive labs, you will practice invoking the pretrained ML APIs available as well as build your own Machine Learning models using just SQL with BigQuery ML.PREREQUISITES
To get the most out of this course, participants must complete the prior courses in this specialization:
• Exploring and Preparing your Data
• Storing and Visualizing your Data
• Architecture and Performance

>>> By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",10,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,55.0,12.0,67.0,0,11691
337,/learn/praktiki-raboty-dannymi-sredstvami-power-query-pivot,Практики работы с данными средствами Power Query и Power Pivot,Saint Petersburg State University,4.8,10747,70,14,"Курс посвящен работе в надстройках Power Query и Power Pivot системы MS Excel. Данный курс является третьим в серии курсов ""Практики анализа экономических данных. От простого к сложному"". Надстройка Power Query предназначена для того, чтобы собирать данные из разных источников и создавать шаблоны для их обработки, позволяющие не проводить многократно одни и те же манипуляции с данными. Надстройка Power Pivot позволяет создавать модели данных и отчеты сложной структуры на их основе. В данном курсе слушатель сможет применить надстройки Microsoft Power Query и Power Pivot для сборки данных из разных источников для анализа деятельности компании.По завершении курса слушатели будут:

Знать:
- инструменты работы с данными надстроек Power Query и Power Pivot системы MS Excel;
- правила, возможности и особенности соединения данных из разных таблиц в одну с помощью надстройки Power Query;
- правила и особенности создания модели данных с помощью надстройки Power Pivot;
- возможности и ограничения DAX-формул.

Уметь:
- загружать в MS Excel данные из таблиц, внешних файлов и папок, собирая их в единый отчет;
- преобразовывать данные разной структуры в вид, удобный для составления аналитических отчетов;
- создавать модель данных с помощью надстройки Power Pivot;
- создавать отчеты на основе данных из нескольких источников.

Владеть:
- навыками работы с надстройками Power Query и Power Pivot системы MS Excel;
- навыками создания отчетов с использованием возможностей Power Query и Power Pivot;
- навыками создания мер с помощью DAX-формул.",12,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,,,,1,4093
338,/learn/inferential-statistics-intro,Inferential Statistics,Duke University,4.8,170962,2075,384,"This course covers commonly used statistical inference methods for numerical and categorical data. You will learn how to set up and perform hypothesis tests, interpret p-values, and report the results of your analysis in a way that is interpretable for clients or the public. Using numerous data examples, you will learn to report estimates of quantities in a way that expresses the uncertainty of the quantity of interest. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The course introduces practical tools for performing data analysis and explores the fundamental concepts necessary to interpret and report results for both categorical and numerical data",17,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,16.0,,22.0,1,88123
339,/learn/mathematics-and-python,Математика и Python для анализа данных,Moscow Institute of Physics and Technology,4.8,216397,5445,921,"Анализ данных и машинное обучение существенно опираются на результаты из математического анализа, линейной алгебры, методов оптимизации, теории вероятностей. Без фундаментальных знаний по этим наукам невозможно понимать, как устроены методы анализа данных. Задача этого курса — сформировать такой фундамент. Мы обойдёмся без сложных формул и доказательств и сделаем упор на интерпретации и понимании смысла математических понятий и объектов. Для успешного применения методов анализа данных нужно уметь программировать. Фактическим стандартом для этого в наши дни является язык Python. В данном курсе мы предлагаем познакомиться с его синтаксисом, а также научиться работать с его основными библиотеками, полезными для анализа данных, например, NumPy, SciPy, Matplotlib и Pandas.

Видео курса разработаны на Python 2. Задания и ноутбуки к ним адаптированы к Python 3.",28,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,39.0,24.0,33.0,0,83101
340,/learn/datasciencemathskills,Data Science Math Skills,Duke University,4.5,256075,9041,2045,"Data science courses contain math—no avoiding that! This course is designed to teach learners the basic math you will need in order to be successful in almost any data science math course and was created for learners who have basic math skills but may not have taken algebra or pre-calculus. Data Science Math Skills introduces the core math that data science is built upon, with no extra complexity, introducing unfamiliar ideas and math symbols one-at-a-time. Learners who complete this course will master the vocabulary, notation, concepts, and algebra rules that all data scientists must know before moving on to more advanced material.

Topics include:
~Set theory, including Venn diagrams
~Properties of the real number line
~Interval notation and algebra with inequalities
~Uses for summation and Sigma notation
~Math on the Cartesian (x,y) plane, slope and distance formulas
~Graphing and describing functions and their inverses on the x-y plane,
~The concept of instantaneous rate of change and tangent lines to a curve
~Exponents, logarithms, and the natural log function.
~Probability theory, including Bayes’ theorem.

While this course is intended as a general introduction to the math skills needed for data science, it can be considered a prerequisite for learners interested in the course, ""Mastering Data Analysis in Excel,"" which is part of the Excel to MySQL Data Science Specialization.  Learners who master Data Science Math Skills will be fully prepared for success with the more advanced math concepts introduced in ""Mastering Data Analysis in Excel."" 

Good luck and we hope you enjoy the course!",13,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,25.0,10.0,25.0,1,250995
341,/learn/machine-learning-duke,Introduction to Machine Learning,Duke University,4.6,131253,1053,249,"This course will provide you a foundational understanding of machine learning models (logistic regression, multilayer perceptrons, convolutional neural networks, natural language processing, etc.) as well as demonstrate how these models can solve complex problems in a variety of industries, from medical diagnostics to image recognition to text prediction. In addition, we have designed practice exercises that will give you hands-on experience implementing these data science models on data sets. These practice exercises will teach you how to implement machine learning algorithms with PyTorch, open source libraries used by leading tech companies in the machine learning field (e.g., Google, NVIDIA, CocaCola, eBay, Snapchat, Uber and many more).",25,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,54226
342,/learn/data-wrangling-analysis-abtesting,"Data Wrangling, Analysis and AB Testing with SQL","University of California, Davis",3.5,72406,329,127,"This course allows you to apply the SQL skills taught in “SQL for Data Science” to four increasingly complex and authentic data science inquiry case studies. We'll learn how to convert timestamps of all types to common formats and perform date/time calculations. We'll select and perform the optimal JOIN for a data science inquiry and clean data within an analysis dataset by deduping, running quality checks, backfilling, and handling nulls. We'll learn how to segment and analyze data per segment using windowing functions and use case statements to execute conditional logic to address a data science inquiry. We'll also describe how to convert a query into a scheduled job and how to insert data into a date partition. Finally, given a predictive analysis need, we'll engineer a feature from raw data using the tools and skills we've built over the course. The real-world application of these skills will give you the framework for performing the analysis of an AB test.",16,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,11.0,12.0,,1,23412
343,/learn/data-visualization-tableau,Fundamentals of Visualization with Tableau,"University of California, Davis",4.5,203898,4820,1091,"In this first course of this specialization, you will discover what data visualization is, and how we can use it to better see and understand data. Using Tableau, we’ll examine the fundamental concepts of data visualization and explore the Tableau interface, identifying and applying the various tools Tableau has to offer. By the end of the course you will be able to prepare and import data into Tableau and explain the relationship between data analytics and data visualization. This course is designed for the learner who has never used Tableau before, or who may need a refresher or want to explore Tableau in more depth. No prior technical or analytical background is required. The course will guide you through the steps necessary to create your first visualization from the beginning based on data context, setting the stage for you to advance to the next course in the Specialization.",11,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,27.0,11.0,33.0,1,116900
344,/learn/predictive-modeling-machine-learning,Predictive Modeling and Machine Learning with MATLAB,MathWorks,4.8,22708,67,20,"In this course, you will build on the skills learned in Exploratory Data Analysis with MATLAB and Data Processing and Feature Engineering with MATLAB to increase your ability to harness the power of MATLAB to analyze data relevant to the work you do.These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background. To be successful in this course, you should have some background in basic statistics (histograms, averages, standard deviation, curve fitting, interpolation) and have completed courses 1 through 2 of this specialization. 

By the end of this course, you will use MATLAB to identify the best machine learning model for obtaining answers from your data. You will prepare your data, train a predictive model, evaluate and improve your model, and understand how to get the most out of your models.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,9208
345,/learn/introduction-to-deep-learning-with-keras,Introduction to Deep Learning & Neural Networks with Keras,IBM,4.7,29389,840,166,"Looking to start a career in Deep Learning? Look no further. This course will introduce you to the field of deep learning and help you answer many questions that people are asking nowadays, like what is deep learning, and how do deep learning models compare to artificial neural networks? You will learn about the different deep learning models and build your first deep learning model using the Keras library.After completing this course, learners will be able to:
•	describe what a neural network is, what a deep learning model is, and the difference between them.
•	demonstrate an understanding of unsupervised deep learning models such as autoencoders and restricted Boltzmann machines.
•	demonstrate an understanding of supervised deep learning models such as convolutional neural networks and recurrent networks.
•	build deep learning models and networks using the Keras library.",8,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,,,,0,16667
346,/learn/mixture-models,Bayesian Statistics: Mixture Models,"University of California, Santa Cruz",4.7,18351,19,6,"Bayesian Statistics: Mixture Models introduces you to an important class of statistical models. The course is organized in five modules, each of which contains lecture videos, short quizzes, background reading, discussion prompts, and one or more peer-reviewed assignments. Statistics is best learned by doing it, not just watching a video, so the course is structured to help you learn through application. Some exercises require the use of R, a freely-available statistical software package. A brief tutorial is provided, but we encourage you to take advantage of the many other resources online for learning R if you are interested.

This is an advanced course, and it was designed to be the third in UC Santa Cruz's series on Bayesian statistics, after Herbie Lee's ""Bayesian Statistics: From Concept to Data Analysis"" and Matthew Heiner's ""Bayesian Statistics: Techniques and Models."" To succeed in the course, you should have some knowledge of and comfort with calculus-based probability, principles of maximum-likelihood estimation, and Bayesian estimation.",22,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,,,,1,4153
347,/learn/healthcare-data,Using clinical health data for better healthcare,The University of Sydney,4.6,7438,65,17,"Digital health is rapidly being realised as the future of healthcare. While this is placing emphasis on the input of quality health data in digital records and systems, the delivery of safe and quality healthcare relies not only on the input of data, but also the ability to access and derive meaning from data to generate evidence, inform decision making and drive better health outcomes.This course provides insight into the use of healthcare data, including an overview of best practices and the practical realities of obtaining useful information from digital health systems via the understanding of the fundamental concepts of health data analytics.  

Learners will understand why data quality is essential in modern healthcare, as they are guided through various stages of the data life cycle, starting with the generation of quality health data, through to discovering patterns and extracting knowledge from health data using common methodologies and tools in the basic analysis, visualisation and communication of health data. In doing so, learners explore current healthcare delivery contexts, and future and emerging digital health data systems and applications that are rapidly becoming tomorrow’s reality.

On completion of this course, you will be able to:
1.	Identify digital health technologies, health data sources, and the evolving roles of health workforce in digital health environments
2.	Understand key health data concepts and terminology, including the significance of data integrity and stakeholder roles in the data life cycle
3.	Use health data and basic data analysis to inform and improve decision making and practice.
4.	Apply effective methods of communication of health data to facilitate safe and quality care.

During this course, you will interact with learning content contributed by:
•	Digital Health Cooperative Research Centre
•	Australian Digital Health Agency
•	eHealth NSW
•	Sydney Local Health District
•	The NSW Ministry of Health
•	Health Education and Training Institute
•	Clinical Excellence Commission 
•	Chris O’Brien Lifehouse
•	Monash Partners / Australian Health Research Alliance
•	Australian Research Data Commons
•	Justice Health & Forensic Mental Health Network
•	South Eastern Sydney Local Health District
•	Western Sydney Local Health District
•	Westmead Breast Cancer Institute
•	Agency for Clinical Innovation
•	Western NSW Local Health District
•	Sydney Children’s Hospital Network

This course is a collaborative venture between NSW Health, the University of Sydney and the Digital Health Cooperative Research Centre, including dedicated resources from eHealth NSW, Health Education and Training Institute, and the Research in Implementation Science & eHealth group. While many learning resources and case examples are drawn from the NSW Health service context, this course has relevance for all existing and future health workforce, regardless of role or work context.
Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.",15,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,20.0,25.0,,1,5144
