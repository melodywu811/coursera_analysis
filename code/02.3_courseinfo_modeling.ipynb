{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acquired-restoration",
   "metadata": {},
   "source": [
    "## 2.3 Course Information Modeling: predicting enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-farmer",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hindu-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_colwidth = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinct-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import preprocessing and metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "coastal-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-pathology",
   "metadata": {},
   "source": [
    "### Import Data and quick cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "active-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/ds_course_modeling.csv'\n",
    "course = pd.read_csv(path)\n",
    "\n",
    "# quick pre-processing, dropping columns and remove rows with null values\n",
    "course.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parental-utility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "course.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entertaining-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_href                 0\n",
       "course_name                 0\n",
       "partner_title               0\n",
       "stars                       0\n",
       "recent_views                0\n",
       "num_ratings                 0\n",
       "num_reviews                 0\n",
       "description                 0\n",
       "length                      0\n",
       "100%_online                 0\n",
       "shareable_certificate       0\n",
       "flexible_deadlines          0\n",
       "english                     0\n",
       "intermediate_level          0\n",
       "beginner_level              0\n",
       "spanish                     0\n",
       "chinese_(traditional)       0\n",
       "arabic                      0\n",
       "portuguese_(brazilian)      0\n",
       "russian                     0\n",
       "advanced_level              0\n",
       "chinese_(simplified)        0\n",
       "french                      0\n",
       "japanese                    0\n",
       "specialization              0\n",
       "outcome_career_benefit    153\n",
       "outcome_pay_increase      225\n",
       "outcome_new_career        180\n",
       "he_partner                  0\n",
       "enrollment                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "course.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "formed-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all null values with 'median'\n",
    "course.fillna('median', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "celtic-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_href</th>\n",
       "      <th>course_name</th>\n",
       "      <th>partner_title</th>\n",
       "      <th>stars</th>\n",
       "      <th>recent_views</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>description</th>\n",
       "      <th>length</th>\n",
       "      <th>100%_online</th>\n",
       "      <th>...</th>\n",
       "      <th>advanced_level</th>\n",
       "      <th>chinese_(simplified)</th>\n",
       "      <th>french</th>\n",
       "      <th>japanese</th>\n",
       "      <th>specialization</th>\n",
       "      <th>outcome_career_benefit</th>\n",
       "      <th>outcome_pay_increase</th>\n",
       "      <th>outcome_new_career</th>\n",
       "      <th>he_partner</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/learn/exploratory-data-analysis</td>\n",
       "      <td>Exploratory Data Analysis</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>4.7</td>\n",
       "      <td>108049</td>\n",
       "      <td>5836</td>\n",
       "      <td>845</td>\n",
       "      <td>This course covers the essential exploratory techniques for summarizing data. These techniques are typically applied before formal modeling commences and can help inform the development of more complex statistical models. Exploratory techniques are also important for eliminating or sharpening potential hypotheses about the world that can be add...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course_href                course_name  \\\n",
       "0  /learn/exploratory-data-analysis  Exploratory Data Analysis   \n",
       "\n",
       "              partner_title  stars  recent_views  num_ratings  num_reviews  \\\n",
       "0  Johns Hopkins University    4.7        108049         5836          845   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                     description  \\\n",
       "0  This course covers the essential exploratory techniques for summarizing data. These techniques are typically applied before formal modeling commences and can help inform the development of more complex statistical models. Exploratory techniques are also important for eliminating or sharpening potential hypotheses about the world that can be add...   \n",
       "\n",
       "   length  100%_online  ...  advanced_level  chinese_(simplified)  french  \\\n",
       "0      55            1  ...               0                     0       0   \n",
       "\n",
       "   japanese  specialization  outcome_career_benefit  outcome_pay_increase  \\\n",
       "0         0               0                    38.0                  15.0   \n",
       "\n",
       "   outcome_new_career  he_partner  enrollment  \n",
       "0                38.0           1      157581  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-contact",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-shannon",
   "metadata": {},
   "source": [
    "### Baseline Model: mean enrollment (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vocational-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = course['enrollment']\n",
    "# null prediction\n",
    "null_predictions = pd.Series(data=y.mean(), index=y.index)\n",
    "# null residuals\n",
    "null_residuals = y - null_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "raised-federal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235563.11860296366"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null RMSE\n",
    "metrics.mean_squared_error(y, null_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-hepatitis",
   "metadata": {},
   "source": [
    "### 1. Modeling: Using all numeric features to predict enrollment.\n",
    "#### Set up X, y, train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mobile-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all numeric features\n",
    "numeric_features = course._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "saving-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = course[numeric_features].drop(columns=['enrollment'])\n",
    "y = course['enrollment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "certain-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-signal",
   "metadata": {},
   "source": [
    "#### Setting up the models in a pipeline and evaluating performance using R2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "northern-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a list to contain pipelines\n",
    "pipelines = []\n",
    "\n",
    "# Set up tuples for all the models we want to test\n",
    "models = [('lr', LinearRegression()),\n",
    "         ('knn', KNeighborsRegressor()),\n",
    "         ('dtr', DecisionTreeRegressor()),\n",
    "         ('rfr', RandomForestRegressor()),\n",
    "         ('ada', AdaBoostRegressor()),\n",
    "         ('svr', SVR()),\n",
    "         ('xgb', XGBRegressor())]\n",
    "\n",
    "# Set up pipelines for all the models alone and with StandardScaler\n",
    "for model in models:\n",
    "    pipelines.append(Pipeline([('ss', StandardScaler()),\n",
    "                              model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adjustable-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a list of pipelines and return their R2 and RMSE scores \n",
    "def pipe_evaluations(pipelines):\n",
    "    evaluations = []\n",
    "\n",
    "# Loop through and fit all the pipelines\n",
    "    for pipe in pipelines:\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        evaluations.append({\n",
    "            'Pipeline': [step[0] for step in pipe.steps],\n",
    "            'R2 (train)': pipe.score(X_train, y_train),\n",
    "            'R2 (test)': pipe.score(X_test, y_test),\n",
    "            'RMSE (train)': metrics.mean_squared_error(y_true =y_train, y_pred = pipe.predict(X_train),\n",
    "                                              squared = False),\n",
    "            'RMSE (test)': metrics.mean_squared_error(y_true =y_test, y_pred = pipe.predict(X_test),\n",
    "                                              squared = False)\n",
    "        })\n",
    "\n",
    "    # add evaluation metrics to a dataframe\n",
    "    evaluations_df = pd.DataFrame(evaluations)\n",
    "    return evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "flexible-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>R2 (train)</th>\n",
       "      <th>R2 (test)</th>\n",
       "      <th>RMSE (train)</th>\n",
       "      <th>RMSE (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ss, lr]</td>\n",
       "      <td>0.950881</td>\n",
       "      <td>0.580621</td>\n",
       "      <td>57866.614044</td>\n",
       "      <td>44385.917368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ss, knn]</td>\n",
       "      <td>0.559316</td>\n",
       "      <td>0.579777</td>\n",
       "      <td>173327.493808</td>\n",
       "      <td>44430.557450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ss, dtr]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28985.633775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ss, rfr]</td>\n",
       "      <td>0.872073</td>\n",
       "      <td>0.623064</td>\n",
       "      <td>93386.591764</td>\n",
       "      <td>42079.997481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ss, ada]</td>\n",
       "      <td>0.980803</td>\n",
       "      <td>0.766812</td>\n",
       "      <td>36175.727129</td>\n",
       "      <td>33097.477841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ss, svr]</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>-0.182886</td>\n",
       "      <td>266301.826967</td>\n",
       "      <td>74544.058599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ss, xgb]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862996</td>\n",
       "      <td>153.023514</td>\n",
       "      <td>25369.305579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pipeline  R2 (train)  R2 (test)   RMSE (train)   RMSE (test)\n",
       "0   [ss, lr]    0.950881   0.580621   57866.614044  44385.917368\n",
       "1  [ss, knn]    0.559316   0.579777  173327.493808  44430.557450\n",
       "2  [ss, dtr]    1.000000   0.821153       0.000000  28985.633775\n",
       "3  [ss, rfr]    0.872073   0.623064   93386.591764  42079.997481\n",
       "4  [ss, ada]    0.980803   0.766812   36175.727129  33097.477841\n",
       "5  [ss, svr]   -0.040256  -0.182886  266301.826967  74544.058599\n",
       "6  [ss, xgb]    1.000000   0.862996     153.023514  25369.305579"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation the pipelines\n",
    "pipe_evaluations(pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-vector",
   "metadata": {},
   "source": [
    "#### Shortlisting models based on performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-cisco",
   "metadata": {},
   "source": [
    "**Takeaways:** based on the test model performance (R2 scores and RMSE), the two models were selected for GridSearch.\n",
    "- **Decision Tree**\n",
    "- **XGBoost**\n",
    "\n",
    "\n",
    "**In addition,** for interpretability, I will also continue exploring the **Linear Regression** model and will apply polynominal features and regularization as next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-mystery",
   "metadata": {},
   "source": [
    "### 2. Excluding `100%_online`, `flexible_deadlines` and all the 'language labels from X\n",
    "#### Set up X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "black-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = course[numeric_features].drop(columns=['spanish','chinese_(traditional)', 'arabic', 'portuguese_(brazilian)', \n",
    "                                           'russian', 'advanced_level', 'chinese_(simplified)', 'french', \n",
    "                                           'japanese', '100%_online', 'flexible_deadlines', 'enrollment'])\n",
    "y = course['enrollment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "miniature-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-exhibit",
   "metadata": {},
   "source": [
    "#### Setting up the models in a pipeline and evaluating performance using R2 and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "hindu-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a list to contain pipelines\n",
    "pipelines = []\n",
    "\n",
    "# Set up tuples for all the models we want to test\n",
    "models = [('lr', LinearRegression()),\n",
    "         ('knn', KNeighborsRegressor()),\n",
    "         ('dtr', DecisionTreeRegressor()),\n",
    "         ('rfr', RandomForestRegressor()),\n",
    "         ('ada', AdaBoostRegressor()),\n",
    "         ('svr', SVR()),\n",
    "         ('xgb', XGBRegressor())]\n",
    "\n",
    "# Set up pipelines for all the models alone and with StandardScaler\n",
    "for model in models:\n",
    "    pipelines.append(Pipeline([('ss', StandardScaler()),\n",
    "                              model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "daily-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>R2 (train)</th>\n",
       "      <th>R2 (test)</th>\n",
       "      <th>RMSE (train)</th>\n",
       "      <th>RMSE (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ss, lr]</td>\n",
       "      <td>0.950881</td>\n",
       "      <td>0.580621</td>\n",
       "      <td>57866.614044</td>\n",
       "      <td>44385.917368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ss, knn]</td>\n",
       "      <td>0.559316</td>\n",
       "      <td>0.579777</td>\n",
       "      <td>173327.493808</td>\n",
       "      <td>44430.557450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ss, dtr]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27615.473721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ss, rfr]</td>\n",
       "      <td>0.920195</td>\n",
       "      <td>0.694450</td>\n",
       "      <td>73759.709359</td>\n",
       "      <td>37886.354880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ss, ada]</td>\n",
       "      <td>0.981504</td>\n",
       "      <td>0.702076</td>\n",
       "      <td>35509.711634</td>\n",
       "      <td>37410.585537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ss, svr]</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>-0.182886</td>\n",
       "      <td>266301.826967</td>\n",
       "      <td>74544.058599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ss, xgb]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862996</td>\n",
       "      <td>153.023514</td>\n",
       "      <td>25369.305579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pipeline  R2 (train)  R2 (test)   RMSE (train)   RMSE (test)\n",
       "0   [ss, lr]    0.950881   0.580621   57866.614044  44385.917368\n",
       "1  [ss, knn]    0.559316   0.579777  173327.493808  44430.557450\n",
       "2  [ss, dtr]    1.000000   0.837661       0.000000  27615.473721\n",
       "3  [ss, rfr]    0.920195   0.694450   73759.709359  37886.354880\n",
       "4  [ss, ada]    0.981504   0.702076   35509.711634  37410.585537\n",
       "5  [ss, svr]   -0.040256  -0.182886  266301.826967  74544.058599\n",
       "6  [ss, xgb]    1.000000   0.862996     153.023514  25369.305579"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation the pipelines\n",
    "pipe_evaluations(pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-entity",
   "metadata": {},
   "source": [
    "**Takeaways:** based on the test model performance (R2 scores and RMSE), the two models were selected for GridSearch.\n",
    "- **Decision Tree**\n",
    "- **XGBoost**\n",
    "\n",
    "\n",
    "For interpretability, I will also continue exploring the **Linear Regression** model and will apply polynominal features and regularization as next steps. **In addition,** Neural Networks are also explored as a benchmark to compare model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-stake",
   "metadata": {},
   "source": [
    "---\n",
    "## Tune shortlisted models, using the X excluding `100%_online`, `flexible_deadlines` and all the 'language labels  \n",
    "Shortlisted models:\n",
    "- **Decision Tree** (tuning using GridSearch)\n",
    "- **XGBoost** (tuning using GridSearch??)\n",
    "- **Linear Regression** (tuning using polynormial features and regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "announced-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "reflected-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = course[numeric_features].drop(columns=['spanish','chinese_(traditional)', 'arabic', 'portuguese_(brazilian)', \n",
    "                                           'russian', 'advanced_level', 'chinese_(simplified)', 'french', \n",
    "                                           'japanese', '100%_online', 'flexible_deadlines', 'enrollment'])\n",
    "y = course['enrollment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-harvey",
   "metadata": {},
   "source": [
    "### GridSearch - Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "secondary-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8198534222259319)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without tuning\n",
    "pipe = Pipeline([('ss', StandardScaler()),\n",
    "                  ('dtr', DecisionTreeRegressor())])\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "activated-merit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('ss', StandardScaler()),\n",
      "                ('dtr',\n",
      "                 DecisionTreeRegressor(min_samples_leaf=2,\n",
      "                                       min_samples_split=8))])\n",
      "\n",
      "0.7385200136660097 0.8383064760082237\n"
     ]
    }
   ],
   "source": [
    "# set up the pipe\n",
    "pipe = Pipeline([('ss', StandardScaler()),\n",
    "                  ('dtr', DecisionTreeRegressor())])\n",
    "\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [{'dtr__max_depth':[11,12,13,None],\n",
    "               'dtr__min_samples_split':[4,6,8],\n",
    "               'dtr__min_samples_leaf': [1,2,3],\n",
    "               'dtr__max_leaf_nodes': [10,11,12,None]}]\n",
    "\n",
    "# create a gridsearch of the pipeline, and fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5) \n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "\n",
    "# print metrics\n",
    "print(best_model.best_estimator_)\n",
    "print('')\n",
    "print(best_model.score(X_train, y_train), best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-gather",
   "metadata": {},
   "source": [
    "**Key takeways:** R-square score improves from **0.820 to 0.838** with GridSearching the Decision Tree Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-premiere",
   "metadata": {},
   "source": [
    "### GridSearch - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-jordan",
   "metadata": {},
   "source": [
    "**Performance without GridSearch:** Before tuning XGBoost model, take a look at the performance of the default setting. There is overfitting in the model and I will try to tune it by adding some bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "confirmed-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999996565146364, 0.8629958220673176)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without tuning\n",
    "pipe = Pipeline([('ss', StandardScaler()),\n",
    "                  ('xgb', XGBRegressor())])\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "protected-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('ss', StandardScaler()),\n",
      "                ('xgb',\n",
      "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
      "                              colsample_bylevel=1, colsample_bynode=1,\n",
      "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                              importance_type='gain',\n",
      "                              interaction_constraints='', learning_rate=0.2,\n",
      "                              max_delta_step=0, max_depth=4, min_child_weight=1,\n",
      "                              missing=nan, monotone_constraints='()',\n",
      "                              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                              scale_pos_weight=1, subsample=1,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n",
      "\n",
      "0.9998210419423381 0.884980902946525\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [{'xgb__max_depth':[4,5],\n",
    "               'xgb__min_child_weight':[1,2],\n",
    "               'xgb__n_estimators': [100,200],\n",
    "               'xgb__learning_rate': [0.2,0.3,0.4]}]\n",
    "\n",
    "# create a gridsearch of the pipeline, and fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5) \n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "\n",
    "print(best_model.best_estimator_)\n",
    "print('')\n",
    "print(best_model.score(X_train, y_train), best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-inclusion",
   "metadata": {},
   "source": [
    "**Key takeways:** R-square score improves from **0.863 to 0.885** with GridSearching the XGBoost Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-prayer",
   "metadata": {},
   "source": [
    "### Linear Regression and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "outstanding-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "noticed-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall:\n",
    "X = course[numeric_features].drop(columns=['spanish','chinese_(traditional)', 'arabic', 'portuguese_(brazilian)', \n",
    "                                           'russian', 'advanced_level', 'chinese_(simplified)', 'french', \n",
    "                                           'japanese', '100%_online', 'flexible_deadlines', 'enrollment'])\n",
    "y = course['enrollment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-lebanon",
   "metadata": {},
   "source": [
    "#### Linear Regression without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "theoretical-contents",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9508811676656268, 0.5806206401638387)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('ss', StandardScaler()),\n",
    "                 ('lr', LinearRegression())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-article",
   "metadata": {},
   "source": [
    "#### LASSO with PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "metric-enzyme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9932006717582604, 0.8702241963094685)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the pipe\n",
    "pipe = Pipeline([('poly', PolynomialFeatures()),\n",
    "                  ('ss', StandardScaler()),\n",
    "                  ('lasso', Lasso())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "athletic-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('poly', PolynomialFeatures(degree=3, interaction_only=True)),\n",
      "                ('ss', StandardScaler()), ('lasso', Lasso(alpha=10))])\n",
      "\n",
      "0.9950073365792866 0.882777862703681\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [{'poly__degree':[2,3],\n",
    "               'poly__interaction_only':[True, False],\n",
    "               'lasso__alpha': [1, 10, 100]}]\n",
    "\n",
    "# create a gridsearch of the pipeline, and fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5) \n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "\n",
    "print(best_model.best_estimator_)\n",
    "print('')\n",
    "print(best_model.score(X_train, y_train), best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-setup",
   "metadata": {},
   "source": [
    "**Key takeways:** R-square score improves from **0.581 to 0.883** with LASSO Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-listening",
   "metadata": {},
   "source": [
    "#### Ridge with PolynomialFeatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "theoretical-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9924096696864031, 0.8622941131736972)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('poly', PolynomialFeatures()),\n",
    "                  ('ss', StandardScaler()),\n",
    "                  ('ridge', Ridge())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "flying-ocean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('poly', PolynomialFeatures(degree=3, interaction_only=True)),\n",
      "                ('ss', StandardScaler()), ('ridge', Ridge(alpha=1))])\n",
      "\n",
      "0.9941874207858192 0.8683042328727619\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [{'poly__degree':[2,3],\n",
    "               'poly__interaction_only':[True, False],\n",
    "               'ridge__alpha': [0.01,0.1,1]}]\n",
    "\n",
    "# create a gridsearch of the pipeline, and fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5) \n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "\n",
    "print(best_model.best_estimator_)\n",
    "print('')\n",
    "print(best_model.score(X_train, y_train), best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-presentation",
   "metadata": {},
   "source": [
    "**Key takeways:** R-square score improves from **0.581 to 0.868** with Ridge Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-packaging",
   "metadata": {},
   "source": [
    "#### Using LASSO for feature selection and intepretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "infinite-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# reference:\n",
    "# https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "personal-living",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9860108160495665, 0.6999168399560736)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, interaction_only=False)\n",
    "X_train_overfit = poly.fit_transform(X_train)\n",
    "X_test_overfit = poly.transform(X_test)\n",
    "sc = StandardScaler()\n",
    "X_train_overfit_sc = sc.fit_transform(X_train_overfit)\n",
    "X_test_overfit_sc = sc.transform(X_test_overfit)\n",
    "lasso_lr = Lasso(alpha=7500)\n",
    "lasso_lr.fit(X_train_overfit_sc, y_train)\n",
    "lasso_lr.score(X_train_overfit_sc, y_train), lasso_lr.score(X_test_overfit_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "physical-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use SelectFromModel \n",
    "\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# reference:\n",
    "# https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "\n",
    "# sel_ = SelectFromModel(Lasso(alpha=3000))\n",
    "# sel_.fit(X_train_overfit_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "centered-forward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_ratings</th>\n",
       "      <td>26699.244012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_reviews</th>\n",
       "      <td>50124.894204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_ratings length</th>\n",
       "      <td>67209.707451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_ratings shareable_certificate</th>\n",
       "      <td>3684.908363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_ratings he_partner</th>\n",
       "      <td>106712.282179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_reviews shareable_certificate</th>\n",
       "      <td>1536.819649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length shareable_certificate</th>\n",
       "      <td>112.550500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_ratings shareable_certificate he_partner</th>\n",
       "      <td>986.866842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_ratings he_partner^2</th>\n",
       "      <td>897.318160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_reviews^2 beginner_level</th>\n",
       "      <td>-4996.774358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_reviews shareable_certificate^2</th>\n",
       "      <td>1786.616014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length^2 he_partner</th>\n",
       "      <td>1849.856188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length shareable_certificate^2</th>\n",
       "      <td>81.249971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model_coefficient\n",
       "num_ratings                                        26699.244012\n",
       "num_reviews                                        50124.894204\n",
       "num_ratings length                                 67209.707451\n",
       "num_ratings shareable_certificate                   3684.908363\n",
       "num_ratings he_partner                            106712.282179\n",
       "num_reviews shareable_certificate                   1536.819649\n",
       "length shareable_certificate                         112.550500\n",
       "num_ratings shareable_certificate he_partner         986.866842\n",
       "num_ratings he_partner^2                             897.318160\n",
       "num_reviews^2 beginner_level                       -4996.774358\n",
       "num_reviews shareable_certificate^2                 1786.616014\n",
       "length^2 he_partner                                 1849.856188\n",
       "length shareable_certificate^2                        81.249971"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the selected features into a DataFrame\n",
    "selections = pd.DataFrame(data=lasso_lr.coef_, index=poly.get_feature_names(X_train.columns), columns=['model_coefficient'])\n",
    "\n",
    "# list the features of the non-zero coefficients \n",
    "selections[selections['model_coefficient']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "martial-citation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_ratings', 'num_reviews', 'num_ratings length',\n",
       "       'num_ratings shareable_certificate', 'num_ratings he_partner',\n",
       "       'num_reviews shareable_certificate', 'length shareable_certificate',\n",
       "       'num_ratings shareable_certificate he_partner',\n",
       "       'num_ratings he_partner^2', 'num_reviews^2 beginner_level',\n",
       "       'num_reviews shareable_certificate^2', 'length^2 he_partner',\n",
       "       'length shareable_certificate^2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the feature names of the non-zero features\n",
    "selections[selections['model_coefficient']!=0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-cherry",
   "metadata": {},
   "source": [
    "**Key Takeways**:  \n",
    "The most important features are: `'num_ratings', 'num_reviews', 'num_ratings length', 'num_ratings shareable_certificate', 'num_ratings he_partner', 'num_reviews shareable_certificate', 'length shareable_certificate', 'num_ratings shareable_certificate he_partner', 'num_ratings he_partner^2', 'num_reviews^2 beginner_level', 'num_reviews shareable_certificate^2', 'length^2 he_partner', 'length shareable_certificate^2'`   \n",
    "All these features and their poly/interaction terms are positively related to enrollment except for `num_reviews^2 beginner_level`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "respiratory-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-virginia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
