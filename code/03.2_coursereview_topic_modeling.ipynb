{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitting-soviet",
   "metadata": {},
   "source": [
    "## 3.2 Course Review Topic Modeling\n",
    "\n",
    "**Credit to Analytics Vidhya Articles for the ideas and codes:**  \n",
    "https://www.analyticsvidhya.com/blog/2018/10/mining-online-reviews-topic-modeling-lda/  \n",
    "https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-today",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_colwidth = 350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-medicare",
   "metadata": {},
   "source": [
    "---\n",
    "### Course Name: Review from 'Machine Learning by Stanford University, Andrew Ng' on Coursera\n",
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressed-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/reviews_machine_learning.csv'\n",
    "reviews = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "angry-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick pre-processing, dropping columns and remove rows with null values\n",
    "reviews.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "reviews.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "separate-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create review label: 1 - 3: bad reviews, 4/5: good reviews\n",
    "reviews['review_is_bad'] = reviews['rating'].map(lambda x: 1 if x < 4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-liver",
   "metadata": {},
   "source": [
    "### Data Pre-processing \n",
    "#### `tokenize`, `stopwords`, `lemmatize`, `pos_tag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "small-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "former-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to associate the wordnet object value corresponding to the POS tag\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "subject-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ruled-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recorded-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text data\n",
    "reviews[\"review_clean\"] = reviews[\"review\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regulated-backing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date_of_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>course_href</th>\n",
       "      <th>review_is_bad</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is an extremely basic course. Machine learning is built on mathematics, yet this course treats mathematics as a mysterious monster to be avoided at all costs, which unfortunately left this student feeling frustrated and patronized. So much time is wasted in the videos with arduous explanations of trivialities, and so little taken up with t...</td>\n",
       "      <td>Mar 18, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>/learn/machine-learning</td>\n",
       "      <td>1</td>\n",
       "      <td>extremely basic course machine learn build mathematics yet course treat mathematics mysterious monster avoid cost unfortunately leave student feeling frustrate patronized much time waste videos arduous explanation triviality little take impart meaningful knowledge end abandon video altogether quizes basic largely base recall rather application ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                          review  \\\n",
       "0  This is an extremely basic course. Machine learning is built on mathematics, yet this course treats mathematics as a mysterious monster to be avoided at all costs, which unfortunately left this student feeling frustrated and patronized. So much time is wasted in the videos with arduous explanations of trivialities, and so little taken up with t...   \n",
       "\n",
       "  date_of_review  rating              course_href  review_is_bad  \\\n",
       "0   Mar 18, 2017       1  /learn/machine-learning              1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                    review_clean  \n",
       "0  extremely basic course machine learn build mathematics yet course treat mathematics mysterious monster avoid cost unfortunately leave student feeling frustrate patronized much time waste videos arduous explanation triviality little take impart meaningful knowledge end abandon video altogether quizes basic largely base recall rather application ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-couple",
   "metadata": {},
   "source": [
    "## LDA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incomplete-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surprised-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    # Given a string of text, tokenize the text and pull out only the nouns and adjectives\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if   is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "trained-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"review_lda\"] = reviews[\"review_clean\"].apply(lambda x: nouns_adj(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "portable-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reviews = reviews[\"review_lda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "burning-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bronze-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document term matrix\n",
    "min_df = 4 # minimum required occurences of a word, e.g 4\n",
    "max_features = 10000 # max number of unique words, e.g 10000\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "              min_df=min_df, \n",
    "              max_features=max_features, \n",
    "              ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aging-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_lda_reviews = vectorizer.fit_transform(lda_reviews.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "soviet-daughter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>ability complex</th>\n",
       "      <th>ability explain</th>\n",
       "      <th>able</th>\n",
       "      <th>able apply</th>\n",
       "      <th>able build</th>\n",
       "      <th>able complete</th>\n",
       "      <th>able course</th>\n",
       "      <th>able explain</th>\n",
       "      <th>able finish</th>\n",
       "      <th>...</th>\n",
       "      <th>zero knowledge</th>\n",
       "      <th>área</th>\n",
       "      <th>ótimo</th>\n",
       "      <th>за</th>\n",
       "      <th>курс</th>\n",
       "      <th>на</th>\n",
       "      <th>не</th>\n",
       "      <th>очень</th>\n",
       "      <th>по</th>\n",
       "      <th>что</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  ability complex  ability explain  able  able apply  able build  \\\n",
       "0        0                0                0     0           0           0   \n",
       "1        0                0                0     0           0           0   \n",
       "2        0                0                0     0           0           0   \n",
       "3        0                0                0     0           0           0   \n",
       "4        0                0                0     0           0           0   \n",
       "\n",
       "   able complete  able course  able explain  able finish  ...  zero knowledge  \\\n",
       "0              0            0             0            0  ...               0   \n",
       "1              0            0             0            0  ...               0   \n",
       "2              0            0             0            0  ...               0   \n",
       "3              0            0             0            0  ...               0   \n",
       "4              0            0             0            0  ...               0   \n",
       "\n",
       "   área  ótimo  за  курс  на  не  очень  по  что  \n",
       "0     0      0   0     0   0   0      0   0    0  \n",
       "1     0      0   0     0   0   0      0   0    0  \n",
       "2     0      0   0     0   0   0      0   0    0  \n",
       "3     0      0   0     0   0   0      0   0    0  \n",
       "4     0      0   0     0   0   0      0   0    0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_lda_reviews_df = pd.DataFrame(vec_lda_reviews.toarray(), columns=vectorizer.get_feature_names())\n",
    "vec_lda_reviews_df.index = lda_reviews.index\n",
    "vec_lda_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "structural-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = pd.Series(lda_reviews).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "weird-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agreed-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adjacent-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "empirical-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=6, random_state=42,\n",
    "                chunksize=1000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "inclusive-slide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.022*\"que\" + 0.021*\"curso\" + 0.013*\"un\" + 0.013*\"la\" + 0.013*\"muy\" + 0.012*\"para\" + 0.011*\"los\" + 0.010*\"el\" + 0.009*\"con\" + 0.007*\"excelente\"'),\n",
       " (1,\n",
       "  '0.066*\"course\" + 0.022*\"great\" + 0.019*\"assignment\" + 0.015*\"program\" + 0.014*\"time\" + 0.014*\"ng\" + 0.014*\"exercise\" + 0.014*\"lecture\" + 0.012*\"easy\" + 0.012*\"lot\"'),\n",
       " (2,\n",
       "  '0.062*\"ng\" + 0.062*\"course\" + 0.058*\"thank\" + 0.031*\"coursera\" + 0.030*\"thanks\" + 0.025*\"andrew\" + 0.022*\"much\" + 0.020*\"professor\" + 0.018*\"i\" + 0.018*\"best\"'),\n",
       " (3,\n",
       "  '0.055*\"science\" + 0.044*\"data\" + 0.030*\"computer\" + 0.020*\"python\" + 0.010*\"benefit\" + 0.009*\"scientist\" + 0.009*\"thought\" + 0.008*\"update\" + 0.007*\"evaluate\" + 0.007*\"language\"'),\n",
       " (4,\n",
       "  '0.057*\"course\" + 0.041*\"machine\" + 0.029*\"learn\" + 0.016*\"ml\" + 0.014*\"great\" + 0.014*\"good\" + 0.013*\"use\" + 0.012*\"algorithm\" + 0.011*\"work\" + 0.011*\"concept\"'),\n",
       " (5,\n",
       "  '0.128*\"course\" + 0.125*\"machine\" + 0.080*\"learn\" + 0.040*\"learning\" + 0.021*\"good\" + 0.021*\"great\" + 0.021*\"start\" + 0.020*\"best\" + 0.018*\"beginner\" + 0.017*\"concept\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "virgin-playing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "governing-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el43792140693986409600816700436\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el43792140693986409600816700436_data = {\"mdsDat\": {\"x\": [-0.18741095573615538, -0.19031245799074734, -0.17131030600652672, -0.06808813042838865, 0.3106528811863451, 0.306468968975473], \"y\": [-0.14551994133868237, 0.05373682764340326, -0.12832029152580038, 0.2837419673296586, -0.04902764046093465, -0.014610921647644699], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [34.87312217260224, 32.823489508551305, 14.763285891505614, 11.032198206204303, 3.7291350595386366, 2.778769161597911]}, \"tinfo\": {\"Term\": [\"machine\", \"course\", \"learn\", \"thank\", \"ng\", \"learning\", \"thanks\", \"andrew\", \"coursera\", \"data\", \"best\", \"professor\", \"much\", \"start\", \"science\", \"beginner\", \"i\", \"lecture\", \"class\", \"assignment\", \"good\", \"prof\", \"python\", \"basic\", \"anyone\", \"application\", \"concept\", \"content\", \"algorithm\", \"teacher\", \"application\", \"linear\", \"algebra\", \"system\", \"tool\", \"implementation\", \"build\", \"network\", \"neural\", \"solid\", \"balance\", \"calculus\", \"research\", \"familiar\", \"statistic\", \"analysis\", \"regression\", \"matrix\", \"intelligence\", \"inspire\", \"library\", \"performance\", \"wide\", \"debug\", \"supervise\", \"software\", \"function\", \"concise\", \"real-world\", \"building\", \"algorithm\", \"model\", \"use\", \"real\", \"different\", \"theory\", \"focus\", \"algorithms\", \"advice\", \"problem\", \"technique\", \"implement\", \"various\", \"mathematical\", \"practical\", \"approach\", \"math\", \"ml\", \"work\", \"machine\", \"project\", \"learn\", \"course\", \"background\", \"introduction\", \"good\", \"basic\", \"concept\", \"great\", \"excellent\", \"program\", \"example\", \"help\", \"knowledge\", \"many\", \"lot\", \"topic\", \"understand\", \"exercise\", \"lecture\", \"content\", \"quiz\", \"fun\", \"question\", \"follow\", \"quality\", \"tutorial\", \"style\", \"discussion\", \"note\", \"watch\", \"enjoyable\", \"video\", \"pleasure\", \"slide\", \"explains\", \"answer\", \"presentation\", \"prepared\", \"guidance\", \"understood\", \"real-life\", \"optional\", \"motivation\", \"reference\", \"deliver\", \"superb\", \"discuss\", \"dedication\", \"forum\", \"videos\", \"test\", \"material\", \"assignment\", \"week\", \"difficult\", \"easy\", \"exercise\", \"everything\", \"time\", \"manner\", \"program\", \"clear\", \"hard\", \"course\", \"great\", \"andrew\", \"professor\", \"understand\", \"explain\", \"way\", \"lot\", \"complete\", \"teacher\", \"topic\", \"ng\", \"excellent\", \"good\", \"class\", \"much\", \"concept\", \"thank\", \"learn\", \"help\", \"thanks\", \"learning\", \"beginner\", \"interested\", \"career\", \"thankful\", \"pursue\", \"specialization\", \"state\", \"meet\", \"date\", \"willing\", \"till\", \"intermediate\", \"success\", \"art\", \"join\", \"delve\", \"select\", \"brief\", \"luck\", \"aspire\", \"era\", \"explained\", \"prerequisite\", \"deadline\", \"enrol\", \"high-level\", \"joy\", \"decade\", \"excercises\", \"anyone\", \"want\", \"start\", \"machine\", \"field\", \"recommend\", \"learn\", \"best\", \"deep\", \"everyone\", \"course\", \"basic\", \"ai\", \"good\", \"concept\", \"introduction\", \"journey\", \"great\", \"introductory\", \"ml\", \"foundation\", \"fundamental\", \"awesome\", \"knowledge\", \"get\", \"look\", \"way\", \"lot\", \"ng\", \"excellent\", \"experience\", \"helpful\", \"topic\", \"understand\", \"thanks\", \"sir\", \"team\", \"stanford\", \"hope\", \"special\", \"tom\", \"mooc\", \"coursera\", \"certificate\", \"minute\", \"bring\", \"guy\", \"enter\", \"reward\", \"staff\", \"refresh\", \"ease\", \"gratitude\", \"module\", \"approachable\", \"man\", \"busy\", \"proud\", \"live\", \"enthusiasm\", \"human\", \"scene\", \"regret\", \"contribution\", \"comprehensible\", \"thank\", \"mr\", \"wonderful\", \"teaching\", \"platform\", \"ng\", \"share\", \"thanks\", \"andrew\", \"university\", \"life\", \"professor\", \"prof\", \"i\", \"much\", \"day\", \"chance\", \"best\", \"class\", \"teacher\", \"online\", \"course\", \"amaze\", \"world\", \"effort\", \"knowledge\", \"lot\", \"many\", \"teach\", \"great\", \"experience\", \"que\", \"curso\", \"un\", \"la\", \"muy\", \"para\", \"los\", \"el\", \"con\", \"excelente\", \"le\", \"bien\", \"por\", \"cours\", \"como\", \"se\", \"una\", \"lo\", \"profesor\", \"este\", \"pero\", \"algoritmos\", \"conceptos\", \"te\", \"tr\\u00e8s\", \"son\", \"del\", \"gracias\", \"est\", \"ce\", \"machine\", \"learn\", \"ng\", \"science\", \"computer\", \"benefit\", \"thought\", \"update\", \"evaluate\", \"aid\", \"financial\", \"reasonable\", \"congratulation\", \"combination\", \"vision\", \"describe\", \"daily\", \"situation\", \"didactic\", \"terrific\", \"s\", \"researcher\", \"inspiration\", \"package\", \"play\", \"discipline\", \"dream\", \"illustrate\", \"preparation\", \"ta\", \"\\u2019\", \"compute\", \"syllabus\", \"scientist\", \"data\", \"python\", \"english\", \"language\", \"professional\"], \"Freq\": [8835.0, 18092.0, 6716.0, 2400.0, 3489.0, 1573.0, 1666.0, 1681.0, 940.0, 563.0, 1563.0, 1341.0, 1690.0, 1149.0, 413.0, 717.0, 1340.0, 1192.0, 1705.0, 2200.0, 3167.0, 931.0, 407.0, 1213.0, 727.0, 974.0, 2526.0, 873.0, 1228.0, 820.0, 973.2181888543594, 498.4190995738372, 471.1526851800656, 382.742604203778, 366.13271430815837, 340.1623580986159, 275.1769365408931, 262.71454637281374, 259.1628810055125, 212.31011235970857, 209.01875470770543, 206.11892850602317, 164.31022774406117, 151.7072032869166, 151.07101926572548, 143.7274028066761, 137.56449428358215, 133.30896969264333, 127.78222335650838, 124.98987616242174, 118.19885136690384, 118.14197319223922, 114.1460467040547, 110.05882037427321, 101.33645949396788, 100.08080555627112, 96.33845092277663, 96.94149057961425, 96.24086282232999, 94.0745467315001, 1156.8411115022152, 263.0539813453036, 1193.9048078576411, 706.1029093299131, 455.9432647666583, 536.2163387914634, 314.1844690789932, 755.3515919343727, 276.4145663199773, 833.3162199343827, 481.4519361380881, 400.9050171740723, 276.59384719988947, 540.6721815449591, 944.6294933635862, 289.2884225923003, 763.4313931977086, 1504.1827834632006, 1054.0693896771568, 3811.706704967514, 350.79414441177937, 2679.4515501874666, 5384.23011093515, 406.87833905969495, 585.2397794574046, 1306.339050763728, 682.5112835383502, 1015.2038451505131, 1332.7402182071696, 838.9066567256027, 742.9248570673402, 488.78120750663663, 618.4678562568483, 600.7237435054502, 540.3546244730504, 641.146942151316, 574.9095675582403, 565.4059123500947, 501.7869425409459, 1191.859328522194, 872.3353403827848, 602.9337969482269, 439.87300595267715, 380.07316136253775, 368.30314073832244, 310.04149343637295, 210.0103338764617, 208.5979289354422, 208.72086470096636, 183.87904425973028, 165.86152544306665, 135.93085893114238, 913.8664205525469, 122.113963976234, 114.11460029864583, 113.08000396902655, 110.65516689483007, 107.69042561401912, 103.63418243108195, 101.08021348081209, 86.88870558677682, 77.38052733760829, 73.17984182301173, 69.62052054083921, 67.925498975365, 67.49508507713756, 65.23437300418102, 63.382891940733415, 63.38833794171368, 276.27404730554235, 198.09968312127316, 224.1602774799967, 1067.6836010540962, 1713.5807147770518, 512.4857084264363, 356.5550274237107, 1089.210882544012, 1201.600970668102, 355.19023902711103, 1226.2951531054055, 240.16985573523937, 1308.6516761254647, 617.0916732173407, 262.25363632154915, 5810.4294454305855, 1927.6087999125411, 925.4124358534233, 744.7408395596996, 868.6711887194791, 474.14166913221527, 860.3525763542389, 1079.522919471917, 554.1055275857558, 515.4929696167875, 778.8195708861828, 1220.3981821420882, 794.28999504438, 1015.937302713562, 736.1419122760792, 713.9231325183003, 846.1730804887808, 678.6980282609463, 803.6280987931245, 575.4565641533823, 523.4947685816064, 1572.2108244106948, 717.0277459863054, 434.66053231079366, 294.1538725816478, 106.6839471108102, 76.345632001293, 70.42817736452469, 47.799152518395935, 42.84955218618184, 39.38648836471207, 37.20263698969358, 36.801736056302154, 34.67525131781229, 33.20270464060448, 32.171438538548465, 28.190124638221143, 27.65639885483862, 26.65075998336075, 23.96092447537368, 23.57793949497345, 23.125291891218055, 22.929797023798702, 21.699373370782634, 21.101785175834948, 19.53351420651991, 19.131959305026264, 18.18624517145214, 17.66291586330596, 17.52924871164257, 17.317583731872396, 593.3924095507696, 231.6976911686131, 818.2411182040915, 4950.0664936180765, 519.9610812537368, 317.15761421782435, 3193.0201583364196, 791.5887244558959, 320.1163785096701, 213.49528628359622, 5066.488233746658, 530.0890367251435, 107.5704043396309, 844.2998660526836, 665.0004655354486, 309.12220877967394, 130.45963916520253, 839.8672656341564, 125.76024749106593, 492.59565429840023, 160.44445100827042, 171.68558497508786, 183.3032566749374, 322.468741057657, 182.9077700428304, 143.6788903015946, 293.8934500048007, 338.11646461275933, 384.79749343525424, 292.32980533986955, 225.00970959190093, 199.8290075096134, 249.4791162197432, 248.18114436320775, 247.32864725887546, 385.6969356761726, 346.9672162397372, 194.96655398071118, 182.42172663269042, 78.48802069306154, 76.56537006953837, 76.0721464646406, 928.2849804156127, 58.01160850874057, 54.35414818995507, 51.07792666114415, 48.15848167268249, 48.27443128537073, 47.72194638704915, 45.694805383402596, 45.946107251500386, 44.88191132455601, 42.24535189370556, 40.23931963913566, 38.50115644332465, 36.878189963065324, 33.45612397012514, 32.705975944201434, 31.520870953705916, 30.39674027030273, 30.14391533964885, 25.859122476928338, 25.753637443707092, 24.594667999454632, 23.84164653124824, 1720.716372631105, 194.47335800506613, 394.48030274452015, 112.22260608670639, 109.12214114174871, 1846.5231909238357, 158.0069440635421, 895.3165403852154, 742.2416942243874, 175.63888323665208, 257.9430286858896, 587.3408307514179, 440.238600150669, 544.9746319599798, 639.6883181213037, 119.54685850438295, 82.22797159949363, 525.2772956291784, 524.9953667344427, 304.53490064654454, 235.78812558431562, 1831.241119694403, 207.25528578528753, 252.67175407680764, 202.32820259194173, 345.5635673138978, 369.62748600277854, 218.41645397181045, 194.2332736135719, 225.2159163633588, 187.89325806547342, 224.41592723364272, 212.77065603537054, 131.48807181426295, 130.5263554714036, 128.65978989723303, 121.9985955508995, 105.45853138743529, 100.17479315577354, 88.90521473073954, 73.07165134809229, 59.28457084466065, 57.534494592602094, 54.240895130454874, 53.779084499508436, 48.16817592490055, 46.832765423004226, 45.33173144332914, 41.27252732198881, 38.06201277380286, 33.892527642454574, 32.92049368726432, 32.31147438018061, 31.598095191143074, 31.19619628964012, 30.77508640957672, 29.846337861718997, 29.10429396876962, 28.722514294570427, 27.854590394558855, 25.814294813980226, 72.78895951044228, 39.56670543157764, 37.44139403289705, 412.50733270549546, 225.54597105980832, 72.73092398744076, 66.74814521587773, 57.70085670446164, 54.484792904382786, 50.33534677549634, 48.08786495692267, 45.28173653485469, 44.79196169152682, 43.15695591765269, 42.28691278200985, 42.17502270370377, 41.62992914956268, 36.102219672097974, 35.52188818963851, 35.31547820565055, 31.01509390607244, 30.239807289039852, 30.128174701273473, 29.802188198409148, 29.630622947726238, 27.582891155127157, 27.25080491015341, 25.401867992810704, 23.740312856532185, 23.28773495738556, 22.90338509205613, 22.80589360636202, 22.065197711696666, 69.31871502894313, 325.08651079523486, 147.16084014787154, 35.978819070746844, 52.26534971782151, 27.68614660134851], \"Total\": [8835.0, 18092.0, 6716.0, 2400.0, 3489.0, 1573.0, 1666.0, 1681.0, 940.0, 563.0, 1563.0, 1341.0, 1690.0, 1149.0, 413.0, 717.0, 1340.0, 1192.0, 1705.0, 2200.0, 3167.0, 931.0, 407.0, 1213.0, 727.0, 974.0, 2526.0, 873.0, 1228.0, 820.0, 974.0681192049318, 499.2673175487206, 472.0011770142192, 383.59078321198064, 366.98057992201126, 341.0102876525952, 276.028466887211, 263.56134260795653, 260.0095233879195, 213.15943156166495, 209.8717212085465, 206.96640833604562, 165.16309319006106, 152.5550511822175, 151.91940638691523, 144.57554754542298, 138.4102134057189, 134.1601518067438, 128.6346577325558, 125.84641890871497, 119.04542913475595, 118.98823369015484, 114.99324278706102, 110.90545791662657, 102.18397423855285, 100.94531168542683, 97.1854224182955, 97.79395248754672, 97.08857038475897, 94.92576873580907, 1228.578046123131, 273.6925069799243, 1331.8969044976645, 800.4333108324478, 508.66571210577433, 605.7574883217736, 342.17466937031844, 883.8666082243807, 299.68696194332784, 1010.2050926496961, 552.9171729526747, 460.6371728820067, 304.50463787486063, 647.860050350992, 1227.4245444930964, 320.4927357994232, 999.1112997450258, 2223.036627717566, 1548.3412065443601, 8835.08473222019, 417.51393213252453, 6716.008773442584, 18092.74126433588, 516.5976266038992, 895.057686080595, 3167.090910276585, 1213.2950795105178, 2526.8917035449736, 4325.78440192102, 1926.0449616210174, 2052.244476304566, 791.0809509592744, 1547.5228821247517, 1500.6140784940776, 1151.1295313864264, 2428.7663147178614, 1603.7222209919407, 1682.7724578623206, 1704.0556699750932, 1192.7127156072743, 873.1898685255583, 603.7858971370413, 440.7289535332744, 380.9270978297828, 369.15709803651805, 310.89448337331794, 210.8629436694182, 209.45390215710944, 209.57783423425846, 184.73140523986743, 166.71456455836937, 136.7854740119031, 920.2083123505516, 122.96931900548807, 114.96582885243953, 113.9368880336895, 111.50661696707371, 108.54397314473806, 104.48901965875149, 101.93414783246416, 87.7411875559791, 78.2375311699675, 74.0321806592492, 70.47887180109993, 68.77796189228191, 68.34951640170537, 66.08900501855379, 64.23697629808215, 64.24541261842823, 280.1208568617062, 205.23596938113224, 234.5190524822667, 1194.0562294933425, 2200.4812194560095, 603.6075747068535, 409.52649310639697, 1390.9807671639933, 1704.0556699750932, 431.2395248005269, 1830.1311825855598, 278.2759630325812, 2052.244476304566, 965.26350387917, 328.99326798944577, 18092.74126433588, 4325.78440192102, 1681.4967170259247, 1341.2504379069483, 1682.7724578623206, 722.5662934869591, 1737.9993011387744, 2428.7663147178614, 912.058653527442, 820.7207701789595, 1603.7222209919407, 3489.525350295728, 1926.0449616210174, 3167.090910276585, 1705.5633295925215, 1690.491097620831, 2526.8917035449736, 2400.106733041221, 6716.008773442584, 1547.5228821247517, 1666.678356085696, 1573.0914269436387, 717.906734890804, 435.5396574392635, 295.0351188349633, 107.56972032341974, 77.22570285862905, 71.30809971052824, 48.68104108618531, 43.73721902058226, 40.26717409190086, 38.08556620506231, 37.68147405868081, 35.55368127311063, 34.08882177108965, 33.05093375372853, 29.07062183836188, 28.535327825688842, 27.538154140921822, 24.84303615750557, 24.460212756723116, 24.007672883211654, 23.809181127370127, 22.580544125794212, 21.981150820538222, 20.42055835079347, 20.014800312985727, 19.06617653818383, 18.548908193684166, 18.414325764954445, 18.199644326861616, 727.582129899085, 279.2005880943227, 1149.7798171934771, 8835.08473222019, 809.4269179918883, 466.23393179867753, 6716.008773442584, 1563.9212987259014, 583.7222185237731, 357.15076229476523, 18092.74126433588, 1213.2950795105178, 186.1997456440592, 3167.090910276585, 2526.8917035449736, 895.057686080595, 257.07348445274505, 4325.78440192102, 250.5786919754207, 2223.036627717566, 383.2143851951334, 437.3605478559221, 504.384199065548, 1500.6140784940776, 565.2325980150918, 334.92324414027263, 1737.9993011387744, 2428.7663147178614, 3489.525350295728, 1926.0449616210174, 1037.2870049571634, 732.3798440886982, 1603.7222209919407, 1682.7724578623206, 1666.678356085696, 386.56766182122425, 347.8378615019774, 195.83697762409713, 183.29243505835944, 79.35923657330969, 77.4378141860548, 76.94818819730985, 940.000835144439, 58.88250168871276, 55.228560874808196, 51.949000882754504, 49.02984536555653, 49.14863380247459, 48.59624747298756, 46.56543207737811, 46.821537443807415, 45.755454564702475, 43.11502015292803, 41.113075069927135, 39.37631953065028, 37.75703574530208, 34.327802258873135, 33.5776369316212, 32.391574232968175, 31.26813306751106, 31.01528485462256, 26.73382186408702, 26.62626482474331, 25.464150436387783, 24.716923798274113, 2400.106733041221, 233.98834226164345, 505.5507641984804, 134.6171738006984, 135.0346916347893, 3489.525350295728, 206.86133591342445, 1666.678356085696, 1681.4967170259247, 278.51314562308943, 459.6022973023697, 1341.2504379069483, 931.0238141341979, 1340.4364456460858, 1690.491097620831, 172.27274836389336, 105.89957479443493, 1563.9212987259014, 1705.5633295925215, 820.7207701789595, 600.8069687808186, 18092.74126433588, 486.7238628677319, 710.7191615239103, 508.81396861965277, 1500.6140784940776, 2428.7663147178614, 1151.1295313864264, 938.7020743703016, 4325.78440192102, 1037.2870049571634, 225.2712765414993, 213.62600564428607, 132.34349081857866, 131.3818497575228, 129.5151337918116, 122.85394499428013, 106.3138817444336, 101.03014059240577, 89.76265797116191, 73.92699861623326, 60.14062368626414, 58.38984500905422, 55.09624817000996, 54.63501084396849, 49.02352501274406, 47.68856047895309, 46.187077553042535, 42.1278707497913, 38.918413026696555, 34.74790838391611, 33.77583755938535, 33.166816552848296, 32.4534424101392, 32.052207881642424, 31.630448653161995, 30.702083521912627, 29.959635028809295, 29.57793634677126, 28.70994647238749, 26.670017934166296, 8835.08473222019, 6716.008773442584, 3489.525350295728, 413.3594486371867, 226.39792215650598, 73.58521957501223, 67.6012928497963, 58.55252201178541, 55.33928901322334, 51.188454694153606, 48.941377169060836, 46.13548296629696, 45.645731183159384, 44.0105659624338, 43.141651815872656, 43.03126278157059, 42.484387412186635, 36.95753584006905, 36.37562435113104, 36.170973088466006, 31.86965659661408, 31.094375552229803, 30.983437788047713, 30.65560754195762, 30.483834921905004, 28.437012677631827, 28.106370080130045, 26.25499439106632, 24.59331060468567, 24.14102281364112, 23.75545052329583, 23.658560571422743, 22.91940236502373, 77.7088503341466, 563.3371464664909, 407.32926209136303, 54.22912115911622, 321.9792251408472, 146.36313508314743], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.5680999755859375, -5.237199783325195, -5.293499946594238, -5.501299858093262, -5.5457000732421875, -5.61929988861084, -5.831299781799316, -5.877600193023682, -5.891200065612793, -6.09060001373291, -6.106299877166748, -6.120200157165527, -6.34689998626709, -6.426700115203857, -6.4309000968933105, -6.480800151824951, -6.524600028991699, -6.556000232696533, -6.598400115966797, -6.6203999519348145, -6.676300048828125, -6.676799774169922, -6.71120023727417, -6.747700214385986, -6.8302001953125, -6.842700004577637, -6.880799770355225, -6.874599933624268, -6.881800174713135, -6.904600143432617, -4.395199775695801, -5.876299858093262, -4.363699913024902, -4.888899803161621, -5.326300144195557, -5.164100170135498, -5.698699951171875, -4.821499824523926, -5.8267998695373535, -4.723299980163574, -5.271900177001953, -5.454999923706055, -5.826099872589111, -5.155900001525879, -4.597899913787842, -5.781300067901611, -4.8109002113342285, -4.132699966430664, -4.48829984664917, -3.2028000354766846, -5.588500022888184, -3.555299997329712, -2.8573999404907227, -5.440199851989746, -5.076700210571289, -4.27370023727417, -4.922900199890137, -4.5258002281188965, -4.253699779510498, -4.716599941253662, -4.838099956512451, -5.256800174713135, -5.021399974822998, -5.05049991607666, -5.156499862670898, -4.985400199890137, -5.0945000648498535, -5.111100196838379, -5.230500221252441, -4.304800033569336, -4.6168999671936035, -4.986299991607666, -5.301599979400635, -5.447700023651123, -5.4791998863220215, -5.651400089263916, -6.040900230407715, -6.047699928283691, -6.047100067138672, -6.173799991607666, -6.2769999504089355, -6.47599983215332, -4.570400238037109, -6.583199977874756, -6.650899887084961, -6.659999847412109, -6.681700229644775, -6.708799839019775, -6.747200012207031, -6.772200107574463, -6.923500061035156, -7.039400100708008, -7.095200061798096, -7.144999980926514, -7.1697001457214355, -7.17609977722168, -7.210100173950195, -7.238900184631348, -7.238800048828125, -5.76669979095459, -6.099299907684326, -5.9756999015808105, -4.414899826049805, -3.941800117492676, -5.148799896240234, -5.511600017547607, -4.394899845123291, -4.2967000007629395, -5.515500068664551, -4.276400089263916, -5.906799793243408, -4.211400032043457, -4.963099956512451, -5.81879997253418, -2.7207000255584717, -3.8241000175476074, -4.5578999519348145, -4.775100231170654, -4.621099948883057, -5.226600170135498, -4.630799770355225, -4.403800010681152, -5.070799827575684, -5.14300012588501, -4.730299949645996, -4.281199932098389, -4.710700035095215, -4.4644999504089355, -4.7866997718811035, -4.817299842834473, -4.64739990234375, -4.8678998947143555, -4.698999881744385, -5.032899856567383, -5.127600193023682, -3.2288999557495117, -4.013999938964844, -4.514500141143799, -4.90500020980835, -5.9191999435424805, -6.253799915313721, -6.334499835968018, -6.722099781036377, -6.831399917602539, -6.9156999588012695, -6.972700119018555, -6.98360013961792, -7.043099880218506, -7.08650016784668, -7.118000030517578, -7.250100135803223, -7.269199848175049, -7.306300163269043, -7.412700176239014, -7.428800106048584, -7.448200225830078, -7.456699848175049, -7.5117998123168945, -7.539700031280518, -7.617000102996826, -7.637700080871582, -7.688399791717529, -7.717599868774414, -7.725200176239014, -7.737400054931641, -4.203199863433838, -5.143700122833252, -3.8819000720977783, -2.081899881362915, -4.335400104522705, -4.829699993133545, -2.520400047302246, -3.91510009765625, -4.820400238037109, -5.225500106811523, -2.0587000846862793, -4.316100120544434, -5.910999774932861, -3.850600004196167, -4.089300155639648, -4.855400085449219, -5.7179999351501465, -3.8559000492095947, -5.754700183868408, -4.389400005340576, -5.511199951171875, -5.443399906158447, -5.377999782562256, -4.8130998611450195, -5.380099773406982, -5.621500015258789, -4.905900001525879, -4.765699863433838, -4.63640022277832, -4.911200046539307, -5.172999858856201, -5.291600227355957, -5.069699764251709, -5.074900150299072, -5.078400135040283, -4.342700004577637, -4.448500156402588, -5.025000095367432, -5.0914998054504395, -5.934800148010254, -5.95959997177124, -5.966100215911865, -3.464400053024292, -6.237100124359131, -6.302299976348877, -6.3643999099731445, -6.423299789428711, -6.420899868011475, -6.432400226593018, -6.475800037384033, -6.470300197601318, -6.49370002746582, -6.554299831390381, -6.60290002822876, -6.64709997177124, -6.690199851989746, -6.787499904632568, -6.810200214385986, -6.847099781036377, -6.883399963378906, -6.8917999267578125, -7.045100212097168, -7.049200057983398, -7.095200061798096, -7.126299858093262, -2.8473000526428223, -5.027500152587891, -4.320199966430664, -5.577300071716309, -5.605299949645996, -2.776700019836426, -5.235099792480469, -3.5006000995635986, -3.6881000995635986, -5.129300117492676, -4.744999885559082, -3.9221999645233154, -4.2104997634887695, -3.996999979019165, -3.8368000984191895, -5.514100074768066, -5.888299942016602, -4.033899784088135, -4.03439998626709, -4.578999996185303, -4.834799766540527, -2.7850000858306885, -4.963799953460693, -4.765699863433838, -4.9878997802734375, -4.452600002288818, -4.385300159454346, -4.911399841308594, -5.02869987487793, -4.88070011138916, -5.0619001388549805, -3.7995998859405518, -3.8529000282287598, -4.334199905395508, -4.341599941253662, -4.355999946594238, -4.40910005569458, -4.554800033569336, -4.606200218200684, -4.725599765777588, -4.9217000007629395, -5.130799770355225, -5.160799980163574, -5.219699859619141, -5.228300094604492, -5.338399887084961, -5.366600036621094, -5.399099826812744, -5.4928998947143555, -5.57390022277832, -5.689899921417236, -5.718999862670898, -5.73769998550415, -5.760000228881836, -5.772799968719482, -5.786399841308594, -5.8171000480651855, -5.842299938201904, -5.855500221252441, -5.886099815368652, -5.962200164794922, -4.925600051879883, -5.535200119018555, -5.590400218963623, -2.896699905395508, -3.5004000663757324, -4.632199764251709, -4.7179999351501465, -4.863699913024902, -4.921000003814697, -5.00029993057251, -5.045899868011475, -5.106100082397461, -5.1168999671936035, -5.154099941253662, -5.174499988555908, -5.17710018157959, -5.190199851989746, -5.332600116729736, -5.348800182342529, -5.354599952697754, -5.484499931335449, -5.509799957275391, -5.513500213623047, -5.524400234222412, -5.530200004577637, -5.601799964904785, -5.613900184631348, -5.684100151062012, -5.751800060272217, -5.770999908447266, -5.787700176239014, -5.791999816894531, -5.824999809265137, -4.680300235748291, -3.1349000930786133, -3.9274001121520996, -5.335999965667725, -4.962600231170654, -5.5980000495910645], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0526, 1.0518, 1.0517, 1.0512, 1.0511, 1.051, 1.0504, 1.0502, 1.0502, 1.0495, 1.0494, 1.0494, 1.0483, 1.0479, 1.0479, 1.0476, 1.0473, 1.0471, 1.0468, 1.0466, 1.0463, 1.0463, 1.0461, 1.0458, 1.0451, 1.0449, 1.0447, 1.0447, 1.0447, 1.0444, 0.9933, 1.0138, 0.9441, 0.9281, 0.944, 0.9315, 0.9681, 0.8963, 0.9726, 0.861, 0.9151, 0.9146, 0.9573, 0.8726, 0.7916, 0.951, 0.7844, 0.6628, 0.6689, 0.2128, 0.8793, 0.1346, -0.1586, 0.8147, 0.6286, 0.1679, 0.4781, 0.1416, -0.1239, 0.2223, 0.0374, 0.572, 0.1363, 0.138, 0.2972, -0.2784, 0.0276, -0.0372, -0.1691, 1.1133, 1.113, 1.1126, 1.1121, 1.1118, 1.1117, 1.1113, 1.11, 1.1099, 1.1099, 1.1094, 1.1089, 1.1078, 1.1071, 1.107, 1.1066, 1.1065, 1.1064, 1.1061, 1.1058, 1.1056, 1.1043, 1.103, 1.1024, 1.1018, 1.1016, 1.1014, 1.101, 1.1006, 1.1006, 1.1002, 1.0786, 1.0689, 1.0022, 0.8639, 0.9504, 0.9755, 0.8695, 0.7647, 0.92, 0.7136, 0.9668, 0.6641, 0.6666, 0.8873, -0.0218, 0.3057, 0.5168, 0.5257, 0.4528, 0.6927, 0.4109, 0.3032, 0.6157, 0.649, 0.3917, 0.0634, 0.2283, -0.023, 0.2738, 0.252, 0.02, -0.1491, -1.0091, 0.1248, -0.044, 1.9125, 1.9118, 1.911, 1.91, 1.9048, 1.9016, 1.9006, 1.8947, 1.8925, 1.8909, 1.8896, 1.8894, 1.888, 1.8867, 1.8861, 1.8823, 1.8817, 1.8803, 1.8769, 1.8763, 1.8756, 1.8754, 1.8732, 1.8722, 1.8686, 1.8679, 1.8658, 1.8641, 1.8638, 1.8633, 1.7092, 1.7265, 1.5729, 1.3337, 1.4705, 1.5277, 1.1695, 1.2321, 1.3123, 1.3985, 0.6402, 1.085, 1.3644, 0.591, 0.5781, 0.8499, 1.2347, 0.2739, 1.2236, 0.4061, 1.0424, 0.9779, 0.9008, 0.3754, 0.7848, 1.0667, 0.1358, -0.0587, -0.2918, 0.0277, 0.3848, 0.6142, 0.0523, -0.001, 0.0052, 2.2021, 2.2018, 2.1999, 2.1996, 2.1933, 2.193, 2.1929, 2.1918, 2.1895, 2.1884, 2.1874, 2.1864, 2.1864, 2.1862, 2.1855, 2.1855, 2.1851, 2.184, 2.1829, 2.1819, 2.1808, 2.1786, 2.178, 2.1771, 2.1761, 2.1759, 2.1711, 2.171, 2.1696, 2.1683, 1.8716, 2.0194, 1.9563, 2.0224, 1.9913, 1.5679, 1.9349, 1.5829, 1.3866, 1.7433, 1.6267, 1.3786, 1.4554, 1.3043, 1.2326, 1.839, 1.9514, 1.1133, 1.0261, 1.213, 1.269, -0.0862, 1.3506, 1.1702, 1.2822, 0.7359, 0.3217, 0.5423, 0.6289, -0.7509, 0.4959, 3.2852, 3.285, 3.2825, 3.2825, 3.2824, 3.282, 3.2809, 3.2805, 3.2794, 3.2774, 3.2747, 3.2742, 3.2733, 3.2732, 3.2714, 3.2709, 3.2703, 3.2685, 3.2667, 3.2641, 3.2633, 3.2629, 3.2623, 3.2619, 3.2616, 3.2607, 3.26, 3.2596, 3.2587, 3.2564, -1.5099, -1.8453, -1.2458, 3.5811, 3.5794, 3.5715, 3.5705, 3.5685, 3.5676, 3.5664, 3.5656, 3.5645, 3.5643, 3.5636, 3.5632, 3.5631, 3.5628, 3.5597, 3.5594, 3.5592, 3.556, 3.5553, 3.5552, 3.5549, 3.5548, 3.5527, 3.5522, 3.5501, 3.5479, 3.5472, 3.5466, 3.5465, 3.5452, 3.4689, 3.0334, 2.5651, 3.1729, 1.765, 1.918]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 3, 6, 1, 1, 3, 1, 3, 5, 2, 4, 1, 2, 4, 5, 2, 1, 2, 3, 1, 1, 2, 4, 3, 3, 1, 2, 2, 3, 4, 1, 2, 3, 1, 1, 3, 3, 6, 2, 3, 4, 5, 3, 4, 1, 1, 4, 1, 3, 5, 4, 1, 4, 1, 2, 4, 1, 2, 3, 6, 5, 1, 2, 3, 4, 6, 6, 5, 1, 2, 3, 5, 1, 6, 2, 4, 5, 1, 2, 3, 4, 4, 5, 5, 6, 1, 6, 3, 1, 4, 3, 1, 3, 2, 1, 3, 5, 2, 3, 6, 6, 1, 2, 1, 2, 6, 2, 2, 6, 4, 1, 2, 3, 2, 4, 5, 4, 6, 2, 3, 4, 4, 3, 5, 5, 6, 2, 3, 4, 1, 2, 1, 2, 5, 1, 2, 3, 3, 1, 2, 1, 2, 3, 4, 1, 2, 3, 3, 2, 1, 1, 3, 4, 6, 1, 2, 2, 2, 5, 1, 3, 2, 1, 1, 3, 1, 2, 3, 1, 2, 3, 5, 4, 1, 2, 3, 4, 2, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 3, 4, 4, 1, 2, 4, 6, 1, 2, 1, 6, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 4, 3, 1, 2, 3, 4, 5, 1, 2, 6, 5, 1, 2, 3, 5, 3, 2, 1, 1, 4, 1, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 3, 1, 3, 5, 4, 1, 2, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 1, 2, 1, 3, 4, 1, 2, 3, 4, 1, 6, 4, 4, 2, 2, 4, 1, 2, 4, 5, 1, 1, 2, 3, 4, 5, 2, 2, 3, 4, 2, 6, 5, 1, 5, 2, 4, 6, 2, 5, 1, 2, 6, 2, 3, 2, 1, 2, 2, 4, 5, 2, 3, 4, 6, 2, 4, 5, 1, 2, 1, 2, 4, 3, 1, 6, 2, 5, 2, 2, 1, 4, 2, 1, 6, 1, 2, 3, 2, 4, 1, 4, 1, 6, 4, 6, 4, 6, 4, 6, 5, 3, 2, 4, 4, 6, 2, 1, 1, 5, 4, 3, 4, 4, 1, 3, 3, 1, 2, 3, 2, 1, 6, 1, 6, 5, 1, 2, 3, 4, 2, 4, 2, 4, 4, 1, 3, 6, 2, 6, 2, 4, 3, 2, 3, 4, 1, 2, 6, 3, 1, 2, 4, 4, 1, 1, 2, 3, 5, 2, 5, 5, 1, 2, 3, 2, 1, 2, 4, 6, 1, 2, 1, 3, 2, 5, 2, 5, 6, 2, 3, 2, 1, 2, 3, 4, 1, 2, 1, 3, 2, 4, 1, 2, 4, 1, 3, 4, 6], \"Freq\": [0.9209609861245577, 0.07674674884371314, 0.3007522905377648, 0.1181526855684076, 0.5800222746085465, 0.9767827589003318, 0.9978788675474234, 0.9417391134824518, 0.05779038639347803, 0.854201293469765, 0.1448182325352714, 0.9648197604075422, 0.5732203026910533, 0.42529248264174924, 0.9960190533240613, 0.5501051477733803, 0.44127353475443043, 0.007731207482220479, 0.9954566196979745, 0.06047427251422841, 0.1223229603128711, 0.8150282636576692, 0.9989034450631609, 0.9017365066922061, 0.09672606127148231, 0.990442998859826, 0.9682026002182171, 0.9580270487642177, 0.22086078067966705, 0.7789205310389904, 0.42229713062902524, 0.3628186615263456, 0.21412248876964662, 0.7878472122986869, 0.1142088096452642, 0.0967871268180205, 0.9958464093993861, 0.5629298358941208, 0.43682695903936164, 0.998736973973448, 0.9920470499593241, 0.15793633618342973, 0.5064193451711593, 0.33569464168542756, 0.9933234107918292, 0.9660654940820963, 0.9817320667071858, 0.996274054995816, 0.9902474454709383, 0.9613199164671277, 0.995330602952357, 0.9964915402645935, 0.9748774846788554, 0.9850124966942102, 0.21718689659185167, 0.7743185008926886, 0.26032454632222696, 0.43152897768729515, 0.30781618652966025, 0.2569246625437982, 0.6392036967319495, 0.10256266770901622, 0.9770381057290562, 0.9791217581257573, 0.2850693856085179, 0.607417075488919, 0.10635280924625476, 0.9709946187427995, 0.9721639628313559, 0.9982423771706221, 0.9915036164436337, 0.4016792641236099, 0.33479867728923546, 0.26316917304650306, 0.9860279102472798, 0.9918813743861327, 0.9858534157209947, 0.9986373312741621, 0.9817723965483443, 0.9883772175724096, 0.297577902725711, 0.3211232568418241, 0.28000179331509134, 0.10120080607183819, 0.9872331654443743, 0.011702117262810473, 0.9970696187367354, 0.9885984607124714, 0.42248234737021195, 0.5769191718290709, 0.9685308412999427, 0.3018469287444112, 0.6965698355640259, 0.9794051492829465, 0.9918357677463696, 0.9774998134472577, 0.980614761931329, 0.4505567745307417, 0.5482059614062257, 0.9679690681182695, 0.980255655449353, 0.98123982212649, 0.9760345684762879, 0.9896737346002596, 0.8964630191255691, 0.10222823902309121, 0.1269759121212462, 0.8717384736016326, 0.9846322578751187, 0.9807435472625275, 0.9972428657049076, 0.9606363227632799, 0.9834893004147911, 0.13228076501384642, 0.7829008320656453, 0.08411331253597842, 0.6013985835140078, 0.39700167931316854, 0.9898036310118408, 0.3319249808084729, 0.6638499616169458, 0.9942576211576769, 0.9492975049904785, 0.9766293849165598, 0.9594432752101627, 0.9660139035004474, 0.9752717591072384, 0.9784761610496735, 0.97579858655388, 0.24919448422329316, 0.5963867993209151, 0.1511966533489644, 0.17391726798393958, 0.8232084017906474, 0.6181415434248956, 0.3817561270231461, 0.987460621510614, 0.43560769178195735, 0.4122437512215425, 0.15160601430313653, 0.9340841883876263, 0.2945913146178712, 0.7053760162762573, 0.23522901456774387, 0.3663402685891093, 0.2169120011382884, 0.18124202761776986, 0.18129824374704837, 0.6559951720313048, 0.16192285891911953, 0.9742900736775849, 0.9917771316220917, 0.9963616335354604, 0.24338207146451019, 0.6424298333073366, 0.11366066281591339, 0.9807652088373201, 0.9176599792668275, 0.07890706828090556, 0.9968655674164943, 0.9852890037968838, 0.010709663084748737, 0.5793101944410496, 0.4175208608584141, 0.9983460275812821, 0.9878024667815577, 0.6059074173450548, 0.3932682105032054, 0.44760334221425224, 0.2264554458633371, 0.32376052025773977, 0.4123658072972543, 0.32079912726953325, 0.2664906135979193, 0.9804605588437427, 0.9741384754321561, 0.3081522045823721, 0.44569951270428604, 0.1941844349956433, 0.0520136879452616, 0.9908357714041078, 0.9789955412284453, 0.20061200766611828, 0.796368878917015, 0.3993478914841536, 0.37156154952004583, 0.12600782983723294, 0.10209865186811694, 0.195253871545216, 0.5311451470705526, 0.2730823378254769, 0.9440802126190011, 0.9929487812306714, 0.9672650159628877, 0.20963321380340338, 0.3834571953556916, 0.4065839911845368, 0.9521997844534543, 0.8705333038823532, 0.12808345368842602, 0.9970373689909777, 0.9682592424128259, 0.9932741915419228, 0.9950661995472844, 0.9987609453466616, 0.984426893269998, 0.653589158662701, 0.34522914534491383, 0.49485452662576423, 0.5028360512487604, 0.9631716911900015, 0.5056919824957539, 0.4901322291881922, 0.9704075200571067, 0.4005027066007044, 0.15460337426183599, 0.21457882117375512, 0.23057227368360023, 0.9970935882069896, 0.705014430358669, 0.13044319856856432, 0.16150110298965104, 0.9810340562443376, 0.3988976325632108, 0.11971395915670828, 0.47543118356638003, 0.005955918366005387, 0.9993061897579855, 0.9994024415117337, 0.9912182337251054, 0.4373346286121004, 0.5613548964274722, 0.9974616452866516, 0.9879112317866406, 0.9732274446888136, 0.20303159362543444, 0.36426256503386767, 0.42994925708915527, 0.9876414846031865, 0.2639199976200518, 0.44467019879821523, 0.1391653029572192, 0.1523407162549441, 0.981185251277235, 0.43146162323698206, 0.5602662736157034, 0.008262512722009362, 0.9799498098736134, 0.13296153788053894, 0.8624532186845769, 0.46910446242276593, 0.25018904662547514, 0.09034604461475491, 0.1893792089040055, 0.09966029828469103, 0.8944302400676473, 0.005862370487334767, 0.7636786814389132, 0.09708628060232578, 0.1391236392136421, 0.8350568918501793, 0.1651591264842314, 0.9913524858825816, 0.9831443553776171, 0.9777549721494085, 0.6765520555296408, 0.05712906319964387, 0.22176872564901123, 0.04408384404381968, 0.9609324087900272, 0.036537353946388865, 0.9729264943565044, 0.9876775760479439, 0.99320545592087, 0.16667497031279696, 0.8291011343764773, 0.19875881066329235, 0.4223624726594962, 0.37858821078722354, 0.9960225976939525, 0.9978701633464073, 0.9961173599537223, 0.34961774955915087, 0.11033019145924022, 0.529298347078485, 0.010603161257121789, 0.996040709813701, 0.4327513053445474, 0.174764950235298, 0.39280503100505076, 0.9860576758639589, 0.9786137808210029, 0.9930491040045976, 0.9916946940087521, 0.9770298054631137, 0.18513760943457577, 0.8071999771347503, 0.9841281478152432, 0.9921173914491239, 0.9801030341189971, 0.7699047605327687, 0.22974935711136588, 0.9758751225395158, 0.9953198942783791, 0.9553639921517905, 0.9949884537208464, 0.8245850333372408, 0.17422204785996923, 0.5263023271382953, 0.4725980080425508, 0.9764015807616164, 0.07515553690313487, 0.27329286146594495, 0.45776554295545785, 0.1913050030261615, 0.5554518223774744, 0.43765130165849325, 0.006710156243486268, 0.3620426360400807, 0.6378382376533858, 0.8406905087147796, 0.15807855719423206, 0.9827969748795151, 0.9841283042658369, 0.6358492357514617, 0.3608874040751539, 0.9971228715170096, 0.9943566860319846, 0.9975662066703455, 0.9986983844094939, 0.8820222627488635, 0.11743639192406964, 0.9841823847012885, 0.9887878626655537, 0.975388076740706, 0.13941499227488094, 0.17802222090484798, 0.6799161930944194, 0.9886887911348649, 0.98245385588217, 0.9970362490193085, 0.9764794337897018, 0.9929579110708309, 0.9648047104084287, 0.9877305861256266, 0.9727120813499297, 0.9725508059484453, 0.9991304211422486, 0.1029483767370145, 0.8879297493567501, 0.9855613071135376, 0.9804578717161684, 0.23203949538491303, 0.7637966723086721, 0.9985315330864722, 0.974090917635507, 0.991598991960653, 0.9906354077307455, 0.9945607306551222, 0.9771323818654999, 0.9828723582534207, 0.9816556644218762, 0.9878572569360351, 0.9957261512394064, 0.28788120564504704, 0.711440562591083, 0.9860101371911996, 0.9939480649063778, 0.9978329257539018, 0.9680592723796319, 0.9835221453515897, 0.9884133079832185, 0.9598854127877791, 0.998459860773938, 0.9527351089285093, 0.9671720623575181, 0.21306014491782563, 0.41546728258976, 0.16405631158672573, 0.20666834057029088, 0.6274972179486861, 0.3716245659696102, 0.1634263993134423, 0.8319889419593427, 0.9975912297230685, 0.8699313812797234, 0.12840982966914835, 0.9676267186508344, 0.9551462775798905, 0.04264045882053082, 0.28290408532774963, 0.7170514445494214, 0.9947037110284677, 0.3137977991316213, 0.14819896058415002, 0.5369962336956043, 0.8848425489298797, 0.11390696991821213, 0.9911053054690491, 0.98191487791535, 0.23386301707363577, 0.6698973339539193, 0.09562156071936043, 0.9943462481391471, 0.9973279787115176, 0.35854089472199785, 0.48574496867554146, 0.1552637961491782, 0.9800682987435598, 0.9959075613078271, 0.9898484556341319, 0.9742984917874645, 0.33575543583458545, 0.5164096880358491, 0.1473758373220835, 0.9915525698178382, 0.1543912762315058, 0.2118391929688103, 0.6319270841103493, 0.9905636513543481, 0.896465781974564, 0.10286081417966103, 0.9096741577835542, 0.08866860021716955, 0.9932533620189832, 0.0065202627703653164, 0.9647431714676937, 0.029234641559627083, 0.9735371324967993, 0.16833775430344697, 0.8309438084765893, 0.9957138444366737, 0.23705418047639534, 0.4948218330332524, 0.16916002199043745, 0.09838899238219322, 0.14910349666123585, 0.8482332254505862, 0.9913625986798176, 0.9714966504838777, 0.2175844797196543, 0.7793480455413072, 0.6807285083837255, 0.2292776285353155, 0.08977349398988409, 0.5332626732440356, 0.10974799079956407, 0.35597745733704755, 0.9681988551404236], \"Term\": [\"advice\", \"advice\", \"ai\", \"ai\", \"ai\", \"aid\", \"algebra\", \"algorithm\", \"algorithm\", \"algorithms\", \"algorithms\", \"algoritmos\", \"amaze\", \"amaze\", \"analysis\", \"andrew\", \"andrew\", \"andrew\", \"answer\", \"anyone\", \"anyone\", \"anyone\", \"application\", \"approach\", \"approach\", \"approachable\", \"art\", \"aspire\", \"assignment\", \"assignment\", \"awesome\", \"awesome\", \"awesome\", \"background\", \"background\", \"background\", \"balance\", \"basic\", \"basic\", \"beginner\", \"benefit\", \"best\", \"best\", \"best\", \"bien\", \"brief\", \"bring\", \"build\", \"building\", \"busy\", \"calculus\", \"career\", \"ce\", \"certificate\", \"chance\", \"chance\", \"class\", \"class\", \"class\", \"clear\", \"clear\", \"clear\", \"combination\", \"como\", \"complete\", \"complete\", \"complete\", \"comprehensible\", \"compute\", \"computer\", \"con\", \"concept\", \"concept\", \"concept\", \"conceptos\", \"concise\", \"congratulation\", \"content\", \"contribution\", \"cours\", \"course\", \"course\", \"course\", \"course\", \"coursera\", \"coursera\", \"curso\", \"daily\", \"data\", \"data\", \"date\", \"day\", \"day\", \"deadline\", \"debug\", \"decade\", \"dedication\", \"deep\", \"deep\", \"del\", \"deliver\", \"delve\", \"describe\", \"didactic\", \"different\", \"different\", \"difficult\", \"difficult\", \"discipline\", \"discuss\", \"discussion\", \"dream\", \"ease\", \"easy\", \"easy\", \"easy\", \"effort\", \"effort\", \"el\", \"english\", \"english\", \"enjoyable\", \"enrol\", \"enter\", \"enthusiasm\", \"era\", \"est\", \"este\", \"evaluate\", \"everyone\", \"everyone\", \"everyone\", \"everything\", \"everything\", \"example\", \"example\", \"excelente\", \"excellent\", \"excellent\", \"excellent\", \"excercises\", \"exercise\", \"exercise\", \"experience\", \"experience\", \"experience\", \"experience\", \"explain\", \"explain\", \"explain\", \"explained\", \"explains\", \"familiar\", \"field\", \"field\", \"field\", \"financial\", \"focus\", \"focus\", \"follow\", \"forum\", \"forum\", \"foundation\", \"foundation\", \"fun\", \"function\", \"fundamental\", \"fundamental\", \"get\", \"get\", \"get\", \"good\", \"good\", \"good\", \"gracias\", \"gratitude\", \"great\", \"great\", \"great\", \"great\", \"guidance\", \"guy\", \"hard\", \"hard\", \"help\", \"help\", \"help\", \"help\", \"helpful\", \"helpful\", \"helpful\", \"high-level\", \"hope\", \"human\", \"i\", \"i\", \"i\", \"illustrate\", \"implement\", \"implement\", \"implementation\", \"inspiration\", \"inspire\", \"intelligence\", \"interested\", \"intermediate\", \"introduction\", \"introduction\", \"introductory\", \"introductory\", \"join\", \"journey\", \"journey\", \"joy\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"la\", \"language\", \"language\", \"language\", \"le\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"lecture\", \"library\", \"life\", \"life\", \"linear\", \"live\", \"lo\", \"look\", \"look\", \"look\", \"los\", \"lot\", \"lot\", \"lot\", \"lot\", \"luck\", \"machine\", \"machine\", \"machine\", \"man\", \"manner\", \"manner\", \"many\", \"many\", \"many\", \"many\", \"material\", \"material\", \"material\", \"math\", \"math\", \"math\", \"mathematical\", \"mathematical\", \"matrix\", \"meet\", \"minute\", \"ml\", \"ml\", \"ml\", \"ml\", \"model\", \"model\", \"module\", \"mooc\", \"motivation\", \"mr\", \"mr\", \"much\", \"much\", \"much\", \"muy\", \"network\", \"neural\", \"ng\", \"ng\", \"ng\", \"ng\", \"note\", \"online\", \"online\", \"online\", \"optional\", \"package\", \"para\", \"performance\", \"pero\", \"platform\", \"platform\", \"play\", \"pleasure\", \"por\", \"practical\", \"practical\", \"preparation\", \"prepared\", \"prerequisite\", \"presentation\", \"problem\", \"problem\", \"prof\", \"prof\", \"profesor\", \"professional\", \"professional\", \"professional\", \"professional\", \"professor\", \"professor\", \"professor\", \"program\", \"program\", \"project\", \"project\", \"proud\", \"pursue\", \"python\", \"python\", \"quality\", \"que\", \"question\", \"quiz\", \"real\", \"real\", \"real-life\", \"real-world\", \"reasonable\", \"recommend\", \"recommend\", \"recommend\", \"reference\", \"refresh\", \"regression\", \"regret\", \"research\", \"researcher\", \"reward\", \"s\", \"scene\", \"science\", \"scientist\", \"scientist\", \"se\", \"select\", \"share\", \"share\", \"sir\", \"situation\", \"slide\", \"software\", \"solid\", \"son\", \"special\", \"specialization\", \"staff\", \"stanford\", \"start\", \"start\", \"state\", \"statistic\", \"style\", \"success\", \"superb\", \"supervise\", \"syllabus\", \"system\", \"ta\", \"te\", \"teach\", \"teach\", \"teach\", \"teach\", \"teacher\", \"teacher\", \"teaching\", \"teaching\", \"team\", \"technique\", \"technique\", \"terrific\", \"test\", \"test\", \"thank\", \"thank\", \"thankful\", \"thanks\", \"thanks\", \"thanks\", \"theory\", \"theory\", \"thought\", \"till\", \"time\", \"time\", \"time\", \"tom\", \"tool\", \"topic\", \"topic\", \"topic\", \"tr\\u00e8s\", \"tutorial\", \"un\", \"una\", \"understand\", \"understand\", \"understand\", \"understood\", \"university\", \"university\", \"university\", \"update\", \"use\", \"use\", \"various\", \"various\", \"video\", \"video\", \"videos\", \"videos\", \"vision\", \"want\", \"want\", \"watch\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"wide\", \"willing\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"\\u2019\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 2, 6, 3, 1, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el43792140693986409600816700436\", ldavis_el43792140693986409600816700436_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el43792140693986409600816700436\", ldavis_el43792140693986409600816700436_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el43792140693986409600816700436\", ldavis_el43792140693986409600816700436_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4     -0.187411 -0.145520       1        1  34.873122\n",
       "1     -0.190312  0.053737       2        1  32.823490\n",
       "5     -0.171310 -0.128320       3        1  14.763286\n",
       "2     -0.068088  0.283742       4        1  11.032198\n",
       "0      0.310653 -0.049028       5        1   3.729135\n",
       "3      0.306469 -0.014611       6        1   2.778769, topic_info=              Term          Freq         Total Category  logprob  loglift\n",
       "22         machine   8835.000000   8835.000000  Default  30.0000  30.0000\n",
       "9           course  18092.000000  18092.000000  Default  29.0000  29.0000\n",
       "19           learn   6716.000000   6716.000000  Default  28.0000  28.0000\n",
       "1134         thank   2400.000000   2400.000000  Default  27.0000  27.0000\n",
       "710             ng   3489.000000   3489.000000  Default  26.0000  26.0000\n",
       "...            ...           ...           ...      ...      ...      ...\n",
       "480           data    325.086511    563.337146   Topic6  -3.1349   3.0334\n",
       "93          python    147.160840    407.329262   Topic6  -3.9274   2.5651\n",
       "444        english     35.978819     54.229121   Topic6  -5.3360   3.1729\n",
       "380       language     52.265350    321.979225   Topic6  -4.9626   1.7650\n",
       "1265  professional     27.686147    146.363135   Topic6  -5.5980   1.9180\n",
       "\n",
       "[360 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "1200      1  0.920961  advice\n",
       "1200      2  0.076747  advice\n",
       "952       1  0.300752      ai\n",
       "952       2  0.118153      ai\n",
       "952       3  0.580022      ai\n",
       "...     ...       ...     ...\n",
       "123       4  0.089773    work\n",
       "986       1  0.533263   world\n",
       "986       3  0.109748   world\n",
       "986       4  0.355977   world\n",
       "1037      6  0.968199       ’\n",
       "\n",
       "[449 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 2, 6, 3, 1, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-person",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
